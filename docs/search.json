[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Diego Alberto Vega Víquez",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "cursos/CA0306/tema1.html",
    "href": "cursos/CA0306/tema1.html",
    "title": "tema1",
    "section": "",
    "text": "tema1 CA0306"
  },
  {
    "objectID": "cursos/CA0306/index.html",
    "href": "cursos/CA0306/index.html",
    "title": "Curso CA0306",
    "section": "",
    "text": "Bienvenido a los apuntes del curso CA0306.\nAquí encontrarás los temas desarrollados durante el curso, organizados por unidad o semana.\n\n\n\nTema 1: Introducción al curso\nTema 2: Lógica y conjuntos\nTema 3: Funciones y relaciones\nTema 4: Inducción y recursión"
  },
  {
    "objectID": "cursos/CA0306/index.html#temas",
    "href": "cursos/CA0306/index.html#temas",
    "title": "Curso CA0306",
    "section": "",
    "text": "Tema 1: Introducción al curso\nTema 2: Lógica y conjuntos\nTema 3: Funciones y relaciones\nTema 4: Inducción y recursión"
  },
  {
    "objectID": "index_main.html",
    "href": "index_main.html",
    "title": "Diego Alberto Vega Víquez",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "cursos/CA0721/index.html",
    "href": "cursos/CA0721/index.html",
    "title": "Curso CA0721",
    "section": "",
    "text": "Bienvenido a los apuntes del curso CA0721.\n\n\n\nTema 1: Introducción\nTema 2: Probabilidad\nTema 3: Distribuciones"
  },
  {
    "objectID": "cursos/CA0721/index.html#temas",
    "href": "cursos/CA0721/index.html#temas",
    "title": "Curso CA0721",
    "section": "",
    "text": "Tema 1: Introducción\nTema 2: Probabilidad\nTema 3: Distribuciones"
  },
  {
    "objectID": "cursos/CA0306/index_CA0306.html",
    "href": "cursos/CA0306/index_CA0306.html",
    "title": "CA0306: Contingencias de Vida I",
    "section": "",
    "text": "Bienvenido a los apuntes del curso CA0306.\nAquí encontrarás los temas desarrollados durante el curso, organizados por unidad o semana."
  },
  {
    "objectID": "cursos/CA0306/index_CA0306.html#temas",
    "href": "cursos/CA0306/index_CA0306.html#temas",
    "title": "CA0306: Contingencias de Vida I",
    "section": "Temas",
    "text": "Temas\n\nTema 1: Distribuciones de Sobrevivencia"
  },
  {
    "objectID": "cursos/CA0306/distribuciones_sobrevivencia_CA0306.html",
    "href": "cursos/CA0306/distribuciones_sobrevivencia_CA0306.html",
    "title": "tema1",
    "section": "",
    "text": "tema1 CA0306"
  },
  {
    "objectID": "cursos/CA0721/antecedentes_CA0721.html",
    "href": "cursos/CA0721/antecedentes_CA0721.html",
    "title": "Preliminares",
    "section": "",
    "text": "Dada una sucesión \\(\\{a_k\\}\\), definimos la suma finita desde \\(k = m\\) hasta \\(k = n\\) como:\n\\[\n\\sum_{k=m}^n a_k = a_m + a_{m+1} + \\cdots + a_n\n\\]\n\n\n\nLinealidad por constante: \\[\n\\sum_{k=1}^n c a_k = c \\sum_{k=1}^n a_k \\quad \\text{para todo } c \\in \\mathbb{R}\n\\]\nSuma término a término: \\[\n\\sum_{k=1}^n (a_k + b_k) = \\sum_{k=1}^n a_k + \\sum_{k=1}^n b_k\n\\]\nCambio de índice: \\[\n\\sum_{k=0}^n a_{k+1} = \\sum_{k=1}^{n+1} a_k\n\\]\n\n\n\n\nSi \\(a_k = b_k - b_{k+1}\\), entonces se tiene:\n\\[\n\\sum_{k=m}^n (b_k - b_{k+1}) = b_m - b_{n+1}\n\\]\nSi la suma es infinita y el límite existe:\n\\[\n\\sum_{k=m}^\\infty (b_k - b_{k+1}) = b_m - \\lim_{j \\to \\infty} b_{j+1}\n\\]\n\n\n\nLa suma de una progresión geométrica de razón \\(r \\ne 1\\) es:\n\\[\n\\sum_{k=m}^n r^k = \\frac{r^m - r^{n+1}}{1 - r}\n\\]"
  },
  {
    "objectID": "cursos/CA0721/index_CA0721.html",
    "href": "cursos/CA0721/index_CA0721.html",
    "title": "CA0721: Probabilidad",
    "section": "",
    "text": "Bienvenido a los apuntes del curso CA0721."
  },
  {
    "objectID": "cursos/CA0721/index_CA0721.html#temas",
    "href": "cursos/CA0721/index_CA0721.html#temas",
    "title": "CA0721: Probabilidad",
    "section": "Temas",
    "text": "Temas\n\nTema 1: Preliminares\nTema 2: Introducción a la Probabilidad\nTema 3: Teoría General de la Probabilidad\nTema 4: Variables Aleatorias"
  },
  {
    "objectID": "cursos/CA0721/antecedentes_CA0721.html#sumas-finitas",
    "href": "cursos/CA0721/antecedentes_CA0721.html#sumas-finitas",
    "title": "Preliminares",
    "section": "",
    "text": "Dada una sucesión \\(\\{a_k\\}\\), definimos la suma finita desde \\(k = m\\) hasta \\(k = n\\) como:\n\\[\n\\sum_{k=m}^n a_k = a_m + a_{m+1} + \\cdots + a_n\n\\]\n\n\n\nLinealidad por constante: \\[\n\\sum_{k=1}^n c a_k = c \\sum_{k=1}^n a_k \\quad \\text{para todo } c \\in \\mathbb{R}\n\\]\nSuma término a término: \\[\n\\sum_{k=1}^n (a_k + b_k) = \\sum_{k=1}^n a_k + \\sum_{k=1}^n b_k\n\\]\nCambio de índice: \\[\n\\sum_{k=0}^n a_{k+1} = \\sum_{k=1}^{n+1} a_k\n\\]\n\n\n\n\nSi \\(a_k = b_k - b_{k+1}\\), entonces se tiene:\n\\[\n\\sum_{k=m}^n (b_k - b_{k+1}) = b_m - b_{n+1}\n\\]\nSi la suma es infinita y el límite existe:\n\\[\n\\sum_{k=m}^\\infty (b_k - b_{k+1}) = b_m - \\lim_{j \\to \\infty} b_{j+1}\n\\]\n\n\n\nLa suma de una progresión geométrica de razón \\(r \\ne 1\\) es:\n\\[\n\\sum_{k=m}^n r^k = \\frac{r^m - r^{n+1}}{1 - r}\n\\]"
  },
  {
    "objectID": "cursos/CA0721/antecedentes_CA0721.html#principios-de-combinatoria",
    "href": "cursos/CA0721/antecedentes_CA0721.html#principios-de-combinatoria",
    "title": "Preliminares",
    "section": "Principios de combinatoria",
    "text": "Principios de combinatoria\nSea \\(\\Omega_1\\) y \\(\\Omega_2\\) dos conjuntos finitos no vacíos. El número de formas de formar pares \\((a, b)\\) con \\(a \\in \\Omega_1\\) y \\(b \\in \\Omega_2\\) es:\n\\[\n|\\Omega_1 \\times \\Omega_2| = |\\Omega_1| \\cdot |\\Omega_2|\n\\]\ndonde \\(\\times\\) denota el producto cartesiano de conjuntos. Este resultado es un caso del principio de multiplicación.\nUna aplicación importante de este principio es el conteo de permutaciones. Si un conjunto \\(\\Omega\\) tiene \\(n\\) elementos, entonces existen:\n\\[\nn! := 1 \\cdot 2 \\cdot 3 \\cdots (n-1)\\cdot n\n\\]\nformas distintas de ordenarlos. Este número se llama el factorial de \\(n\\), y representa la cantidad total de permutaciones posibles de los elementos del conjunto.\n\nIntuitivamente, una permutación es una forma de reorganizar (ordenar) todos los elementos del conjunto.\n\n\nPermutaciones\nNúmero de formas de seleccionar \\(k\\) objetos ordenadamente de un total de \\(n\\):\n\\[\nP(n,k) = \\frac{n!}{(n-k)!}\n\\]\n\n\nCombinaciones\nNúmero de formas de elegir \\(k\\) objetos sin importar el orden:\n\\[\n\\binom{n}{k} = \\frac{n!}{k! (n-k)!}\n\\]\n\n\nCoeficiente multinomial\nNúmero de formas de dividir \\(n\\) objetos en \\(r\\) grupos de tamaños \\(n_1, n_2, \\ldots, n_r\\) con \\(n_1 + \\cdots + n_r = n\\):\n\\[\n\\binom{n}{n_1\\, n_2\\, \\cdots\\, n_r} = \\frac{n!}{n_1! \\, n_2! \\cdots n_r!}\n\\]\n\n\nFórmula del binomio\nExpansión de \\((a + b)^n\\) usando combinatoria:\n\\[\n(a + b)^n = \\sum_{k=0}^n \\binom{n}{k} a^{n-k} b^k\n\\]"
  },
  {
    "objectID": "cursos/CA0721/antecedentes_CA0721.html#algunos-recordatorios-de-teoría-de-conjuntos",
    "href": "cursos/CA0721/antecedentes_CA0721.html#algunos-recordatorios-de-teoría-de-conjuntos",
    "title": "Preliminares",
    "section": "Algunos recordatorios de Teoría de Conjuntos",
    "text": "Algunos recordatorios de Teoría de Conjuntos\nDado un conjunto \\(\\Omega\\), los subconjuntos \\(A, B, C, D \\subseteq \\Omega\\) pueden relacionarse mediante las siguientes operaciones y propiedades:\n\nPertenencia\nUn elemento \\(a\\) pertenece a un conjunto \\(A\\) si:\n\\[\na \\in A\n\\]\n\n\n\nIntersección de conjuntos\nLa intersección de dos conjuntos \\(A\\) y \\(B\\) se define como:\n\\[\nA \\cap B = \\{x \\in \\Omega \\mid x \\in A \\text{ y } x \\in B\\}\n\\]\nPropiedades:\n\nConmutatividad: \\(A \\cap B = B \\cap A\\)\nAsociatividad: \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\)\nInclusión: \\(A \\subseteq B \\Rightarrow A \\cap B = A\\)\nSi \\(D \\subseteq A\\) y \\(D \\subseteq B \\Rightarrow D \\subseteq A \\cap B\\)\n\n\n\n\nUnión de conjuntos\nLa unión de dos conjuntos \\(A\\) y \\(B\\) se define como:\n\\[\nA \\cup B = \\{x \\in \\Omega \\mid x \\in A \\text{ o } x \\in B\\}\n\\]\nPropiedades:\n\nConmutatividad: \\(A \\cup B = B \\cup A\\)\nAsociatividad: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\)\nInclusión: \\(A \\subseteq B \\Rightarrow A \\cup B = B\\)\nSi \\(A \\subseteq D\\) y \\(B \\subseteq D \\Rightarrow A \\cup B \\subseteq D\\)\n\n\n\n\nDiferencia de conjuntos\nLa diferencia de conjuntos se define como:\n\\[\nB - A = \\{x \\in B \\mid x \\notin A\\}\n\\]\nEl complemento de un conjunto \\(A\\) respecto al universo \\(\\Omega\\) es:\n\\[\nA^c = \\Omega - A = \\{x \\in \\Omega \\mid x \\notin A\\}\n\\]\n\n\n\nLeyes de De Morgan\nSean \\(\\{A_i\\}_{i \\in I}\\) una familia de conjuntos, se tiene:\n\n$ ( {i I} A_i )^c = {i I} A_i^c $\n$ ( {i I} A_i )^c = {i I} A_i^c $\n\nEn particular, para \\(A\\) y \\(B\\) arbitrarios:\n\n\\(E \\setminus (A \\cup B) = (E \\setminus A) \\cap (E \\setminus B)\\)\n\\(E \\setminus (A \\cap B) = (E \\setminus A) \\cup (E \\setminus B)\\)\n\\(A \\cap B = A \\setminus B^c\\)"
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html",
    "href": "cursos/CA0721/intro_proba_CA0721.html",
    "title": "Introducción a la Probabilidad",
    "section": "",
    "text": "Sea \\(\\Omega\\) un conjunto finito al que llamamos espacio muestral. Sus elementos representan todos los posibles resultados de un experimento aleatorio.\nSean \\(A, B \\subseteq \\Omega\\) subconjuntos del espacio muestral. Estos subconjuntos se denominan eventos.\nUn elemento \\(a\\) pertenece a un evento \\(A\\) si:\n\\[\na \\in A\n\\]\n\n\n\n\nEn el contexto de la probabilidad, un experimento aleatorio es un proceso que genera un resultado que no puede preverse con certeza. El conjunto \\(\\Omega\\) representa el conjunto de todos los posibles resultados de ese experimento.\nPor ejemplo:\n\nAl lanzar un dado: \\(\\Omega = \\{1,2,3,4,5,6\\}\\)\nAl lanzar una moneda: \\(\\Omega = \\{\\text{cara}, \\text{cruz}\\}\\)\n\n\n\n\n\nUn evento es cualquier subconjunto del espacio muestral. Esto incluye desde el conjunto vacío hasta el conjunto total \\(\\Omega\\). Notamos que:\n\nNota: Como los eventos son conjuntos, todas las operaciones entre conjuntos (unión, intersección, complemento, etc.) también se aplican a los eventos. Puedes consultar la sección Algunos recordatorios de Teoría de Conjuntos para ver esas propiedades en detalle.\n\nPodemos construir nuevos eventos combinando otros mediante operaciones de conjuntos:\n\nIntersección \\((A \\cap B\\,)\\): elementos que están en ambos eventos.\nUnión \\((A \\cup B\\,)\\): elementos que están en al menos uno de los eventos.\nComplemento \\((A^c)\\): elementos que no están en el evento \\(A\\).\n\n\n\n\n\nLa probabilidad es una función que asigna un número entre 0 y 1 a cada evento, representando cuán probable es que ese evento ocurra.\nProvisionalmente, podemos pensar en la probabilidad como una función:\n\\[\nP : \\mathcal{F} \\to [0,1]\n\\]\ndonde \\(\\mathcal{F}\\) es una colección de subconjuntos de \\(\\Omega\\) (es decir, eventos), y \\(P(A)\\) nos da la probabilidad de que ocurra el evento \\(A\\).\nMás adelante, formalizaremos los axiomas que esta función debe cumplir."
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html#introducción-a-la-notación-y-conceptos-básicos-de-probabilidad",
    "href": "cursos/CA0721/intro_proba_CA0721.html#introducción-a-la-notación-y-conceptos-básicos-de-probabilidad",
    "title": "Introducción a la Probabilidad",
    "section": "",
    "text": "Sea \\(\\Omega\\) un conjunto finito al que llamamos espacio muestral. Sus elementos representan todos los posibles resultados de un experimento aleatorio.\nSean \\(A, B \\subseteq \\Omega\\) subconjuntos del espacio muestral. Estos subconjuntos se denominan eventos.\nUn elemento \\(a\\) pertenece a un evento \\(A\\) si:\n\\[\na \\in A\n\\]\n\n\n\n\nEn el contexto de la probabilidad, un experimento aleatorio es un proceso que genera un resultado que no puede preverse con certeza. El conjunto \\(\\Omega\\) representa el conjunto de todos los posibles resultados de ese experimento.\nPor ejemplo:\n\nAl lanzar un dado: \\(\\Omega = \\{1,2,3,4,5,6\\}\\)\nAl lanzar una moneda: \\(\\Omega = \\{\\text{cara}, \\text{cruz}\\}\\)\n\n\n\n\n\nUn evento es cualquier subconjunto del espacio muestral. Esto incluye desde el conjunto vacío hasta el conjunto total \\(\\Omega\\). Notamos que:\n\nNota: Como los eventos son conjuntos, todas las operaciones entre conjuntos (unión, intersección, complemento, etc.) también se aplican a los eventos. Puedes consultar la sección Algunos recordatorios de Teoría de Conjuntos para ver esas propiedades en detalle.\n\nPodemos construir nuevos eventos combinando otros mediante operaciones de conjuntos:\n\nIntersección \\((A \\cap B\\,)\\): elementos que están en ambos eventos.\nUnión \\((A \\cup B\\,)\\): elementos que están en al menos uno de los eventos.\nComplemento \\((A^c)\\): elementos que no están en el evento \\(A\\).\n\n\n\n\n\nLa probabilidad es una función que asigna un número entre 0 y 1 a cada evento, representando cuán probable es que ese evento ocurra.\nProvisionalmente, podemos pensar en la probabilidad como una función:\n\\[\nP : \\mathcal{F} \\to [0,1]\n\\]\ndonde \\(\\mathcal{F}\\) es una colección de subconjuntos de \\(\\Omega\\) (es decir, eventos), y \\(P(A)\\) nos da la probabilidad de que ocurra el evento \\(A\\).\nMás adelante, formalizaremos los axiomas que esta función debe cumplir."
  },
  {
    "objectID": "cursos/CA0721/antecedentes_CA0721.html#sec-conjuntos",
    "href": "cursos/CA0721/antecedentes_CA0721.html#sec-conjuntos",
    "title": "Preliminares",
    "section": "Algunos recordatorios de Teoría de Conjuntos",
    "text": "Algunos recordatorios de Teoría de Conjuntos\nDado un conjunto \\(\\Omega\\), los subconjuntos \\(A, B, C, D \\subseteq \\Omega\\) pueden relacionarse mediante las siguientes operaciones y propiedades:\n\nPertenencia\nUn elemento \\(a\\) pertenece a un conjunto \\(A\\) si:\n\\[\na \\in A\n\\]\n\n\n\nIntersección de conjuntos\nLa intersección de dos conjuntos \\(A\\) y \\(B\\) se define como:\n\\[\nA \\cap B = \\{x \\in \\Omega \\mid x \\in A \\text{ y } x \\in B\\}\n\\]\nPropiedades:\n\nConmutatividad: \\(A \\cap B = B \\cap A\\)\nAsociatividad: \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\)\nInclusión: \\(A \\subseteq B \\Rightarrow A \\cap B = A\\)\nSi \\(D \\subseteq A\\) y \\(D \\subseteq B \\Rightarrow D \\subseteq A \\cap B\\)\n\n\n\n\nUnión de conjuntos\nLa unión de dos conjuntos \\(A\\) y \\(B\\) se define como:\n\\[\nA \\cup B = \\{x \\in \\Omega \\mid x \\in A \\text{ o } x \\in B\\}\n\\]\nPropiedades:\n\nConmutatividad: \\(A \\cup B = B \\cup A\\)\nAsociatividad: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\)\nInclusión: \\(A \\subseteq B \\Rightarrow A \\cup B = B\\)\nSi \\(A \\subseteq D\\) y \\(B \\subseteq D \\Rightarrow A \\cup B \\subseteq D\\)\n\n\n\n\nDiferencia de conjuntos\nLa diferencia de conjuntos se define como:\n\\[\nB - A = \\{x \\in B \\mid x \\notin A\\}\n\\]\nEl complemento de un conjunto \\(A\\) respecto al universo \\(\\Omega\\) es:\n\\[\nA^c = \\Omega - A = \\{x \\in \\Omega \\mid x \\notin A\\}\n\\]\n\n\n\nLeyes de De Morgan\nSean \\(\\{A_i\\}_{i \\in I}\\) una familia de conjuntos, se tiene:\n\n\\(\\left( \\bigcap\\limits_{i \\in I} A_i \\right)^c = \\bigcup\\limits_{i \\in I} A_i^c\\)\n\\(\\left( \\bigcup\\limits_{i \\in I} A_i \\right)^c = \\bigcap\\limits_{i \\in I} A_i^c\\)\n\nEn particular, para \\(A\\) y \\(B\\) arbitrarios:\n\n\\(E \\setminus (A \\cup B) = (E \\setminus A) \\cap (E \\setminus B)\\)\n\\(E \\setminus (A \\cap B) = (E \\setminus A) \\cup (E \\setminus B)\\)\n\\(A \\cap B = A \\setminus B^c\\)"
  },
  {
    "objectID": "cursos/CA0721/teoria_general_proba_CA0721.html",
    "href": "cursos/CA0721/teoria_general_proba_CA0721.html",
    "title": "Teoría General de Probabilidades",
    "section": "",
    "text": "Hasta ahora hemos trabajado con la probabilidad en contextos finitos y simples, donde todos los resultados son igualmente probables (modelo de Laplace). Sin embargo, para desarrollar una teoría más general de la probabilidad, necesitamos una base más formal.\nUn experimento aleatorio es un proceso cuyo resultado no se puede predecir con certeza, pero cuyo conjunto de resultados posibles puede describirse. A cada experimento aleatorio le asociamos tres componentes fundamentales:\n\nUn espacio muestral \\(\\Omega\\): el conjunto de todos los posibles resultados del experimento.\nUn conjunto de eventos \\(\\mathcal{F}\\): una colección de subconjuntos de \\(\\Omega\\), considerados como los eventos del experimento.\nUna función de probabilidad \\(P\\): que asigna a cada evento \\(A \\in \\mathcal{F}\\) un número entre \\(0\\) y \\(1\\), representando la probabilidad de que ese evento ocurra.\n\n\n\nPara que el conjunto de eventos \\(\\mathcal{F}\\) sea adecuado, debe cumplir ciertas propiedades. A esto se le llama una \\(\\sigma\\)-álgebra de subconjuntos, y garantiza que podamos hacer operaciones como complementos, uniones y demás, sin salirnos del conjunto de eventos válidos.\nFormalmente, \\(\\mathcal{F}\\) es una \\(\\sigma-\\)álgebra sobre \\(\\Omega\\) si:\n\n\\(\\mathcal{F}\\) no es vacío.\nSi \\(A \\in \\mathcal{F}\\), entonces su complemento también está en \\(\\mathcal{F}\\): \\[\nA^c = \\Omega \\setminus A \\in \\mathcal{F}\n\\]\nSi \\(A_1, A_2, A_3, \\dots \\in \\mathcal{F}\\), entonces la unión infinita también pertenece a \\(\\mathcal{F}\\): \\[\n\\bigcup_{j \\in \\mathbb{N}} A_j \\in \\mathcal{F}\n\\]\n\n\n\nRecurriendo a propiedades básicas de conjuntos, no es difícil probar que si \\(\\mathcal{F}\\) es una \\(\\sigma-\\)álgebra tomada de un espacio muestral \\(\\Omega\\), entonces:\n\n\\(\\emptyset \\in \\mathcal{F}\\) y \\(\\Omega \\in \\mathcal{F}\\).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cup B \\in \\mathcal{F}\\)\n(de hecho, puede verse también que \\(\\mathcal{F}\\) es cerrado bajo un número finito de uniones).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cap B \\in \\mathcal{F}\\)\n(de hecho, puede verse también que \\(\\mathcal{F}\\) es cerrado bajo un número finito de intersecciones).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\setminus B \\in \\mathcal{F}\\).\nSi \\(A_j \\in \\mathcal{F}\\) para todo \\(j \\in \\mathbb{N}\\), entonces\n\\[\n\\bigcap_{j \\in \\mathbb{N}} A_j \\in \\mathcal{F}.\n\\]\n\n\n\n\n\nLa función \\(P : \\mathcal{F} \\to [0,1]\\) se llama medida de probabilidad sobre \\((\\Omega,\\mathcal{F})\\), y debe cumplir con las siguientes propiedades:\n\nNo negatividad y normalización: \\[\nP(A) \\geq 0 \\quad \\text{para todo } A \\in \\mathcal{F}, \\quad \\text{y} \\quad P(\\Omega) = 1\n\\]\nAditividad numerable: Si \\(\\{A_j\\}_{j \\in \\mathbb{N}}\\) es una familia de eventos disjuntos dos a dos (es decir, \\(A_i \\cap A_j = \\emptyset\\) si \\(i \\neq j\\)), entonces: \\[\nP\\left( \\bigcup_{j \\in \\mathbb{N}} A_j \\right) = \\sum_{j \\in \\mathbb{N}} P(A_j)\n\\]\n\n\n\nSea \\(P\\) una medida de probabilidad definida sobre \\((\\Omega, \\mathcal{F})\\). Entonces se cumple que:\n\n\\(P(\\emptyset) = 0\\)\nSi \\(A_1, A_2, \\ldots, A_n \\in \\mathcal{F}\\) y son disjuntos dos a dos, entonces:\n\\[\nP\\left( \\bigcup_{j=1}^n A_j \\right) = \\sum_{j=1}^n P(A_j)\n\\]\nSi \\(A \\in \\mathcal{F}\\), entonces:\n\\[\nP(A) + P(A^c) = 1\n\\]\nSi \\(A, B \\in \\mathcal{F}\\), entonces:\n\\[\nP(A) + P(B) = P(A \\cup B) + P(A \\cap B)\n\\]\nEn particular:\n\\[\nP(A \\cup B) \\leq P(A) + P(B)\n\\]\nSi \\(A, B \\in \\mathcal{F}\\) y \\(A \\subseteq B\\), entonces:\n\\[\nP(A) \\leq P(B)\n\\]\nPara eventos arbitrarios \\(A_1, \\ldots, A_n \\in \\mathcal{F}\\) (no necesariamente disjuntos), se cumple el principio de inclusión-exclusión:\n\\[\nP\\left( \\bigcup_{i=1}^n A_i \\right) =\n\\sum_{i=1}^n P(A_i)\n- \\sum_{i_1 &lt; i_2} P(A_{i_1} \\cap A_{i_2})\n+ \\sum_{i_1 &lt; i_2 &lt; i_3} P(A_{i_1} \\cap A_{i_2} \\cap A_{i_3})\n- \\cdots + (-1)^{n-1} P\\left( \\bigcap_{j=1}^n A_j \\right)\n\\]\n\n\n\n\n\nSea \\((\\Omega, \\mathcal{F}, P)\\) una tripleta donde:\n\n\\(\\Omega\\) es un conjunto no vacío.\n\\(\\mathcal{F}\\) es una \\(\\sigma\\)-álgebra de subconjuntos de \\(\\Omega\\).\n\\(P : \\mathcal{F} \\to [0,1]\\) es una medida de probabilidad sobre \\((\\Omega, \\mathcal{F})\\).\n\nEste conjunto \\((\\Omega, \\mathcal{F}, P)\\) es lo que se conoce como un espacio de probabilidad. A partir de esta estructura, se puede desarrollar toda la teoría moderna de la probabilidad, tanto para espacios finitos como infinitos."
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html#probabilidad-clásica",
    "href": "cursos/CA0721/intro_proba_CA0721.html#probabilidad-clásica",
    "title": "intro_proba_CA0721",
    "section": "Probabilidad clásica",
    "text": "Probabilidad clásica\nSi \\(A\\) es un evento, se define la probabilidad clásica de \\(A\\) como:\n\\[\nP(A) = \\frac{|A|}{|\\Omega|}\n\\]\ndonde \\(|A|\\) representa el número de elementos del conjunto \\(A\\).\n\n\nPropiedades fundamentales\nSupongamos que \\(|\\Omega| = N\\). Entonces:\n\n\\(P(\\Omega) = 1\\), \\(P(\\emptyset) = 0\\)\nSi \\(A \\subseteq \\Omega\\) y \\(|A| = N - n\\), entonces \\(|A^c| = n\\) y \\(P(A^c) = 1 - P(A)\\)\nSi \\(A \\cap B = \\emptyset\\), se cumple:\n\\[\n|A \\cup B| = |A| + |B| \\quad \\Rightarrow \\quad P(A \\cup B) = P(A) + P(B)\n\\]\nEn general, si \\(A_1, A_2, \\ldots, A_n\\) son disjuntos dos a dos:\n\\[\nP\\left(\\bigcup_{i=1}^n A_i\\right) = \\sum_{i=1}^n P(A_i)\n\\]\n\n\nEsta propiedad se conoce como aditividad finita."
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html#espacios-finitos-y-medidas-de-probabilidad",
    "href": "cursos/CA0721/intro_proba_CA0721.html#espacios-finitos-y-medidas-de-probabilidad",
    "title": "Introducción a la Probabilidad",
    "section": "Espacios finitos y medidas de probabilidad",
    "text": "Espacios finitos y medidas de probabilidad\nUna medida de probabilidad sobre un espacio finito es una función \\(P\\) definida en subconjuntos de \\(\\Omega\\), tal que:\n\n\\(P(\\Omega) = 1\\)\nSi \\(A, B \\subseteq \\Omega\\) y \\(A \\cap B = \\emptyset\\), entonces:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\n\n\nPrincipio de inclusión-exclusión\nPara eventos \\(A_1, \\ldots, A_n\\), se tiene:\n\\[\nP\\left(\\bigcup_{i=1}^n A_i\\right) = \\sum_{i=1}^n P(A_i)\n- \\sum_{i_1&lt;i_2} P(A_{i_1} \\cap A_{i_2})\n+ \\sum_{i_1&lt;i_2&lt;i_3} P(A_{i_1} \\cap A_{i_2} \\cap A_{i_3})\n- \\cdots + (-1)^{n-1} P\\left(\\bigcap_{j=1}^n A_j\\right)\n\\]"
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html#probabilidad-condicional-e-independencia",
    "href": "cursos/CA0721/intro_proba_CA0721.html#probabilidad-condicional-e-independencia",
    "title": "Introducción a la Probabilidad",
    "section": "Probabilidad condicional e independencia",
    "text": "Probabilidad condicional e independencia\n\nProbabilidad condicional\nDado un evento \\(B\\) tal que \\(P(B) &gt; 0\\), se define la probabilidad de \\(A\\) dado \\(B\\) como:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\nTambién se tiene:\n\\[\nP(B \\mid A) = \\frac{P(B \\cap A)}{P(A)} = \\frac{P(A \\cap B)}{P(A)}\n\\]\n\n\n\nIndependencia de eventos\nSe dice que dos eventos \\(A\\) y \\(B\\) son independientes si:\n\\[\nP(A \\cap B) = P(A) \\cdot P(B)\n\\]\n\nSi no se cumple la propiedad anterior, los eventos se dicen dependientes.\n\nTambién se define independencia de una familia de eventos \\((A_i)_{i \\in I}\\) como:\n\\[\nP\\left(\\bigcap_{j \\in J} A_j\\right) = \\prod_{j \\in J} P(A_j)\n\\]\npara todo subconjunto finito no vacío \\(J \\subseteq I\\)."
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html#fórmulas-fundamentales",
    "href": "cursos/CA0721/intro_proba_CA0721.html#fórmulas-fundamentales",
    "title": "Introducción a la Probabilidad",
    "section": "Fórmulas fundamentales",
    "text": "Fórmulas fundamentales\n\nTeorema de la probabilidad total\nSi \\(\\{E_1, \\ldots, E_n\\}\\) es una partición del espacio muestral \\(\\Omega\\) (eventos mutuamente excluyentes y exhaustivos), entonces:\n\\[\nP(A) = \\sum_{i=1}^n P(A \\cap E_i) = \\sum_{i=1}^n P(A \\mid E_i) P(E_i)\n\\]\n\n\n\nFórmula de Bayes\nPara calcular la probabilidad de un evento \\(E_i\\) dado que ocurrió \\(A\\):\n\\[\nP(E_i \\mid A) = \\frac{P(E_i \\cap A)}{P(A)} = \\frac{P(A \\mid E_i) P(E_i)}{\\sum_{k=1}^n P(A \\mid E_k) P(E_k)}\n\\]"
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html#modelo-de-probabilidad-de-laplace",
    "href": "cursos/CA0721/intro_proba_CA0721.html#modelo-de-probabilidad-de-laplace",
    "title": "Introducción a la Probabilidad",
    "section": "Modelo de probabilidad de Laplace",
    "text": "Modelo de probabilidad de Laplace\nCuando el espacio muestral \\(\\Omega\\) es finito, se puede considerar que todos los resultados son igualmente probables. A este modelo se le conoce como modelo de probabilidad de Laplace o también como probabilidad clásica.\nEn este contexto, se asigna la misma probabilidad a cada resultado \\(\\omega \\in \\Omega\\), de modo que:\n\\[\nP(\\{\\omega\\}) = \\frac{1}{|\\Omega|}\n\\]\ndonde \\(|\\Omega|\\) denota la cantidad total de posibles resultados.\n\nDe forma general, si \\(A\\) es un evento (es decir, un subconjunto de \\(\\Omega\\)), su probabilidad se define como el cociente entre la cantidad de resultados favorables (elementos de \\(A\\)) y la cantidad total de posibles resultados:\n\\[\nP(A) = \\frac{|A|}{|\\Omega|}\n\\]\nEsta definición supone que todos los resultados tienen la misma probabilidad y es válida únicamente cuando el número de resultados posibles es finito y equiprobable.\n\n\nNota: Este modelo es un caso particular de lo que más adelante definiremos como una medida de probabilidad sobre una colección de eventos \\(\\mathcal{F}\\). Por ahora, basta con tener una comprensión intuitiva: el modelo de Laplace asigna igual peso a todos los elementos de \\(\\Omega\\) y calcula la probabilidad de un evento \\(A\\) como la proporción de casos favorables respecto al total."
  },
  {
    "objectID": "cursos/CA0721/teoria_general_proba_CA0721.html#espacios-finitos-y-medidas-de-probabilidad",
    "href": "cursos/CA0721/teoria_general_proba_CA0721.html#espacios-finitos-y-medidas-de-probabilidad",
    "title": "Teoría General de Probabilidades",
    "section": "Espacios finitos y medidas de probabilidad",
    "text": "Espacios finitos y medidas de probabilidad\nUna medida de probabilidad sobre un espacio finito es una función \\(P\\) definida en subconjuntos de \\(\\Omega\\), tal que:\n\n\\(P(\\Omega) = 1\\)\nSi \\(A, B \\subseteq \\Omega\\) y \\(A \\cap B = \\emptyset\\), entonces:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\n\nPrincipio de inclusión-exclusión\nPara eventos \\(A_1, \\ldots, A_n\\), se tiene:\n\\[\nP\\left(\\bigcup_{i=1}^n A_i\\right) = \\sum_{i=1}^n P(A_i)\n- \\sum_{i_1&lt;i_2} P(A_{i_1} \\cap A_{i_2})\n+ \\sum_{i_1&lt;i_2&lt;i_3} P(A_{i_1} \\cap A_{i_2} \\cap A_{i_3})\n- \\cdots + (-1)^{n-1} P\\left(\\bigcap_{j=1}^n A_j\\right)\n\\]"
  },
  {
    "objectID": "cursos/CA0721/teoria_general_proba_CA0721.html#probabilidad-condicional-e-independencia",
    "href": "cursos/CA0721/teoria_general_proba_CA0721.html#probabilidad-condicional-e-independencia",
    "title": "Teoría General de Probabilidades",
    "section": "Probabilidad condicional e independencia",
    "text": "Probabilidad condicional e independencia\n\nProbabilidad condicional\nSean \\(A, B\\) dos eventos en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) con \\(P(B) &gt; 0\\). La probabilidad condicional de \\(A\\) dado \\(B\\) viene dada por:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\nTambién se tiene:\n\\[\nP(B \\mid A) = \\frac{P(B \\cap A)}{P(A)} = \\frac{P(A \\cap B)}{P(A)}\n\\]\n\n\nIndependencia de eventos\nSean \\(A, B\\) dos eventos en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\). Se dice que \\(A\\) y \\(B\\) son independientes si:\n\\[\nP(A \\cap B) = P(A) \\cdot P(B)\n\\]\n\nSi no se cumple la propiedad anterior, los eventos se dicen dependientes.\n\nTambién se define independencia de una familia de eventos \\((A_i)_{i \\in I}\\) en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) como:\n\\[\nP\\left(\\bigcap_{j \\in J} A_j\\right) = \\prod_{j \\in J} P(A_j)\n\\]\npara todo subconjunto finito no vacío \\(J \\subseteq I\\)."
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html#independencia-de-eventos",
    "href": "cursos/CA0721/intro_proba_CA0721.html#independencia-de-eventos",
    "title": "Introducción a la Probabilidad",
    "section": "Independencia de eventos",
    "text": "Independencia de eventos\nSe dice que dos eventos \\(A\\) y \\(B\\) son independientes si:\n\\[\nP(A \\cap B) = P(A) \\cdot P(B)\n\\]\n\nSi no se cumple la propiedad anterior, los eventos se dicen dependientes.\n\nTambién se define independencia de una familia de eventos \\((A_i)_{i \\in I}\\) como:\n\\[\nP\\left(\\bigcap_{j \\in J} A_j\\right) = \\prod_{j \\in J} P(A_j)\n\\]\npara todo subconjunto finito no vacío \\(J \\subseteq I\\)."
  },
  {
    "objectID": "cursos/CA0721/teoria_general_proba_CA0721.html#experimentos-aleatorios-y-espacio-de-probabilidad",
    "href": "cursos/CA0721/teoria_general_proba_CA0721.html#experimentos-aleatorios-y-espacio-de-probabilidad",
    "title": "Teoría General de Probabilidades",
    "section": "",
    "text": "Hasta ahora hemos trabajado con la probabilidad en contextos finitos y simples, donde todos los resultados son igualmente probables (modelo de Laplace). Sin embargo, para desarrollar una teoría más general de la probabilidad, necesitamos una base más formal.\nUn experimento aleatorio es un proceso cuyo resultado no se puede predecir con certeza, pero cuyo conjunto de resultados posibles puede describirse. A cada experimento aleatorio le asociamos tres componentes fundamentales:\n\nUn espacio muestral \\(\\Omega\\): el conjunto de todos los posibles resultados del experimento.\nUn conjunto de eventos \\(\\mathcal{F}\\): una colección de subconjuntos de \\(\\Omega\\), considerados como los eventos del experimento.\nUna función de probabilidad \\(P\\): que asigna a cada evento \\(A \\in \\mathcal{F}\\) un número entre \\(0\\) y \\(1\\), representando la probabilidad de que ese evento ocurra.\n\n\n\nPara que el conjunto de eventos \\(\\mathcal{F}\\) sea adecuado, debe cumplir ciertas propiedades. A esto se le llama una \\(\\sigma\\)-álgebra de subconjuntos, y garantiza que podamos hacer operaciones como complementos, uniones y demás, sin salirnos del conjunto de eventos válidos.\nFormalmente, \\(\\mathcal{F}\\) es una \\(\\sigma-\\)álgebra sobre \\(\\Omega\\) si:\n\n\\(\\mathcal{F}\\) no es vacío.\nSi \\(A \\in \\mathcal{F}\\), entonces su complemento también está en \\(\\mathcal{F}\\): \\[\nA^c = \\Omega \\setminus A \\in \\mathcal{F}\n\\]\nSi \\(A_1, A_2, A_3, \\dots \\in \\mathcal{F}\\), entonces la unión infinita también pertenece a \\(\\mathcal{F}\\): \\[\n\\bigcup_{j \\in \\mathbb{N}} A_j \\in \\mathcal{F}\n\\]\n\n\n\nRecurriendo a propiedades básicas de conjuntos, no es difícil probar que si \\(\\mathcal{F}\\) es una \\(\\sigma-\\)álgebra tomada de un espacio muestral \\(\\Omega\\), entonces:\n\n\\(\\emptyset \\in \\mathcal{F}\\) y \\(\\Omega \\in \\mathcal{F}\\).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cup B \\in \\mathcal{F}\\)\n(de hecho, puede verse también que \\(\\mathcal{F}\\) es cerrado bajo un número finito de uniones).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cap B \\in \\mathcal{F}\\)\n(de hecho, puede verse también que \\(\\mathcal{F}\\) es cerrado bajo un número finito de intersecciones).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\setminus B \\in \\mathcal{F}\\).\nSi \\(A_j \\in \\mathcal{F}\\) para todo \\(j \\in \\mathbb{N}\\), entonces\n\\[\n\\bigcap_{j \\in \\mathbb{N}} A_j \\in \\mathcal{F}.\n\\]\n\n\n\n\n\nLa función \\(P : \\mathcal{F} \\to [0,1]\\) se llama medida de probabilidad sobre \\((\\Omega,\\mathcal{F})\\), y debe cumplir con las siguientes propiedades:\n\nNo negatividad y normalización: \\[\nP(A) \\geq 0 \\quad \\text{para todo } A \\in \\mathcal{F}, \\quad \\text{y} \\quad P(\\Omega) = 1\n\\]\nAditividad numerable: Si \\(\\{A_j\\}_{j \\in \\mathbb{N}}\\) es una familia de eventos disjuntos dos a dos (es decir, \\(A_i \\cap A_j = \\emptyset\\) si \\(i \\neq j\\)), entonces: \\[\nP\\left( \\bigcup_{j \\in \\mathbb{N}} A_j \\right) = \\sum_{j \\in \\mathbb{N}} P(A_j)\n\\]\n\n\n\nSea \\(P\\) una medida de probabilidad definida sobre \\((\\Omega, \\mathcal{F})\\). Entonces se cumple que:\n\n\\(P(\\emptyset) = 0\\)\nSi \\(A_1, A_2, \\ldots, A_n \\in \\mathcal{F}\\) y son disjuntos dos a dos, entonces:\n\\[\nP\\left( \\bigcup_{j=1}^n A_j \\right) = \\sum_{j=1}^n P(A_j)\n\\]\nSi \\(A \\in \\mathcal{F}\\), entonces:\n\\[\nP(A) + P(A^c) = 1\n\\]\nSi \\(A, B \\in \\mathcal{F}\\), entonces:\n\\[\nP(A) + P(B) = P(A \\cup B) + P(A \\cap B)\n\\]\nEn particular:\n\\[\nP(A \\cup B) \\leq P(A) + P(B)\n\\]\nSi \\(A, B \\in \\mathcal{F}\\) y \\(A \\subseteq B\\), entonces:\n\\[\nP(A) \\leq P(B)\n\\]\nPara eventos arbitrarios \\(A_1, \\ldots, A_n \\in \\mathcal{F}\\) (no necesariamente disjuntos), se cumple el principio de inclusión-exclusión:\n\\[\nP\\left( \\bigcup_{i=1}^n A_i \\right) =\n\\sum_{i=1}^n P(A_i)\n- \\sum_{i_1 &lt; i_2} P(A_{i_1} \\cap A_{i_2})\n+ \\sum_{i_1 &lt; i_2 &lt; i_3} P(A_{i_1} \\cap A_{i_2} \\cap A_{i_3})\n- \\cdots + (-1)^{n-1} P\\left( \\bigcap_{j=1}^n A_j \\right)\n\\]\n\n\n\n\n\nSea \\((\\Omega, \\mathcal{F}, P)\\) una tripleta donde:\n\n\\(\\Omega\\) es un conjunto no vacío.\n\\(\\mathcal{F}\\) es una \\(\\sigma\\)-álgebra de subconjuntos de \\(\\Omega\\).\n\\(P : \\mathcal{F} \\to [0,1]\\) es una medida de probabilidad sobre \\((\\Omega, \\mathcal{F})\\).\n\nEste conjunto \\((\\Omega, \\mathcal{F}, P)\\) es lo que se conoce como un espacio de probabilidad. A partir de esta estructura, se puede desarrollar toda la teoría moderna de la probabilidad, tanto para espacios finitos como infinitos."
  },
  {
    "objectID": "cursos/CA0721/teoria_general_proba_CA0721.html#fórmulas-fundamentales",
    "href": "cursos/CA0721/teoria_general_proba_CA0721.html#fórmulas-fundamentales",
    "title": "Teoría General de Probabilidades",
    "section": "Fórmulas fundamentales",
    "text": "Fórmulas fundamentales\nSea \\((\\Omega, \\mathcal{F}, P)\\) un espacio de probabilidad.\nDecimos que una colección \\(\\{E_i\\}_{i \\in \\mathbb{N}} \\subseteq \\mathcal{F}\\) es una partición de \\(\\Omega\\) si cumple que:\n\n\\(\\displaystyle \\bigcup_{i \\in \\mathbb{N}} E_i = \\Omega\\)\n\\(E_i \\cap E_j = \\emptyset\\) para todo \\(i \\ne j\\)\n\n\nTeorema de la probabilidad total\nSi \\(\\{E_i\\}_{i \\in \\mathbb{N}}\\) es una partición de \\((\\Omega, \\mathcal{F}, P)\\) y \\(B \\in \\mathcal{F}\\), entonces:\n\\[\nP(B) = \\sum_{i \\in \\mathbb{N}} P(B \\cap E_i)\n\\]\nSi además \\(P(E_i) &gt; 0\\) para todo \\(i\\), se tiene la versión condicional:\n\\[\nP(B) = \\sum_{i \\in \\mathbb{N}} P(B \\mid E_i) \\, P(E_i)\n\\]\n\n\nFórmula de Bayes\nSean \\(A, B \\in \\mathcal{F}\\) con \\(P(A), P(B) &gt; 0\\). Entonces:\n\\[\nP(B \\mid A) = \\frac{P(B)}{P(A)} \\cdot P(A \\mid B)\n\\]\nMás generalmente, si \\(\\{E_i\\}_{i \\in \\mathbb{N}}\\) es una partición de \\(\\Omega\\) con \\(P(E_i) &gt; 0\\) y \\(B \\in \\mathcal{F}\\) tal que \\(P(B) &gt; 0\\), se cumple:\n\\[\nP(E_k \\mid B) = \\frac{P(B \\mid E_k) \\, P(E_k)}{\\sum\\limits_{i \\in \\mathbb{N}} P(B \\mid E_i) \\, P(E_i)}\n\\]\n\n\nDesigualdad de Boole\nSi \\(\\{A_n\\}_{n \\in \\mathbb{N}}\\) es una familia de eventos en \\((\\Omega, \\mathcal{F}, P)\\), entonces:\n\\[\nP\\left( \\bigcup_{n \\in \\mathbb{N}} A_n \\right) \\leq \\sum_{n \\in \\mathbb{N}} P(A_n)\n\\]\n\n\nContinuidad de la probabilidad\nSea \\(\\{A_n\\}_{n \\in \\mathbb{N}}\\) una sucesión de eventos en \\((\\Omega, \\mathcal{F}, P)\\).\n\nCreciente\n\\[\nA_n \\subseteq A_{n+1} \\;\\;\\forall n\\quad\\implies\\quad P\\left( \\bigcup_{n \\in \\mathbb{N}} A_n \\right) = \\lim_{n \\to \\infty} P(A_n)\n\\]\nDecreciente\n\\[\nA_{n+1} \\subseteq A_n\\;\\;\\forall n\\quad\\implies\\quad P\\left( \\bigcap_{n \\in \\mathbb{N}} A_n \\right) = \\lim_{n \\to \\infty} P(A_n)\n\\]\n\n\n\nLemas de Borel–Cantelli\nSea \\(\\{A_n\\}_{n \\in \\mathbb{N}}\\) una sucesión de eventos en \\((\\Omega, \\mathcal{F}, P)\\). Denotamos:\n\\[\n\\{A_n \\text{ i.o.}\\} := \\bigcap_{n=1}^{\\infty} \\bigcup_{k = n}^{\\infty} A_k\n\\]\n\nNota: La notación “\\(A_n\\) i.o.” proviene del inglés infinitely often, y se refiere al evento de que ocurran infinitamente muchos de los eventos \\(A_n\\). Es decir, que sin importar cuán lejos avancemos en la sucesión, siempre habrá algunos \\(A_k\\) con \\(k &gt; n\\) que se cumplan.\nIntuitivamente, \\(A_n\\) ocurre infinitas veces si, a partir de cierto punto, sigue ocurriendo de forma repetida (aunque no necesariamente de forma continua).\n\n\nPrimer lema de Borel–Cantelli:\n\\[\n\\sum\\limits_{n=1}^\\infty P(A_n) &lt; \\infty \\quad\\implies\\quad P(A_n \\text{ i.o.}) = 0\n\\]\nSegundo lema de Borel–Cantelli:\n\\[\n\\left.\\begin{array} AA_n \\text{ son independientes} \\\\ \\sum\\limits_{n=1}^\\infty P(A_n) = \\infty \\end{array}\\right\\}\\quad\\implies\\quad P(A_n \\text{ i.o.}) = 1\n\\]"
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html",
    "title": "Variables Aleatorias",
    "section": "",
    "text": "Una variable aleatoria (v.a.) en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) es una función\n\\[\nX : \\Omega \\to \\mathbb{R} \\quad \\text{tal que} \\quad X^{-1}(B) \\in \\mathcal{F} \\quad \\text{para todo } B \\in \\mathcal{B}(\\mathbb{R})\n\\]\ndonde \\(\\mathcal{B}(\\mathbb{R})\\) denota la \\(\\sigma\\)-álgebra de Borel en \\(\\mathbb{R}\\), es decir, la \\(\\sigma\\)-álgebra generada por todos los conjuntos abiertos de \\(\\mathbb{R}\\).\n\nNota: La escogencia de la \\(\\sigma\\)-álgebra de Borel puede parecer extraña, pero gracias a ella se podrán calcular probabilidades de eventos de interés. En efecto, como consecuencia de esta definición de variable aleatoria se tiene que:\n\n\\(\\{X &lt; a\\} = \\{\\omega \\in \\Omega : X(\\omega) &lt; a\\} \\in \\mathcal{F}\\) para todo \\(a \\in \\mathbb{R}\\)\n\\(\\{X \\leq a\\} \\in \\mathcal{F}\\) para todo \\(a \\in \\mathbb{R}\\)\nPara todo \\(a &lt; b\\), los siguientes eventos también están en \\(\\mathcal{F}\\): \\[\n\\{a &lt; X \\leq b\\},\\quad \\{a &lt; X &lt; b\\},\\quad \\{a \\leq X &lt; b\\},\\quad \\{a \\leq X \\leq b\\}\n\\]\n\n\n\n\nPara que \\(X\\) sea una variable aleatoria, basta que:\n\\[\n\\{X &lt; a\\} \\in \\mathcal{F} \\quad \\text{para todo } a \\in \\mathbb{R}\n\\]\nEsta condición es suficiente y también necesaria. Además, puede reemplazarse \\(\\{X &lt; a\\}\\) por cualquiera de los siguientes conjuntos sin cambiar la validez del resultado:\n\n\\(\\{X \\leq a\\}\\), \\(\\{X &gt; a\\}\\), \\(\\{X \\geq a\\}\\)\n\n\n\n\nSean \\(X\\) y \\(Y\\) variables aleatorias reales sobre \\((\\Omega, \\mathcal{F}, P)\\). Entonces:\n\nPara todo \\(a, b \\in \\mathbb{R}\\), \\(aX + bY\\) es una variable aleatoria.\n\\(\\min\\{X, Y\\}\\) y \\(\\max\\{X, Y\\}\\) son variables aleatorias.\nSi \\(g : \\mathbb{R} \\to \\mathbb{R}\\) es continua, entonces \\(g(X)\\) también es una variable aleatoria.\n\n\n\n\nSi \\(\\{X_n\\}_{n \\in \\mathbb{N}}\\) es una sucesión de variables aleatorias, entonces:\n\n\\(\\inf\\limits_{n \\in \\mathbb{N}} X_n\\), \\(\\sup\\limits_{n \\in \\mathbb{N}} X_n\\) son variables aleatorias.\n\\(\\liminf X_n\\), \\(\\limsup X_n\\) también son variables aleatorias."
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#definición",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#definición",
    "title": "Variables Aleatorias",
    "section": "",
    "text": "Una variable aleatoria (v.a.) en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) es una función\n\\[\nX : \\Omega \\to \\mathbb{R} \\quad \\text{tal que} \\quad X^{-1}(B) \\in \\mathcal{F} \\quad \\text{para todo } B \\in \\mathcal{B}(\\mathbb{R})\n\\]\ndonde \\(\\mathcal{B}(\\mathbb{R})\\) denota la \\(\\sigma\\)-álgebra de Borel en \\(\\mathbb{R}\\), es decir, la \\(\\sigma\\)-álgebra generada por todos los conjuntos abiertos de \\(\\mathbb{R}\\).\n\nNota: La escogencia de la \\(\\sigma\\)-álgebra de Borel puede parecer extraña, pero gracias a ella se podrán calcular probabilidades de eventos de interés. En efecto, como consecuencia de esta definición de variable aleatoria se tiene que:\n\n\\(\\{X &lt; a\\} = \\{\\omega \\in \\Omega : X(\\omega) &lt; a\\} \\in \\mathcal{F}\\) para todo \\(a \\in \\mathbb{R}\\)\n\\(\\{X \\leq a\\} \\in \\mathcal{F}\\) para todo \\(a \\in \\mathbb{R}\\)\nPara todo \\(a &lt; b\\), los siguientes eventos también están en \\(\\mathcal{F}\\): \\[\n\\{a &lt; X \\leq b\\},\\quad \\{a &lt; X &lt; b\\},\\quad \\{a \\leq X &lt; b\\},\\quad \\{a \\leq X \\leq b\\}\n\\]\n\n\n\n\nPara que \\(X\\) sea una variable aleatoria, basta que:\n\\[\n\\{X &lt; a\\} \\in \\mathcal{F} \\quad \\text{para todo } a \\in \\mathbb{R}\n\\]\nEsta condición es suficiente y también necesaria. Además, puede reemplazarse \\(\\{X &lt; a\\}\\) por cualquiera de los siguientes conjuntos sin cambiar la validez del resultado:\n\n\\(\\{X \\leq a\\}\\), \\(\\{X &gt; a\\}\\), \\(\\{X \\geq a\\}\\)\n\n\n\n\nSean \\(X\\) y \\(Y\\) variables aleatorias reales sobre \\((\\Omega, \\mathcal{F}, P)\\). Entonces:\n\nPara todo \\(a, b \\in \\mathbb{R}\\), \\(aX + bY\\) es una variable aleatoria.\n\\(\\min\\{X, Y\\}\\) y \\(\\max\\{X, Y\\}\\) son variables aleatorias.\nSi \\(g : \\mathbb{R} \\to \\mathbb{R}\\) es continua, entonces \\(g(X)\\) también es una variable aleatoria.\n\n\n\n\nSi \\(\\{X_n\\}_{n \\in \\mathbb{N}}\\) es una sucesión de variables aleatorias, entonces:\n\n\\(\\inf\\limits_{n \\in \\mathbb{N}} X_n\\), \\(\\sup\\limits_{n \\in \\mathbb{N}} X_n\\) son variables aleatorias.\n\\(\\liminf X_n\\), \\(\\limsup X_n\\) también son variables aleatorias."
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#funciones-de-distribución",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#funciones-de-distribución",
    "title": "Variables Aleatorias",
    "section": "Funciones de distribución",
    "text": "Funciones de distribución\nSea \\(X\\) una variable aleatoria real en un espacio \\((\\Omega, \\mathcal{F}, P)\\).\nLa función de distribución (acumulada) de \\(X\\) es la función \\(F_X : \\mathbb{R} \\to [0,1]\\) definida por:\n\\[\nF_X(t) = P(X \\leq t)\n\\]\n\nPropiedades\n\n\\(F_X(t) \\in [0, 1]\\) para todo \\(t \\in \\mathbb{R}\\)\n\\(F_X\\) es monótona creciente y en particular \\(\\forall t \\in \\mathbb{R}\\)\n\\[F_X(t^-) = \\lim\\limits_{x \\to t^-}F_X(x)\\] \\[F_X(t^+) = \\lim\\limits_{x \\to t^+}F_X(x)\\] \\[\nP [X&lt;t] = F_X(t^-) \\leq F_X(t) \\leq F_X(t^+)\n\\]\nAdemás:\n\\[\n\\lim_{t \\to -\\infty} F_X(t) = 0 \\quad \\text{y} \\quad \\lim_{t \\to +\\infty} F_X(t) = 1\n\\]"
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#variables-aleatorias-discretas",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#variables-aleatorias-discretas",
    "title": "Variables Aleatorias",
    "section": "Variables aleatorias discretas",
    "text": "Variables aleatorias discretas\nUna variable aleatoria \\(X\\) es discreta si existe un subconjunto numerable \\(N \\subseteq \\mathbb{R}\\) tal que:\n\\[\nP(\\Omega) = \\sum_{n \\in N} P(X = n)\n\\]\nPara estas variables, la función:\n\\[\np_X(n) = P(X = n), \\quad n \\in \\mathbb{N}\n\\]\nse llama función de masa de probabilidad de \\(X\\).\n\n\n\n\n\n\nTeorema: Existencia de variables aleatorias discretas\n\n\n\nSea \\(S = \\{s_j : j \\in I\\}\\) un conjunto finito o numerable, y sea \\(\\{\\pi_j : j \\in I\\}\\) una colección de números reales tal que:\n\n\\(\\pi_j \\geq 0\\) para todo \\(j \\in I\\)\n\\(\\displaystyle \\sum_{j \\in I} \\pi_j = 1\\)\n\nEntonces existe un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) y una variable aleatoria \\(X\\) en \\((\\Omega, \\mathcal{F}, P)\\) tal que la función de masa de probabilidad de \\(X\\) cumple:\n\\[\nP(X = s_j) = \\pi_j \\quad \\text{si } j \\in I, \\qquad\nP(X = s) = 0 \\quad \\text{si } s \\notin S\n\\]\n\n\n\nFunción de distribución\nSi \\(X\\) es una variable aleatoria discreta con función de probabilidad \\(f_X(x)\\), entonces la función de distribución acumulada se calcula como:\n\\[\nF_X(x) = P[X \\leq x] = \\sum_{u \\leq x} P[X = u]\n\\]\n\n\nTransformaciones\nSea \\(X\\) una v.a. discreta en un e.p \\((\\Omega, \\mathcal{F}, P)\\) y sea \\(g : \\mathbb{R} \\to \\mathbb{R}\\) una función. \\(Y = g(X)\\) es una v.a. La función de masa de \\(Y\\) se calcula de la siguiente manera:\n\\[\\begin{align*}\nP_Y(y) &= P_X(g(X) = y) \\\\\n&= P_X(X \\in g^{-1}(y)) \\\\\n&=\n\\begin{cases}\n0 & \\text{si } y \\notin \\text{Im}(g(X)) \\\\\n\\sum\\limits_{x \\in g^{-1}(y)} P[X = x] & \\text{si } y \\in \\text{Im}(g(X))\n\\end{cases}\n\\end{align*}\\]\n\n\nEsperanza\nSean \\(n\\) los valores que toma \\(X\\). Se define:\n\\[\n\\mathbb{E}[X] = \\sum_{n \\in \\text{Im}(X)} n \\cdot P[X = n]\n\\]\nSiempre y cuando la anterior suma, en caso de ser una serie, converja absolutamente.\n\nPropiedades\nSi \\(X, Y\\) son variables aleatorias en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) y \\(a, b \\in \\mathbb{R}\\):\n\nLinealidad de la esperanza:\n\n\\[\n\\mathbb{E}[aX + bY] = a \\cdot \\mathbb{E}[X] + b \\cdot \\mathbb{E}[Y]\n\\]\n\nSi \\(g(X)\\) y \\(h(Y)\\) son funciones de \\(X\\) y \\(Y\\) respectivamente, entonces:\n\n\\[\n\\mathbb{E}[g(X) + h(Y)] = \\mathbb{E}[g(X)] + \\mathbb{E}[h(Y)]\n\\]\n\n\n\nLey del estadístico inconsciente\nSi \\(X\\) es una v.a. discreta en un e.p. \\((\\Omega, \\mathcal{F}, P)\\) y sea \\(g : \\mathbb{R} \\to \\mathbb{R}\\) una función tal que\n\\[\n\\sum_{n \\in \\text{Im}(X)} \\left| g(n) \\right| \\cdot P[X = n]\n\\]\nes finita, entonces\n\\[\n\\mathbb{E}[g(x)] = \\sum_{n \\in \\text{Im}(X)} g(n) \\cdot P[X = n]\n\\]\n\nNota: No ocupa la función de masa de \\(g(x)\\) para calcular \\(\\mathbb{E}[g(x)]\\)\n\n\n\nMomentos y Varianza\nSea \\(X\\) una v.a. discreta en un e.p \\((\\Omega, \\mathcal{F}, P)\\) y sea \\(n &gt; 0\\):\n\nEl \\(n\\)–ésimo momento de \\(X\\) se define como \\(\\mathbb{E}[X^n]\\)\nSi \\(\\mu = \\mathbb{E}[X]\\), el \\(n\\)–ésimo momento centrado se define como:\n\n\\[\n\\mathbb{E}\\left[(X - \\mu)^n\\right]\n\\]\n\nEl segundo momento centrado es particularmente importante:\n\nLa varianza de \\(X\\), denotada \\(\\operatorname{Var}[X]\\), se calcula así:\n\n\n\\[\\begin{align*}\n\\operatorname{Var}[X] &= \\mathbb{E} \\left[(X - \\mu)^2 \\right]\\\\\n&= \\sum_{n \\in \\mathbb{N}} (n - \\mu)^2 \\cdot P_X(X = n)\n\\end{align*}\\]\nSiempre que la anterior suma sea finita.\n\nNota: Es posible mostrar que si \\(\\mathbb{E}[X^2] &lt; \\infty\\), entonces:\n\n\\[\n\\operatorname{Var}[X] = \\mathbb{E}[X^2] - \\mu^2\n\\]\n\nPropiedades de la varianza\nSean \\(X\\) e \\(Y\\) dos variables aleatorias y sea \\(c\\) una constante, entonces:\n\n\\(\\operatorname{Var}(c) = 0\\)\n\\(\\operatorname{Var}(X + c) = \\operatorname{Var}(X)\\)\n\\(\\operatorname{Var}(cX) = c^2 \\cdot \\operatorname{Var}(X)\\)\nSi \\(X\\) e \\(Y\\) son variables aleatorias independientes, entonces:\n\n\\[\n\\operatorname{Var}(X + Y) = \\operatorname{Var}(X) + \\operatorname{Var}(Y)\n\\]\n\n\n\nDesviación estándar\nSea \\(X\\) una variable aleatoria discreta, se define la desviación estándar o típica de \\(X\\) por:\n\\[\n\\sigma_X = \\sqrt{\\operatorname{Var}(X)}\n\\]\n\n\nFórmula de convolución discreta\nSean \\(X, Y\\) (v.a) discretas e independientes en un e.p \\((\\Omega, \\mathcal{F}, P)\\).\nEntonces, la función de probabilidad de masa de la v.a \\(Z = X + Y\\) viene dada por:\n\\[\nP_Z(z) = \\sum_{x \\in \\text{Im}(X)} P_X(x) P_Y(z - x)\n\\]\nY además:\n\\[\n\\varphi_{X + Y}(t) = \\varphi_X(t) \\varphi_Y(t) \\quad \\forall t \\in \\mathbb{R}\n\\]\nDe hecho, una fórmula similar aplica para las funciones generadoras de momentos y generadoras de probabilidades. Aunque en estos casos dicha fórmula solo sería válida para todos los valores de \\(t\\) donde estas funciones estén definidas.\n\n\nFunciones importantes\nSea \\(X\\) una (v.a) discreta en un e.p \\((\\Omega, \\mathcal{F}, P)\\)\n\n\n\n\n\n\nFunción característica\n\n\n\n\\[\n\\varphi_X(t) = \\mathbb{E}[e^{itX}] = \\sum_{n \\in \\text{Im}(X)} e^{itn} \\cdot P[X = n]\n\\] Esta está definida para todo \\(t \\in \\mathbb{R}\\).\n\n\n\n\n\n\n\n\nFunción generadora de momentos\n\n\n\n\\[\nM_X(t) = \\mathbb{E}[e^{tX}] = \\sum_{n \\in \\text{Im}(X)} e^{tn} \\cdot P[X = n]\n\\] Para todos aquellos valores de \\(t\\) donde dicho valor esperado exista.\n\n\n\n\n\n\n\n\nFunción generadora de probabilidades\n\n\n\n\\[\nG_X(t) = \\mathbb{E}[t^X] = \\sum_{n \\in \\text{Im}(X)} t^n \\cdot P[X = n]\n\\] Para todos aquellos valores de \\(t\\) donde dicho valor esperado exista.\n\n\n\nNota: No lo vamos a probar, pero existe un teorema que dice que dos variables aleatorias \\(X, Y\\) tienen la misma distribución si y solo si \\(\\varphi_X = \\varphi_Y\\). Esto nos permite reconocer variables aleatorias.\n\n\n\n\nDistribuciones discretas comunes\n\n\n\n\n\n\nBernoulli\n\n\n\n\\[X \\sim \\text{Bernoulli}(p)\\]\n\n\\(\\begin{cases}P(X = 0) = 1 - p \\\\P(X = 1) = p\\end{cases}\\)\n\\(\\mathbb{E}[X] = p\\)\n\\(\\operatorname{Var}(X) = p(1 - p)\\)\n\nEste tipo de variable se suele usar en experimentos Bernoulli donde los resultados pueden etiquetarse como éxito o fracaso\n\n\n\n\n\n\n\n\nBinomial\n\n\n\n\\[X \\sim \\text{Bin}(n, p)\\]\n\n\\(P(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k}\\)\n\\(\\mathbb{E}[X] = n p\\)\n\\(\\operatorname{Var}(X) = n p (1 - p)\\)\n\nSe usa para modelar el número de éxitos en \\(n\\) ensayos independientes con probabilidad de éxito \\(p\\).\n\n\n\n\n\n\n\n\nBinomial negativa\n\n\n\n\\[X \\sim \\text{BN}(r, p)\\]\n\n\\(P(X = k) = \\binom{k + r - 1}{k} p^r (1 - p)^k\\), \\(k = 0, 1, 2, \\dots\\)\n\\(\\mathbb{E}[X] = \\dfrac{r(1 - p)}{p}\\)\n\\(\\operatorname{Var}(X) = \\dfrac{r(1 - p)}{p^2}\\)\n\nSe usa cuando se conoce el número de éxitos deseados (\\(r\\)) y se desea modelar el número de fracasos antes de lograrlos.\n\n\n\n\n\n\n\n\nGeométrica\n\n\n\n\\[X \\sim \\text{Geom}(p)\\]\n\n\\(P(X = n) = (1 - p)^{n - 1} p\\), \\(n = 1, 2, 3, \\dots\\)\n\\(\\mathbb{E}[X] = \\dfrac{1}{p}\\)\n\\(\\operatorname{Var}(X) = \\dfrac{1 - p}{p^2}\\)\n\nModela el número de intentos necesarios para obtener el primer éxito.\n\n\nCondición necesaria, note que: \\[\\begin{align*}\n        \\displaystyle\\sum^\\infty_{n=1}p_n &= p\\displaystyle\\sum^\\infty_{n=1}({1-p})^{n-1} = p\\displaystyle\\sum^\\infty_{k=0}({1-p})^k \\\\ &= \\frac{p}{1-({1-p})}=1\n    \\end{align*}\\]\n\n\n\n\n\n\nPoisson\n\n\n\n\\[X \\sim \\text{Poisson}(\\lambda)\\]\n\n\\(P(X = n) = \\dfrac{\\lambda^n e^{-\\lambda}}{n!}\\), \\(n = 0, 1, 2, \\dots\\)\n\\(\\mathbb{E}[X] = \\lambda\\)\n\\(\\operatorname{Var}(X) = \\lambda\\)\n\nSe usa para modelar el número de ocurrencias de un evento raro en un intervalo fijo de tiempo o espacio.\n\n\n\n\n\n\n\n\nHipergeométrica\n\n\n\n\\[X \\sim \\text{HG}(m + n, m, r)\\]\nUna variable \\(X\\) se llama hipergeométrica de parámetros \\(n\\), \\(m\\) y \\(r\\) si su distribución está dada por:\n\n\\(P[X = k] = \\frac{\\dbinom{m}{k} \\dbinom{n}{r - k}}{\\dbinom{m + n}{r}}\\)\n\\(\\mathbb{E}[X] = r \\cdot \\dfrac{m}{m + n}\\)\n\\(\\operatorname{Var}(X) = r \\cdot \\dfrac{m}{m + n} \\cdot \\dfrac{n}{m + n} \\cdot \\dfrac{m + n - r}{m + n - 1}\\)"
  }
]