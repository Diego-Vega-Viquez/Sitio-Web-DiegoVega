[
  {
    "objectID": "index_main.html",
    "href": "index_main.html",
    "title": "Diego Alberto Vega V√≠quez",
    "section": "",
    "text": "Bienvenido a mi sitio web personal. Este espacio ha sido creado como una plataforma para compartir mis apuntes, recursos y materiales de estudio a lo largo de mi formaci√≥n acad√©mica.\n\n\nEl prop√≥sito principal de esta p√°gina es organizar de forma clara y accesible mis apuntes de distintos cursos, permiti√©ndome consultarlos f√°cilmente desde cualquier lugar, as√≠ como compartirlos con otras personas interesadas en los temas que estudio.\nAqu√≠ encontrar√°s:\n\nüìö Apuntes por curso, organizados por tema.\nüßë‚Äçüíº Una breve secci√≥n sobre m√≠, con enlaces a mis redes profesionales.\nüîç Una estructura clara y navegable, pensada para facilitar el aprendizaje y la revisi√≥n.\n\n\n\n\nEn la barra superior de navegaci√≥n pod√©s acceder a:\n\nInicio (esta p√°gina)\nSobre m√≠ ‚Äì Una presentaci√≥n personal y formas de contacto\nCursos ‚Äì Acceso a los apuntes clasificados por materia\n\nGracias por visitar este espacio. ¬°Espero que el contenido te sea √∫til!"
  },
  {
    "objectID": "index_main.html#objetivo-del-sitio",
    "href": "index_main.html#objetivo-del-sitio",
    "title": "Diego Alberto Vega V√≠quez",
    "section": "",
    "text": "El prop√≥sito principal de esta p√°gina es organizar de forma clara y accesible mis apuntes de distintos cursos, permiti√©ndome consultarlos f√°cilmente desde cualquier lugar, as√≠ como compartirlos con otras personas interesadas en los temas que estudio.\nAqu√≠ encontrar√°s:\n\nüìö Apuntes por curso, organizados por tema.\nüßë‚Äçüíº Una breve secci√≥n sobre m√≠, con enlaces a mis redes profesionales.\nüîç Una estructura clara y navegable, pensada para facilitar el aprendizaje y la revisi√≥n."
  },
  {
    "objectID": "index_main.html#qu√©-pod√©s-explorar",
    "href": "index_main.html#qu√©-pod√©s-explorar",
    "title": "Diego Alberto Vega V√≠quez",
    "section": "",
    "text": "En la barra superior de navegaci√≥n pod√©s acceder a:\n\nInicio (esta p√°gina)\nSobre m√≠ ‚Äì Una presentaci√≥n personal y formas de contacto\nCursos ‚Äì Acceso a los apuntes clasificados por materia\n\nGracias por visitar este espacio. ¬°Espero que el contenido te sea √∫til!"
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html",
    "href": "cursos/CA0721/intro_proba_CA0721.html",
    "title": "Introducci√≥n a la Probabilidad",
    "section": "",
    "text": "Sea \\(\\Omega\\) un conjunto finito al que llamamos espacio muestral. Sus elementos representan todos los posibles resultados de un experimento aleatorio.\nSean \\(A, B \\subseteq \\Omega\\) subconjuntos del espacio muestral. Estos subconjuntos se denominan eventos.\nUn elemento \\(a\\) pertenece a un evento \\(A\\) si:\n\\[\na \\in A\n\\]\n\n\n\n\nEn el contexto de la probabilidad, un experimento aleatorio es un proceso que genera un resultado que no puede preverse con certeza. El conjunto \\(\\Omega\\) representa el conjunto de todos los posibles resultados de ese experimento.\nPor ejemplo:\n\nAl lanzar un dado: \\(\\Omega = \\{1,2,3,4,5,6\\}\\)\nAl lanzar una moneda: \\(\\Omega = \\{\\text{cara}, \\text{cruz}\\}\\)\n\n\n\n\n\nUn evento es cualquier subconjunto del espacio muestral. Esto incluye desde el conjunto vac√≠o hasta el conjunto total \\(\\Omega\\). Notamos que:\n\nNota: Como los eventos son conjuntos, todas las operaciones entre conjuntos (uni√≥n, intersecci√≥n, complemento, etc.) tambi√©n se aplican a los eventos. Puedes consultar la secci√≥n Algunos recordatorios de Teor√≠a de Conjuntos para ver esas propiedades en detalle.\n\nPodemos construir nuevos eventos combinando otros mediante operaciones de conjuntos:\n\nIntersecci√≥n \\((A \\cap B\\,)\\): elementos que est√°n en ambos eventos.\nUni√≥n \\((A \\cup B\\,)\\): elementos que est√°n en al menos uno de los eventos.\nComplemento \\((A^c)\\): elementos que no est√°n en el evento \\(A\\).\n\n\n\n\n\nLa probabilidad es una funci√≥n que asigna un n√∫mero entre 0 y 1 a cada evento, representando cu√°n probable es que ese evento ocurra.\nProvisionalmente, podemos pensar en la probabilidad como una funci√≥n:\n\\[\nP : \\mathcal{F} \\to [0,1]\n\\]\ndonde \\(\\mathcal{F}\\) es una colecci√≥n de subconjuntos de \\(\\Omega\\) (es decir, eventos), y \\(P(A)\\) nos da la probabilidad de que ocurra el evento \\(A\\).\nM√°s adelante, formalizaremos los axiomas que esta funci√≥n debe cumplir.",
    "crumbs": [
      "Inicio",
      "Tema 2: Introducci√≥n a la Probabilidad"
    ]
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html#introducci√≥n-a-la-notaci√≥n-y-conceptos-b√°sicos-de-probabilidad",
    "href": "cursos/CA0721/intro_proba_CA0721.html#introducci√≥n-a-la-notaci√≥n-y-conceptos-b√°sicos-de-probabilidad",
    "title": "Introducci√≥n a la Probabilidad",
    "section": "",
    "text": "Sea \\(\\Omega\\) un conjunto finito al que llamamos espacio muestral. Sus elementos representan todos los posibles resultados de un experimento aleatorio.\nSean \\(A, B \\subseteq \\Omega\\) subconjuntos del espacio muestral. Estos subconjuntos se denominan eventos.\nUn elemento \\(a\\) pertenece a un evento \\(A\\) si:\n\\[\na \\in A\n\\]\n\n\n\n\nEn el contexto de la probabilidad, un experimento aleatorio es un proceso que genera un resultado que no puede preverse con certeza. El conjunto \\(\\Omega\\) representa el conjunto de todos los posibles resultados de ese experimento.\nPor ejemplo:\n\nAl lanzar un dado: \\(\\Omega = \\{1,2,3,4,5,6\\}\\)\nAl lanzar una moneda: \\(\\Omega = \\{\\text{cara}, \\text{cruz}\\}\\)\n\n\n\n\n\nUn evento es cualquier subconjunto del espacio muestral. Esto incluye desde el conjunto vac√≠o hasta el conjunto total \\(\\Omega\\). Notamos que:\n\nNota: Como los eventos son conjuntos, todas las operaciones entre conjuntos (uni√≥n, intersecci√≥n, complemento, etc.) tambi√©n se aplican a los eventos. Puedes consultar la secci√≥n Algunos recordatorios de Teor√≠a de Conjuntos para ver esas propiedades en detalle.\n\nPodemos construir nuevos eventos combinando otros mediante operaciones de conjuntos:\n\nIntersecci√≥n \\((A \\cap B\\,)\\): elementos que est√°n en ambos eventos.\nUni√≥n \\((A \\cup B\\,)\\): elementos que est√°n en al menos uno de los eventos.\nComplemento \\((A^c)\\): elementos que no est√°n en el evento \\(A\\).\n\n\n\n\n\nLa probabilidad es una funci√≥n que asigna un n√∫mero entre 0 y 1 a cada evento, representando cu√°n probable es que ese evento ocurra.\nProvisionalmente, podemos pensar en la probabilidad como una funci√≥n:\n\\[\nP : \\mathcal{F} \\to [0,1]\n\\]\ndonde \\(\\mathcal{F}\\) es una colecci√≥n de subconjuntos de \\(\\Omega\\) (es decir, eventos), y \\(P(A)\\) nos da la probabilidad de que ocurra el evento \\(A\\).\nM√°s adelante, formalizaremos los axiomas que esta funci√≥n debe cumplir.",
    "crumbs": [
      "Inicio",
      "Tema 2: Introducci√≥n a la Probabilidad"
    ]
  },
  {
    "objectID": "cursos/CA0721/intro_proba_CA0721.html#modelo-de-probabilidad-de-laplace",
    "href": "cursos/CA0721/intro_proba_CA0721.html#modelo-de-probabilidad-de-laplace",
    "title": "Introducci√≥n a la Probabilidad",
    "section": "Modelo de probabilidad de Laplace",
    "text": "Modelo de probabilidad de Laplace\nCuando el espacio muestral \\(\\Omega\\) es finito, se puede considerar que todos los resultados son igualmente probables. A este modelo se le conoce como modelo de probabilidad de Laplace o tambi√©n como probabilidad cl√°sica.\nEn este contexto, se asigna la misma probabilidad a cada resultado \\(\\omega \\in \\Omega\\), de modo que:\n\\[\nP(\\{\\omega\\}) = \\frac{1}{|\\Omega|}\n\\]\ndonde \\(|\\Omega|\\) denota la cantidad total de posibles resultados.\n\nDe forma general, si \\(A\\) es un evento (es decir, un subconjunto de \\(\\Omega\\)), su probabilidad se define como el cociente entre la cantidad de resultados favorables (elementos de \\(A\\)) y la cantidad total de posibles resultados:\n\\[\nP(A) = \\frac{|A|}{|\\Omega|}\n\\]\nEsta definici√≥n supone que todos los resultados tienen la misma probabilidad y es v√°lida √∫nicamente cuando el n√∫mero de resultados posibles es finito y equiprobable.\n\n\nNota: Este modelo es un caso particular de lo que m√°s adelante definiremos como una medida de probabilidad sobre una colecci√≥n de eventos \\(\\mathcal{F}\\). Por ahora, basta con tener una comprensi√≥n intuitiva: el modelo de Laplace asigna igual peso a todos los elementos de \\(\\Omega\\) y calcula la probabilidad de un evento \\(A\\) como la proporci√≥n de casos favorables respecto al total.",
    "crumbs": [
      "Inicio",
      "Tema 2: Introducci√≥n a la Probabilidad"
    ]
  },
  {
    "objectID": "cursos/CA0721/antecedentes_CA0721.html",
    "href": "cursos/CA0721/antecedentes_CA0721.html",
    "title": "Preliminares",
    "section": "",
    "text": "Dada una sucesi√≥n \\(\\{a_k\\}\\), definimos la suma finita desde \\(k = m\\) hasta \\(k = n\\) como:\n\\[\n\\sum_{k=m}^n a_k = a_m + a_{m+1} + \\cdots + a_n\n\\]\n\n\n\nLinealidad por constante: \\[\n\\sum_{k=1}^n c a_k = c \\sum_{k=1}^n a_k \\quad \\text{para todo } c \\in \\mathbb{R}\n\\]\nSuma t√©rmino a t√©rmino: \\[\n\\sum_{k=1}^n (a_k + b_k) = \\sum_{k=1}^n a_k + \\sum_{k=1}^n b_k\n\\]\nCambio de √≠ndice: \\[\n\\sum_{k=0}^n a_{k+1} = \\sum_{k=1}^{n+1} a_k\n\\]\n\n\n\n\nSi \\(a_k = b_k - b_{k+1}\\), entonces se tiene:\n\\[\n\\sum_{k=m}^n (b_k - b_{k+1}) = b_m - b_{n+1}\n\\]\nSi la suma es infinita y el l√≠mite existe:\n\\[\n\\sum_{k=m}^\\infty (b_k - b_{k+1}) = b_m - \\lim_{j \\to \\infty} b_{j+1}\n\\]\n\n\n\nLa suma de una progresi√≥n geom√©trica de raz√≥n \\(r \\ne 1\\) es:\n\\[\n\\sum_{k=m}^n r^k = \\frac{r^m - r^{n+1}}{1 - r}\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 1: Preliminares"
    ]
  },
  {
    "objectID": "cursos/CA0721/antecedentes_CA0721.html#sumas-finitas",
    "href": "cursos/CA0721/antecedentes_CA0721.html#sumas-finitas",
    "title": "Preliminares",
    "section": "",
    "text": "Dada una sucesi√≥n \\(\\{a_k\\}\\), definimos la suma finita desde \\(k = m\\) hasta \\(k = n\\) como:\n\\[\n\\sum_{k=m}^n a_k = a_m + a_{m+1} + \\cdots + a_n\n\\]\n\n\n\nLinealidad por constante: \\[\n\\sum_{k=1}^n c a_k = c \\sum_{k=1}^n a_k \\quad \\text{para todo } c \\in \\mathbb{R}\n\\]\nSuma t√©rmino a t√©rmino: \\[\n\\sum_{k=1}^n (a_k + b_k) = \\sum_{k=1}^n a_k + \\sum_{k=1}^n b_k\n\\]\nCambio de √≠ndice: \\[\n\\sum_{k=0}^n a_{k+1} = \\sum_{k=1}^{n+1} a_k\n\\]\n\n\n\n\nSi \\(a_k = b_k - b_{k+1}\\), entonces se tiene:\n\\[\n\\sum_{k=m}^n (b_k - b_{k+1}) = b_m - b_{n+1}\n\\]\nSi la suma es infinita y el l√≠mite existe:\n\\[\n\\sum_{k=m}^\\infty (b_k - b_{k+1}) = b_m - \\lim_{j \\to \\infty} b_{j+1}\n\\]\n\n\n\nLa suma de una progresi√≥n geom√©trica de raz√≥n \\(r \\ne 1\\) es:\n\\[\n\\sum_{k=m}^n r^k = \\frac{r^m - r^{n+1}}{1 - r}\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 1: Preliminares"
    ]
  },
  {
    "objectID": "cursos/CA0721/antecedentes_CA0721.html#principios-de-combinatoria",
    "href": "cursos/CA0721/antecedentes_CA0721.html#principios-de-combinatoria",
    "title": "Preliminares",
    "section": "Principios de combinatoria",
    "text": "Principios de combinatoria\nSea \\(\\Omega_1\\) y \\(\\Omega_2\\) dos conjuntos finitos no vac√≠os. El n√∫mero de formas de formar pares \\((a, b)\\) con \\(a \\in \\Omega_1\\) y \\(b \\in \\Omega_2\\) es:\n\\[\n|\\Omega_1 \\times \\Omega_2| = |\\Omega_1| \\cdot |\\Omega_2|\n\\]\ndonde \\(\\times\\) denota el producto cartesiano de conjuntos. Este resultado es un caso del principio de multiplicaci√≥n.\nUna aplicaci√≥n importante de este principio es el conteo de permutaciones. Si un conjunto \\(\\Omega\\) tiene \\(n\\) elementos, entonces existen:\n\\[\nn! := 1 \\cdot 2 \\cdot 3 \\cdots (n-1)\\cdot n\n\\]\nformas distintas de ordenarlos. Este n√∫mero se llama el factorial de \\(n\\), y representa la cantidad total de permutaciones posibles de los elementos del conjunto.\n\nIntuitivamente, una permutaci√≥n es una forma de reorganizar (ordenar) todos los elementos del conjunto.\n\n\nPermutaciones\nN√∫mero de formas de seleccionar \\(k\\) objetos ordenadamente de un total de \\(n\\):\n\\[\nP(n,k) = \\frac{n!}{(n-k)!}\n\\]\n\n\nCombinaciones\nN√∫mero de formas de elegir \\(k\\) objetos sin importar el orden:\n\\[\n\\binom{n}{k} = \\frac{n!}{k! (n-k)!}\n\\]\n\n\nCoeficiente multinomial\nN√∫mero de formas de dividir \\(n\\) objetos en \\(r\\) grupos de tama√±os \\(n_1, n_2, \\ldots, n_r\\) con \\(n_1 + \\cdots + n_r = n\\):\n\\[\n\\binom{n}{n_1\\, n_2\\, \\cdots\\, n_r} = \\frac{n!}{n_1! \\, n_2! \\cdots n_r!}\n\\]\n\n\nF√≥rmula del binomio\nExpansi√≥n de \\((a + b)^n\\) usando combinatoria:\n\\[\n(a + b)^n = \\sum_{k=0}^n \\binom{n}{k} a^{n-k} b^k\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 1: Preliminares"
    ]
  },
  {
    "objectID": "cursos/CA0721/antecedentes_CA0721.html#sec-conjuntos",
    "href": "cursos/CA0721/antecedentes_CA0721.html#sec-conjuntos",
    "title": "Preliminares",
    "section": "Algunos recordatorios de Teor√≠a de Conjuntos",
    "text": "Algunos recordatorios de Teor√≠a de Conjuntos\nDado un conjunto \\(\\Omega\\), los subconjuntos \\(A, B, C, D \\subseteq \\Omega\\) pueden relacionarse mediante las siguientes operaciones y propiedades:\n\nPertenencia\nUn elemento \\(a\\) pertenece a un conjunto \\(A\\) si:\n\\[\na \\in A\n\\]\n\n\n\nIntersecci√≥n de conjuntos\nLa intersecci√≥n de dos conjuntos \\(A\\) y \\(B\\) se define como:\n\\[\nA \\cap B = \\{x \\in \\Omega \\mid x \\in A \\text{ y } x \\in B\\}\n\\]\nPropiedades:\n\nConmutatividad: \\(A \\cap B = B \\cap A\\)\nAsociatividad: \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\)\nInclusi√≥n: \\(A \\subseteq B \\Rightarrow A \\cap B = A\\)\nSi \\(D \\subseteq A\\) y \\(D \\subseteq B \\Rightarrow D \\subseteq A \\cap B\\)\n\n\n\n\nUni√≥n de conjuntos\nLa uni√≥n de dos conjuntos \\(A\\) y \\(B\\) se define como:\n\\[\nA \\cup B = \\{x \\in \\Omega \\mid x \\in A \\text{ o } x \\in B\\}\n\\]\nPropiedades:\n\nConmutatividad: \\(A \\cup B = B \\cup A\\)\nAsociatividad: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\)\nInclusi√≥n: \\(A \\subseteq B \\Rightarrow A \\cup B = B\\)\nSi \\(A \\subseteq D\\) y \\(B \\subseteq D \\Rightarrow A \\cup B \\subseteq D\\)\n\n\n\n\nDiferencia de conjuntos\nLa diferencia de conjuntos se define como:\n\\[\nB - A = \\{x \\in B \\mid x \\notin A\\}\n\\]\nEl complemento de un conjunto \\(A\\) respecto al universo \\(\\Omega\\) es:\n\\[\nA^c = \\Omega - A = \\{x \\in \\Omega \\mid x \\notin A\\}\n\\]\n\n\n\nLeyes de De Morgan\nSean \\(\\{A_i\\}_{i \\in I}\\) una familia de conjuntos, se tiene:\n\n\\(\\left( \\bigcap\\limits_{i \\in I} A_i \\right)^c = \\bigcup\\limits_{i \\in I} A_i^c\\)\n\\(\\left( \\bigcup\\limits_{i \\in I} A_i \\right)^c = \\bigcap\\limits_{i \\in I} A_i^c\\)\n\nEn particular, para \\(A\\) y \\(B\\) arbitrarios:\n\n\\(E \\setminus (A \\cup B) = (E \\setminus A) \\cap (E \\setminus B)\\)\n\\(E \\setminus (A \\cap B) = (E \\setminus A) \\cup (E \\setminus B)\\)\n\\(A \\cap B = A \\setminus B^c\\)",
    "crumbs": [
      "Inicio",
      "Tema 1: Preliminares"
    ]
  },
  {
    "objectID": "cursos/CA0721/index_CA0721.html",
    "href": "cursos/CA0721/index_CA0721.html",
    "title": "CA0721: Probabilidad",
    "section": "",
    "text": "Bienvenido a los apuntes del curso CA0721.",
    "crumbs": [
      "Inicio",
      "P√°gina principal del curso"
    ]
  },
  {
    "objectID": "cursos/CA0721/index_CA0721.html#temas",
    "href": "cursos/CA0721/index_CA0721.html#temas",
    "title": "CA0721: Probabilidad",
    "section": "Temas",
    "text": "Temas\n\nTema 1: Preliminares\nTema 2: Introducci√≥n a la Probabilidad\nTema 3: Teor√≠a General de la Probabilidad\nTema 4: Variables Aleatorias\nTema 5: Vectores Aleatorios",
    "crumbs": [
      "Inicio",
      "P√°gina principal del curso"
    ]
  },
  {
    "objectID": "cursos/CA0306/distribuciones_sobrevivencia_CA0306.html",
    "href": "cursos/CA0306/distribuciones_sobrevivencia_CA0306.html",
    "title": "tema1",
    "section": "",
    "text": "tema1 CA0306"
  },
  {
    "objectID": "cursos/CA0306/index_CA0306.html",
    "href": "cursos/CA0306/index_CA0306.html",
    "title": "CA0306: Contingencias de Vida I",
    "section": "",
    "text": "Bienvenido a los apuntes del curso CA0306."
  },
  {
    "objectID": "cursos/CA0306/index_CA0306.html#temas",
    "href": "cursos/CA0306/index_CA0306.html#temas",
    "title": "CA0306: Contingencias de Vida I",
    "section": "Temas",
    "text": "Temas\n\nTema 1: Distribuciones de Sobrevivencia"
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html",
    "title": "Variables Aleatorias",
    "section": "",
    "text": "Una variable aleatoria (v.a.) en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) es una funci√≥n\n\\[\nX : \\Omega \\to \\mathbb{R} \\quad \\text{tal que} \\quad X^{-1}(B) \\in \\mathcal{F} \\quad \\text{para todo } B \\in \\mathcal{B}(\\mathbb{R})\n\\]\ndonde \\(\\mathcal{B}(\\mathbb{R})\\) denota la \\(\\sigma\\)-√°lgebra de Borel en \\(\\mathbb{R}\\), es decir, la \\(\\sigma\\)-√°lgebra generada por todos los conjuntos abiertos de \\(\\mathbb{R}\\).\n\nNota: La escogencia de la \\(\\sigma\\)-√°lgebra de Borel puede parecer extra√±a, pero gracias a ella se podr√°n calcular probabilidades de eventos de inter√©s. En efecto, como consecuencia de esta definici√≥n de variable aleatoria se tiene que:\n\n\\(\\{X &lt; a\\} = \\{\\omega \\in \\Omega : X(\\omega) &lt; a\\} \\in \\mathcal{F}\\) para todo \\(a \\in \\mathbb{R}\\)\n\\(\\{X \\leq a\\} \\in \\mathcal{F}\\) para todo \\(a \\in \\mathbb{R}\\)\nPara todo \\(a &lt; b\\), los siguientes eventos tambi√©n est√°n en \\(\\mathcal{F}\\): \\[\n\\{a &lt; X \\leq b\\},\\quad \\{a &lt; X &lt; b\\},\\quad \\{a \\leq X &lt; b\\},\\quad \\{a \\leq X \\leq b\\}\n\\]\n\n\n\n\nPara que \\(X\\) sea una variable aleatoria, basta que:\n\\[\n\\{X &lt; a\\} \\in \\mathcal{F} \\quad \\text{para todo } a \\in \\mathbb{R}\n\\]\nEsta condici√≥n es suficiente y tambi√©n necesaria. Adem√°s, puede reemplazarse \\(\\{X &lt; a\\}\\) por cualquiera de los siguientes conjuntos sin cambiar la validez del resultado:\n\n\\(\\{X \\leq a\\}\\), \\(\\{X &gt; a\\}\\), \\(\\{X \\geq a\\}\\)\n\n\n\n\nSean \\(X\\) y \\(Y\\) variables aleatorias reales sobre \\((\\Omega, \\mathcal{F}, P)\\). Entonces:\n\nPara todo \\(a, b \\in \\mathbb{R}\\), \\(aX + bY\\) es una variable aleatoria.\n\\(\\min\\{X, Y\\}\\) y \\(\\max\\{X, Y\\}\\) son variables aleatorias.\nSi \\(g : \\mathbb{R} \\to \\mathbb{R}\\) es continua, entonces \\(g(X)\\) tambi√©n es una variable aleatoria.\n\n\n\n\nSi \\(\\{X_n\\}_{n \\in \\mathbb{N}}\\) es una sucesi√≥n de variables aleatorias, entonces:\n\n\\(\\inf\\limits_{n \\in \\mathbb{N}} X_n\\), \\(\\sup\\limits_{n \\in \\mathbb{N}} X_n\\) son variables aleatorias.\n\\(\\liminf X_n\\), \\(\\limsup X_n\\) tambi√©n son variables aleatorias.",
    "crumbs": [
      "Inicio",
      "Tema 4: Variables Aleatorias"
    ]
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#definici√≥n",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#definici√≥n",
    "title": "Variables Aleatorias",
    "section": "",
    "text": "Una variable aleatoria (v.a.) en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) es una funci√≥n\n\\[\nX : \\Omega \\to \\mathbb{R} \\quad \\text{tal que} \\quad X^{-1}(B) \\in \\mathcal{F} \\quad \\text{para todo } B \\in \\mathcal{B}(\\mathbb{R})\n\\]\ndonde \\(\\mathcal{B}(\\mathbb{R})\\) denota la \\(\\sigma\\)-√°lgebra de Borel en \\(\\mathbb{R}\\), es decir, la \\(\\sigma\\)-√°lgebra generada por todos los conjuntos abiertos de \\(\\mathbb{R}\\).\n\nNota: La escogencia de la \\(\\sigma\\)-√°lgebra de Borel puede parecer extra√±a, pero gracias a ella se podr√°n calcular probabilidades de eventos de inter√©s. En efecto, como consecuencia de esta definici√≥n de variable aleatoria se tiene que:\n\n\\(\\{X &lt; a\\} = \\{\\omega \\in \\Omega : X(\\omega) &lt; a\\} \\in \\mathcal{F}\\) para todo \\(a \\in \\mathbb{R}\\)\n\\(\\{X \\leq a\\} \\in \\mathcal{F}\\) para todo \\(a \\in \\mathbb{R}\\)\nPara todo \\(a &lt; b\\), los siguientes eventos tambi√©n est√°n en \\(\\mathcal{F}\\): \\[\n\\{a &lt; X \\leq b\\},\\quad \\{a &lt; X &lt; b\\},\\quad \\{a \\leq X &lt; b\\},\\quad \\{a \\leq X \\leq b\\}\n\\]\n\n\n\n\nPara que \\(X\\) sea una variable aleatoria, basta que:\n\\[\n\\{X &lt; a\\} \\in \\mathcal{F} \\quad \\text{para todo } a \\in \\mathbb{R}\n\\]\nEsta condici√≥n es suficiente y tambi√©n necesaria. Adem√°s, puede reemplazarse \\(\\{X &lt; a\\}\\) por cualquiera de los siguientes conjuntos sin cambiar la validez del resultado:\n\n\\(\\{X \\leq a\\}\\), \\(\\{X &gt; a\\}\\), \\(\\{X \\geq a\\}\\)\n\n\n\n\nSean \\(X\\) y \\(Y\\) variables aleatorias reales sobre \\((\\Omega, \\mathcal{F}, P)\\). Entonces:\n\nPara todo \\(a, b \\in \\mathbb{R}\\), \\(aX + bY\\) es una variable aleatoria.\n\\(\\min\\{X, Y\\}\\) y \\(\\max\\{X, Y\\}\\) son variables aleatorias.\nSi \\(g : \\mathbb{R} \\to \\mathbb{R}\\) es continua, entonces \\(g(X)\\) tambi√©n es una variable aleatoria.\n\n\n\n\nSi \\(\\{X_n\\}_{n \\in \\mathbb{N}}\\) es una sucesi√≥n de variables aleatorias, entonces:\n\n\\(\\inf\\limits_{n \\in \\mathbb{N}} X_n\\), \\(\\sup\\limits_{n \\in \\mathbb{N}} X_n\\) son variables aleatorias.\n\\(\\liminf X_n\\), \\(\\limsup X_n\\) tambi√©n son variables aleatorias.",
    "crumbs": [
      "Inicio",
      "Tema 4: Variables Aleatorias"
    ]
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#funciones-de-distribuci√≥n",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#funciones-de-distribuci√≥n",
    "title": "Variables Aleatorias",
    "section": "Funciones de distribuci√≥n",
    "text": "Funciones de distribuci√≥n\nSea \\(X\\) una variable aleatoria real en un espacio \\((\\Omega, \\mathcal{F}, P)\\).\nLa funci√≥n de distribuci√≥n (acumulada) de \\(X\\) es la funci√≥n \\(F_X : \\mathbb{R} \\to [0,1]\\) definida por:\n\\[\nF_X(t) = P(X \\leq t)\n\\]\n\nPropiedades\n\n\\(F_X(t) \\in [0, 1]\\) para todo \\(t \\in \\mathbb{R}\\)\n\\(F_X\\) es mon√≥tona creciente y en particular \\(\\forall t \\in \\mathbb{R}\\)\n\\[F_X(t^-) = \\lim\\limits_{x \\to t^-}F_X(x)\\] \\[F_X(t^+) = \\lim\\limits_{x \\to t^+}F_X(x)\\] \\[\nP [X&lt;t] = F_X(t^-) \\leq F_X(t) \\leq F_X(t^+)\n\\]\nAdem√°s:\n\\[\n\\lim_{t \\to -\\infty} F_X(t) = 0 \\quad \\text{y} \\quad \\lim_{t \\to +\\infty} F_X(t) = 1\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 4: Variables Aleatorias"
    ]
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#variables-aleatorias-discretas",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#variables-aleatorias-discretas",
    "title": "Variables Aleatorias",
    "section": "Variables aleatorias discretas",
    "text": "Variables aleatorias discretas\nUna variable aleatoria \\(X\\) es discreta si existe un subconjunto numerable \\(N \\subseteq \\mathbb{R}\\) tal que:\n\\[\nP(\\Omega) = \\sum_{n \\in N} P(X = n)\n\\]\nPara estas variables, la funci√≥n:\n\\[\np_X(n) = P(X = n), \\quad n \\in \\mathbb{N}\n\\]\nse llama funci√≥n de masa de probabilidad de \\(X\\).\n\n\n\n\n\n\nTeorema: Existencia de variables aleatorias discretas\n\n\n\nSea \\(S = \\{s_j : j \\in I\\}\\) un conjunto finito o numerable, y sea \\(\\{\\pi_j : j \\in I\\}\\) una colecci√≥n de n√∫meros reales tal que:\n\n\\(\\pi_j \\geq 0\\) para todo \\(j \\in I\\)\n\\(\\displaystyle \\sum_{j \\in I} \\pi_j = 1\\)\n\nEntonces existe un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) y una variable aleatoria \\(X\\) en \\((\\Omega, \\mathcal{F}, P)\\) tal que la funci√≥n de masa de probabilidad de \\(X\\) cumple:\n\\[\nP(X = s_j) = \\pi_j \\quad \\text{si } j \\in I, \\qquad\nP(X = s) = 0 \\quad \\text{si } s \\notin S\n\\]\n\n\n\nFunci√≥n de distribuci√≥n\nSi \\(X\\) es una variable aleatoria discreta con funci√≥n de probabilidad \\(f_X(x)\\), entonces la funci√≥n de distribuci√≥n acumulada se calcula como:\n\\[\nF_X(x) = P[X \\leq x] = \\sum_{u \\leq x} P[X = u]\n\\]\n\n\nTransformaciones\nSea \\(X\\) una v.a. discreta en un e.p \\((\\Omega, \\mathcal{F}, P)\\) y sea \\(g : \\mathbb{R} \\to \\mathbb{R}\\) una funci√≥n. \\(Y = g(X)\\) es una v.a. La funci√≥n de masa de \\(Y\\) se calcula de la siguiente manera:\n\\[\\begin{align*}\nP_Y(y) &= P_X(g(X) = y) \\\\\n&= P_X(X \\in g^{-1}(y)) \\\\\n&=\n\\begin{cases}\n0 & \\text{si } y \\notin \\text{Im}(g(X)) \\\\\n\\sum\\limits_{x \\in g^{-1}(y)} P[X = x] & \\text{si } y \\in \\text{Im}(g(X))\n\\end{cases}\n\\end{align*}\\]\n\n\nEsperanza\nSean \\(n\\) los valores que toma \\(X\\). Se define:\n\\[\n\\mathbb{E}[X] = \\sum_{n \\in \\text{Im}(X)} n \\cdot P[X = n]\n\\]\nSiempre y cuando la anterior suma, en caso de ser una serie, converja absolutamente.\n\nPropiedades\nSi \\(X, Y\\) son variables aleatorias en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) y \\(a, b \\in \\mathbb{R}\\):\n\nLinealidad de la esperanza:\n\n\\[\n\\mathbb{E}[aX + bY] = a \\cdot \\mathbb{E}[X] + b \\cdot \\mathbb{E}[Y]\n\\]\n\nSi \\(g(X)\\) y \\(h(Y)\\) son funciones de \\(X\\) y \\(Y\\) respectivamente, entonces:\n\n\\[\n\\mathbb{E}[g(X) + h(Y)] = \\mathbb{E}[g(X)] + \\mathbb{E}[h(Y)]\n\\]\n\n\n\nLey del estad√≠stico inconsciente\nSi \\(X\\) es una v.a. discreta en un e.p. \\((\\Omega, \\mathcal{F}, P)\\) y sea \\(g : \\mathbb{R} \\to \\mathbb{R}\\) una funci√≥n tal que\n\\[\n\\sum_{n \\in \\text{Im}(X)} \\left| g(n) \\right| \\cdot P[X = n]\n\\]\nes finita, entonces\n\\[\n\\mathbb{E}[g(x)] = \\sum_{n \\in \\text{Im}(X)} g(n) \\cdot P[X = n]\n\\]\n\nNota: No ocupa la funci√≥n de masa de \\(g(x)\\) para calcular \\(\\mathbb{E}[g(x)]\\)\n\n\n\nMomentos y Varianza\nSea \\(X\\) una v.a. discreta en un e.p \\((\\Omega, \\mathcal{F}, P)\\) y sea \\(n &gt; 0\\):\n\nEl \\(n\\)‚Äì√©simo momento de \\(X\\) se define como \\(\\mathbb{E}[X^n]\\)\nSi \\(\\mu = \\mathbb{E}[X]\\), el \\(n\\)‚Äì√©simo momento centrado se define como:\n\n\\[\n\\mathbb{E}\\left[(X - \\mu)^n\\right]\n\\]\n\nEl segundo momento centrado es particularmente importante:\n\nLa varianza de \\(X\\), denotada \\(\\operatorname{Var}[X]\\), se calcula as√≠:\n\n\n\\[\\begin{align*}\n\\operatorname{Var}[X] &= \\mathbb{E} \\left[(X - \\mu)^2 \\right]\\\\\n&= \\sum_{n \\in \\mathbb{N}} (n - \\mu)^2 \\cdot P_X(X = n)\n\\end{align*}\\]\nSiempre que la anterior suma sea finita.\n\nNota: Es posible mostrar que si \\(\\mathbb{E}[X^2] &lt; \\infty\\), entonces:\n\n\\[\n\\operatorname{Var}[X] = \\mathbb{E}[X^2] - \\mu^2\n\\]\n\nPropiedades de la varianza\nSean \\(X\\) e \\(Y\\) dos variables aleatorias y sea \\(c\\) una constante, entonces:\n\n\\(\\operatorname{Var}(c) = 0\\)\n\\(\\operatorname{Var}(X + c) = \\operatorname{Var}(X)\\)\n\\(\\operatorname{Var}(cX) = c^2 \\cdot \\operatorname{Var}(X)\\)\nSi \\(X\\) e \\(Y\\) son variables aleatorias independientes, entonces:\n\n\\[\n\\operatorname{Var}(X + Y) = \\operatorname{Var}(X) + \\operatorname{Var}(Y)\n\\]\n\n\n\nDesviaci√≥n est√°ndar\nSea \\(X\\) una variable aleatoria discreta, se define la desviaci√≥n est√°ndar o t√≠pica de \\(X\\) por:\n\\[\n\\sigma_X = \\sqrt{\\operatorname{Var}(X)}\n\\]\n\n\nF√≥rmula de convoluci√≥n discreta\nSean \\(X, Y\\) (v.a) discretas e independientes en un e.p \\((\\Omega, \\mathcal{F}, P)\\).\nEntonces, la funci√≥n de probabilidad de masa de la v.a \\(Z = X + Y\\) viene dada por:\n\\[\nP_Z(z) = \\sum_{x \\in \\text{Im}(X)} P_X(x) P_Y(z - x)\n\\]\nY adem√°s:\n\\[\n\\varphi_{X + Y}(t) = \\varphi_X(t) \\varphi_Y(t) \\quad \\forall t \\in \\mathbb{R}\n\\]\nDe hecho, una f√≥rmula similar aplica para las funciones generadoras de momentos y generadoras de probabilidades. Aunque en estos casos dicha f√≥rmula solo ser√≠a v√°lida para todos los valores de \\(t\\) donde estas funciones est√©n definidas.\n\n\nFunciones importantes\nSea \\(X\\) una (v.a) discreta en un e.p \\((\\Omega, \\mathcal{F}, P)\\)\n\n\n\n\n\n\nFunci√≥n Caracter√≠stica\n\n\n\n\\[\n\\varphi_X(t) = \\mathbb{E}[e^{itX}] = \\sum_{n \\in \\text{Im}(X)} e^{itn} \\cdot P[X = n]\n\\] Esta est√° definida para todo \\(t \\in \\mathbb{R}\\).\n\n\n\n\n\n\n\n\nFunci√≥n Generadora de Momentos\n\n\n\n\\[\nM_X(t) = \\mathbb{E}[e^{tX}] = \\sum_{n \\in \\text{Im}(X)} e^{tn} \\cdot P[X = n]\n\\] Para todos aquellos valores de \\(t\\) donde dicho valor esperado exista.\n\n\n\n\n\n\n\n\nFunci√≥n Generadora de Probabilidades\n\n\n\n\\[\nG_X(t) = \\mathbb{E}[t^X] = \\sum_{n \\in \\text{Im}(X)} t^n \\cdot P[X = n]\n\\] Para todos aquellos valores de \\(t\\) donde dicho valor esperado exista.\n\n\n\nNota: No lo vamos a probar, pero existe un teorema que dice que dos variables aleatorias \\(X, Y\\) tienen la misma distribuci√≥n si y solo si \\(\\varphi_X = \\varphi_Y\\). Esto nos permite reconocer variables aleatorias.\n\n\n\n\nDistribuciones discretas comunes\n\n\n\n\n\n\nBernoulli\n\n\n\n\\[X \\sim \\text{Bernoulli}(p)\\]\n\n\\(\\begin{cases}P(X = 0) = 1 - p \\\\P(X = 1) = p\\end{cases}\\)\n\\(\\mathbb{E}[X] = p\\)\n\\(\\operatorname{Var}(X) = p(1 - p)\\)\n\nEste tipo de variable se suele usar en experimentos Bernoulli donde los resultados pueden etiquetarse como √©xito o fracaso\n\n\n\n\n\n\n\n\nBinomial\n\n\n\n\\[X \\sim \\text{Bin}(n, p)\\]\n\n\\(P(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k}\\)\n\\(\\mathbb{E}[X] = n p\\)\n\\(\\operatorname{Var}(X) = n p (1 - p)\\)\n\nSe usa para modelar el n√∫mero de √©xitos en \\(n\\) ensayos independientes con probabilidad de √©xito \\(p\\).\n\n\n\n\n\n\n\n\nBinomial negativa\n\n\n\n\\[X \\sim \\text{BN}(r, p)\\]\n\n\\(P(X = k) = \\binom{k + r - 1}{k} p^r (1 - p)^k\\),‚ÄÉ\\(k = 0, 1, 2, \\dots\\)\n\\(\\mathbb{E}[X] = \\dfrac{r(1 - p)}{p}\\)\n\\(\\operatorname{Var}(X) = \\dfrac{r(1 - p)}{p^2}\\)\n\nSe usa cuando se conoce el n√∫mero de √©xitos deseados (\\(r\\)) y se desea modelar el n√∫mero de fracasos antes de lograrlos.\n\n\n\n\n\n\n\n\nGeom√©trica\n\n\n\n\\[X \\sim \\text{Geom}(p)\\]\n\n\\(P(X = n) = (1 - p)^{n - 1} p\\),‚ÄÉ\\(n = 1, 2, 3, \\dots\\)\n\\(\\mathbb{E}[X] = \\dfrac{1}{p}\\)\n\\(\\operatorname{Var}(X) = \\dfrac{1 - p}{p^2}\\)\n\nModela el n√∫mero de intentos necesarios para obtener el primer √©xito.\n\n\nCondici√≥n necesaria, note que: \\[\\begin{align*}\n        \\displaystyle\\sum^\\infty_{n=1}p_n &= p\\displaystyle\\sum^\\infty_{n=1}({1-p})^{n-1} = p\\displaystyle\\sum^\\infty_{k=0}({1-p})^k \\\\ &= \\frac{p}{1-({1-p})}=1\n    \\end{align*}\\]\n\n\n\n\n\n\nPoisson\n\n\n\n\\[X \\sim \\text{Poisson}(\\lambda)\\]\n\n\\(P(X = n) = \\dfrac{\\lambda^n e^{-\\lambda}}{n!}\\),‚ÄÉ\\(n = 0, 1, 2, \\dots\\)\n\\(\\mathbb{E}[X] = \\lambda\\)\n\\(\\operatorname{Var}(X) = \\lambda\\)\n\nSe usa para modelar el n√∫mero de ocurrencias de un evento raro en un intervalo fijo de tiempo o espacio.\n\n\n\n\n\n\n\n\nHipergeom√©trica\n\n\n\n\\[X \\sim \\text{HG}(m + n, m, r)\\]\nUna variable \\(X\\) se llama hipergeom√©trica de par√°metros \\(n\\), \\(m\\) y \\(r\\) si su distribuci√≥n est√° dada por:\n\n\\(P[X = k] = \\frac{\\dbinom{m}{k} \\dbinom{n}{r - k}}{\\dbinom{m + n}{r}}\\)\n\\(\\mathbb{E}[X] = r \\cdot \\dfrac{m}{m + n}\\)\n\\(\\operatorname{Var}(X) = r \\cdot \\dfrac{m}{m + n} \\cdot \\dfrac{n}{m + n} \\cdot \\dfrac{m + n - r}{m + n - 1}\\)",
    "crumbs": [
      "Inicio",
      "Tema 4: Variables Aleatorias"
    ]
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#variables-aleatorias-discretas-1",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#variables-aleatorias-discretas-1",
    "title": "Variables Aleatorias",
    "section": "Variables aleatorias discretas",
    "text": "Variables aleatorias discretas",
    "crumbs": [
      "Inicio",
      "Tema 4: Variables Aleatorias"
    ]
  },
  {
    "objectID": "cursos/CA0721/teoria_general_proba_CA0721.html",
    "href": "cursos/CA0721/teoria_general_proba_CA0721.html",
    "title": "Teor√≠a General de Probabilidades",
    "section": "",
    "text": "Hasta ahora hemos trabajado con la probabilidad en contextos finitos y simples, donde todos los resultados son igualmente probables (modelo de Laplace). Sin embargo, para desarrollar una teor√≠a m√°s general de la probabilidad, necesitamos una base m√°s formal.\nUn experimento aleatorio es un proceso cuyo resultado no se puede predecir con certeza, pero cuyo conjunto de resultados posibles puede describirse. A cada experimento aleatorio le asociamos tres componentes fundamentales:\n\nUn espacio muestral \\(\\Omega\\): el conjunto de todos los posibles resultados del experimento.\nUn conjunto de eventos \\(\\mathcal{F}\\): una colecci√≥n de subconjuntos de \\(\\Omega\\), considerados como los eventos del experimento.\nUna funci√≥n de probabilidad \\(P\\): que asigna a cada evento \\(A \\in \\mathcal{F}\\) un n√∫mero entre \\(0\\) y \\(1\\), representando la probabilidad de que ese evento ocurra.\n\n\n\nPara que el conjunto de eventos \\(\\mathcal{F}\\) sea adecuado, debe cumplir ciertas propiedades. A esto se le llama una \\(\\sigma\\)-√°lgebra de subconjuntos, y garantiza que podamos hacer operaciones como complementos, uniones y dem√°s, sin salirnos del conjunto de eventos v√°lidos.\nFormalmente, \\(\\mathcal{F}\\) es una \\(\\sigma-\\)√°lgebra sobre \\(\\Omega\\) si:\n\n\\(\\mathcal{F}\\) no es vac√≠o.\nSi \\(A \\in \\mathcal{F}\\), entonces su complemento tambi√©n est√° en \\(\\mathcal{F}\\): \\[\nA^c = \\Omega \\setminus A \\in \\mathcal{F}\n\\]\nSi \\(A_1, A_2, A_3, \\dots \\in \\mathcal{F}\\), entonces la uni√≥n infinita tambi√©n pertenece a \\(\\mathcal{F}\\): \\[\n\\bigcup_{j \\in \\mathbb{N}} A_j \\in \\mathcal{F}\n\\]\n\n\n\nRecurriendo a propiedades b√°sicas de conjuntos, no es dif√≠cil probar que si \\(\\mathcal{F}\\) es una \\(\\sigma-\\)√°lgebra tomada de un espacio muestral \\(\\Omega\\), entonces:\n\n\\(\\emptyset \\in \\mathcal{F}\\) y \\(\\Omega \\in \\mathcal{F}\\).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cup B \\in \\mathcal{F}\\)\n(de hecho, puede verse tambi√©n que \\(\\mathcal{F}\\) es cerrado bajo un n√∫mero finito de uniones).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cap B \\in \\mathcal{F}\\)\n(de hecho, puede verse tambi√©n que \\(\\mathcal{F}\\) es cerrado bajo un n√∫mero finito de intersecciones).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\setminus B \\in \\mathcal{F}\\).\nSi \\(A_j \\in \\mathcal{F}\\) para todo \\(j \\in \\mathbb{N}\\), entonces\n\\[\n\\bigcap_{j \\in \\mathbb{N}} A_j \\in \\mathcal{F}.\n\\]\n\n\n\n\n\nLa funci√≥n \\(P : \\mathcal{F} \\to [0,1]\\) se llama medida de probabilidad sobre \\((\\Omega,\\mathcal{F})\\), y debe cumplir con las siguientes propiedades:\n\nNo negatividad y normalizaci√≥n: \\[\nP(A) \\geq 0 \\quad \\text{para todo } A \\in \\mathcal{F}, \\quad \\text{y} \\quad P(\\Omega) = 1\n\\]\nAditividad numerable: Si \\(\\{A_j\\}_{j \\in \\mathbb{N}}\\) es una familia de eventos disjuntos dos a dos (es decir, \\(A_i \\cap A_j = \\emptyset\\) si \\(i \\neq j\\)), entonces: \\[\nP\\left( \\bigcup_{j \\in \\mathbb{N}} A_j \\right) = \\sum_{j \\in \\mathbb{N}} P(A_j)\n\\]\n\n\n\nSea \\(P\\) una medida de probabilidad definida sobre \\((\\Omega, \\mathcal{F})\\). Entonces se cumple que:\n\n\\(P(\\emptyset) = 0\\)\nSi \\(A_1, A_2, \\ldots, A_n \\in \\mathcal{F}\\) y son disjuntos dos a dos, entonces:\n\\[\nP\\left( \\bigcup_{j=1}^n A_j \\right) = \\sum_{j=1}^n P(A_j)\n\\]\nSi \\(A \\in \\mathcal{F}\\), entonces:\n\\[\nP(A) + P(A^c) = 1\n\\]\nSi \\(A, B \\in \\mathcal{F}\\), entonces:\n\\[\nP(A) + P(B) = P(A \\cup B) + P(A \\cap B)\n\\]\nEn particular:\n\\[\nP(A \\cup B) \\leq P(A) + P(B)\n\\]\nSi \\(A, B \\in \\mathcal{F}\\) y \\(A \\subseteq B\\), entonces:\n\\[\nP(A) \\leq P(B)\n\\]\nPara eventos arbitrarios \\(A_1, \\ldots, A_n \\in \\mathcal{F}\\) (no necesariamente disjuntos), se cumple el principio de inclusi√≥n-exclusi√≥n:\n\\[\nP\\left( \\bigcup_{i=1}^n A_i \\right) =\n\\sum_{i=1}^n P(A_i)\n- \\sum_{i_1 &lt; i_2} P(A_{i_1} \\cap A_{i_2})\n+ \\sum_{i_1 &lt; i_2 &lt; i_3} P(A_{i_1} \\cap A_{i_2} \\cap A_{i_3})\n- \\cdots + (-1)^{n-1} P\\left( \\bigcap_{j=1}^n A_j \\right)\n\\]\n\n\n\n\n\nSea \\((\\Omega, \\mathcal{F}, P)\\) una tripleta donde:\n\n\\(\\Omega\\) es un conjunto no vac√≠o.\n\\(\\mathcal{F}\\) es una \\(\\sigma\\)-√°lgebra de subconjuntos de \\(\\Omega\\).\n\\(P : \\mathcal{F} \\to [0,1]\\) es una medida de probabilidad sobre \\((\\Omega, \\mathcal{F})\\).\n\nEste conjunto \\((\\Omega, \\mathcal{F}, P)\\) es lo que se conoce como un espacio de probabilidad. A partir de esta estructura, se puede desarrollar toda la teor√≠a moderna de la probabilidad, tanto para espacios finitos como infinitos.",
    "crumbs": [
      "Inicio",
      "Tema 3: Teor√≠a General de la Probabilidad"
    ]
  },
  {
    "objectID": "cursos/CA0721/teoria_general_proba_CA0721.html#experimentos-aleatorios-y-espacio-de-probabilidad",
    "href": "cursos/CA0721/teoria_general_proba_CA0721.html#experimentos-aleatorios-y-espacio-de-probabilidad",
    "title": "Teor√≠a General de Probabilidades",
    "section": "",
    "text": "Hasta ahora hemos trabajado con la probabilidad en contextos finitos y simples, donde todos los resultados son igualmente probables (modelo de Laplace). Sin embargo, para desarrollar una teor√≠a m√°s general de la probabilidad, necesitamos una base m√°s formal.\nUn experimento aleatorio es un proceso cuyo resultado no se puede predecir con certeza, pero cuyo conjunto de resultados posibles puede describirse. A cada experimento aleatorio le asociamos tres componentes fundamentales:\n\nUn espacio muestral \\(\\Omega\\): el conjunto de todos los posibles resultados del experimento.\nUn conjunto de eventos \\(\\mathcal{F}\\): una colecci√≥n de subconjuntos de \\(\\Omega\\), considerados como los eventos del experimento.\nUna funci√≥n de probabilidad \\(P\\): que asigna a cada evento \\(A \\in \\mathcal{F}\\) un n√∫mero entre \\(0\\) y \\(1\\), representando la probabilidad de que ese evento ocurra.\n\n\n\nPara que el conjunto de eventos \\(\\mathcal{F}\\) sea adecuado, debe cumplir ciertas propiedades. A esto se le llama una \\(\\sigma\\)-√°lgebra de subconjuntos, y garantiza que podamos hacer operaciones como complementos, uniones y dem√°s, sin salirnos del conjunto de eventos v√°lidos.\nFormalmente, \\(\\mathcal{F}\\) es una \\(\\sigma-\\)√°lgebra sobre \\(\\Omega\\) si:\n\n\\(\\mathcal{F}\\) no es vac√≠o.\nSi \\(A \\in \\mathcal{F}\\), entonces su complemento tambi√©n est√° en \\(\\mathcal{F}\\): \\[\nA^c = \\Omega \\setminus A \\in \\mathcal{F}\n\\]\nSi \\(A_1, A_2, A_3, \\dots \\in \\mathcal{F}\\), entonces la uni√≥n infinita tambi√©n pertenece a \\(\\mathcal{F}\\): \\[\n\\bigcup_{j \\in \\mathbb{N}} A_j \\in \\mathcal{F}\n\\]\n\n\n\nRecurriendo a propiedades b√°sicas de conjuntos, no es dif√≠cil probar que si \\(\\mathcal{F}\\) es una \\(\\sigma-\\)√°lgebra tomada de un espacio muestral \\(\\Omega\\), entonces:\n\n\\(\\emptyset \\in \\mathcal{F}\\) y \\(\\Omega \\in \\mathcal{F}\\).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cup B \\in \\mathcal{F}\\)\n(de hecho, puede verse tambi√©n que \\(\\mathcal{F}\\) es cerrado bajo un n√∫mero finito de uniones).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\cap B \\in \\mathcal{F}\\)\n(de hecho, puede verse tambi√©n que \\(\\mathcal{F}\\) es cerrado bajo un n√∫mero finito de intersecciones).\nSi \\(A, B \\in \\mathcal{F}\\), entonces \\(A \\setminus B \\in \\mathcal{F}\\).\nSi \\(A_j \\in \\mathcal{F}\\) para todo \\(j \\in \\mathbb{N}\\), entonces\n\\[\n\\bigcap_{j \\in \\mathbb{N}} A_j \\in \\mathcal{F}.\n\\]\n\n\n\n\n\nLa funci√≥n \\(P : \\mathcal{F} \\to [0,1]\\) se llama medida de probabilidad sobre \\((\\Omega,\\mathcal{F})\\), y debe cumplir con las siguientes propiedades:\n\nNo negatividad y normalizaci√≥n: \\[\nP(A) \\geq 0 \\quad \\text{para todo } A \\in \\mathcal{F}, \\quad \\text{y} \\quad P(\\Omega) = 1\n\\]\nAditividad numerable: Si \\(\\{A_j\\}_{j \\in \\mathbb{N}}\\) es una familia de eventos disjuntos dos a dos (es decir, \\(A_i \\cap A_j = \\emptyset\\) si \\(i \\neq j\\)), entonces: \\[\nP\\left( \\bigcup_{j \\in \\mathbb{N}} A_j \\right) = \\sum_{j \\in \\mathbb{N}} P(A_j)\n\\]\n\n\n\nSea \\(P\\) una medida de probabilidad definida sobre \\((\\Omega, \\mathcal{F})\\). Entonces se cumple que:\n\n\\(P(\\emptyset) = 0\\)\nSi \\(A_1, A_2, \\ldots, A_n \\in \\mathcal{F}\\) y son disjuntos dos a dos, entonces:\n\\[\nP\\left( \\bigcup_{j=1}^n A_j \\right) = \\sum_{j=1}^n P(A_j)\n\\]\nSi \\(A \\in \\mathcal{F}\\), entonces:\n\\[\nP(A) + P(A^c) = 1\n\\]\nSi \\(A, B \\in \\mathcal{F}\\), entonces:\n\\[\nP(A) + P(B) = P(A \\cup B) + P(A \\cap B)\n\\]\nEn particular:\n\\[\nP(A \\cup B) \\leq P(A) + P(B)\n\\]\nSi \\(A, B \\in \\mathcal{F}\\) y \\(A \\subseteq B\\), entonces:\n\\[\nP(A) \\leq P(B)\n\\]\nPara eventos arbitrarios \\(A_1, \\ldots, A_n \\in \\mathcal{F}\\) (no necesariamente disjuntos), se cumple el principio de inclusi√≥n-exclusi√≥n:\n\\[\nP\\left( \\bigcup_{i=1}^n A_i \\right) =\n\\sum_{i=1}^n P(A_i)\n- \\sum_{i_1 &lt; i_2} P(A_{i_1} \\cap A_{i_2})\n+ \\sum_{i_1 &lt; i_2 &lt; i_3} P(A_{i_1} \\cap A_{i_2} \\cap A_{i_3})\n- \\cdots + (-1)^{n-1} P\\left( \\bigcap_{j=1}^n A_j \\right)\n\\]\n\n\n\n\n\nSea \\((\\Omega, \\mathcal{F}, P)\\) una tripleta donde:\n\n\\(\\Omega\\) es un conjunto no vac√≠o.\n\\(\\mathcal{F}\\) es una \\(\\sigma\\)-√°lgebra de subconjuntos de \\(\\Omega\\).\n\\(P : \\mathcal{F} \\to [0,1]\\) es una medida de probabilidad sobre \\((\\Omega, \\mathcal{F})\\).\n\nEste conjunto \\((\\Omega, \\mathcal{F}, P)\\) es lo que se conoce como un espacio de probabilidad. A partir de esta estructura, se puede desarrollar toda la teor√≠a moderna de la probabilidad, tanto para espacios finitos como infinitos.",
    "crumbs": [
      "Inicio",
      "Tema 3: Teor√≠a General de la Probabilidad"
    ]
  },
  {
    "objectID": "cursos/CA0721/teoria_general_proba_CA0721.html#probabilidad-condicional-e-independencia",
    "href": "cursos/CA0721/teoria_general_proba_CA0721.html#probabilidad-condicional-e-independencia",
    "title": "Teor√≠a General de Probabilidades",
    "section": "Probabilidad condicional e independencia",
    "text": "Probabilidad condicional e independencia\n\nProbabilidad condicional\nSean \\(A, B\\) dos eventos en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) con \\(P(B) &gt; 0\\). La probabilidad condicional de \\(A\\) dado \\(B\\) viene dada por:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\nTambi√©n se tiene:\n\\[\nP(B \\mid A) = \\frac{P(B \\cap A)}{P(A)} = \\frac{P(A \\cap B)}{P(A)}\n\\]\n\n\nIndependencia de eventos\nSean \\(A, B\\) dos eventos en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\). Se dice que \\(A\\) y \\(B\\) son independientes si:\n\\[\nP(A \\cap B) = P(A) \\cdot P(B)\n\\]\n\nSi no se cumple la propiedad anterior, los eventos se dicen dependientes.\n\nTambi√©n se define independencia de una familia de eventos \\((A_i)_{i \\in I}\\) en un espacio de probabilidad \\((\\Omega, \\mathcal{F}, P)\\) como:\n\\[\nP\\left(\\bigcap_{j \\in J} A_j\\right) = \\prod_{j \\in J} P(A_j)\n\\]\npara todo subconjunto finito no vac√≠o \\(J \\subseteq I\\).",
    "crumbs": [
      "Inicio",
      "Tema 3: Teor√≠a General de la Probabilidad"
    ]
  },
  {
    "objectID": "cursos/CA0721/teoria_general_proba_CA0721.html#f√≥rmulas-fundamentales",
    "href": "cursos/CA0721/teoria_general_proba_CA0721.html#f√≥rmulas-fundamentales",
    "title": "Teor√≠a General de Probabilidades",
    "section": "F√≥rmulas fundamentales",
    "text": "F√≥rmulas fundamentales\nSea \\((\\Omega, \\mathcal{F}, P)\\) un espacio de probabilidad.\nDecimos que una colecci√≥n \\(\\{E_i\\}_{i \\in \\mathbb{N}} \\subseteq \\mathcal{F}\\) es una partici√≥n de \\(\\Omega\\) si cumple que:\n\n\\(\\displaystyle \\bigcup_{i \\in \\mathbb{N}} E_i = \\Omega\\)\n\\(E_i \\cap E_j = \\emptyset\\) para todo \\(i \\ne j\\)\n\n\nTeorema de la probabilidad total\nSi \\(\\{E_i\\}_{i \\in \\mathbb{N}}\\) es una partici√≥n de \\((\\Omega, \\mathcal{F}, P)\\) y \\(B \\in \\mathcal{F}\\), entonces:\n\\[\nP(B) = \\sum_{i \\in \\mathbb{N}} P(B \\cap E_i)\n\\]\nSi adem√°s \\(P(E_i) &gt; 0\\) para todo \\(i\\), se tiene la versi√≥n condicional:\n\\[\nP(B) = \\sum_{i \\in \\mathbb{N}} P(B \\mid E_i) \\, P(E_i)\n\\]\n\n\nF√≥rmula de Bayes\nSean \\(A, B \\in \\mathcal{F}\\) con \\(P(A), P(B) &gt; 0\\). Entonces:\n\\[\nP(B \\mid A) = \\frac{P(B)}{P(A)} \\cdot P(A \\mid B)\n\\]\nM√°s generalmente, si \\(\\{E_i\\}_{i \\in \\mathbb{N}}\\) es una partici√≥n de \\(\\Omega\\) con \\(P(E_i) &gt; 0\\) y \\(B \\in \\mathcal{F}\\) tal que \\(P(B) &gt; 0\\), se cumple:\n\\[\nP(E_k \\mid B) = \\frac{P(B \\mid E_k) \\, P(E_k)}{\\sum\\limits_{i \\in \\mathbb{N}} P(B \\mid E_i) \\, P(E_i)}\n\\]\n\n\nDesigualdad de Boole\nSi \\(\\{A_n\\}_{n \\in \\mathbb{N}}\\) es una familia de eventos en \\((\\Omega, \\mathcal{F}, P)\\), entonces:\n\\[\nP\\left( \\bigcup_{n \\in \\mathbb{N}} A_n \\right) \\leq \\sum_{n \\in \\mathbb{N}} P(A_n)\n\\]\n\n\nContinuidad de la probabilidad\nSea \\(\\{A_n\\}_{n \\in \\mathbb{N}}\\) una sucesi√≥n de eventos en \\((\\Omega, \\mathcal{F}, P)\\).\n\nCreciente\n\\[\nA_n \\subseteq A_{n+1} \\;\\;\\forall n\\quad\\implies\\quad P\\left( \\bigcup_{n \\in \\mathbb{N}} A_n \\right) = \\lim_{n \\to \\infty} P(A_n)\n\\]\nDecreciente\n\\[\nA_{n+1} \\subseteq A_n\\;\\;\\forall n\\quad\\implies\\quad P\\left( \\bigcap_{n \\in \\mathbb{N}} A_n \\right) = \\lim_{n \\to \\infty} P(A_n)\n\\]\n\n\n\nLemas de Borel‚ÄìCantelli\nSea \\(\\{A_n\\}_{n \\in \\mathbb{N}}\\) una sucesi√≥n de eventos en \\((\\Omega, \\mathcal{F}, P)\\). Denotamos:\n\\[\n\\{A_n \\text{ i.o.}\\} := \\bigcap_{n=1}^{\\infty} \\bigcup_{k = n}^{\\infty} A_k\n\\]\n\nNota: La notaci√≥n ‚Äú\\(A_n\\) i.o.‚Äù proviene del ingl√©s infinitely often, y se refiere al evento de que ocurran infinitamente muchos de los eventos \\(A_n\\). Es decir, que sin importar cu√°n lejos avancemos en la sucesi√≥n, siempre habr√° algunos \\(A_k\\) con \\(k &gt; n\\) que se cumplan.\nIntuitivamente, \\(A_n\\) ocurre infinitas veces si, a partir de cierto punto, sigue ocurriendo de forma repetida (aunque no necesariamente de forma continua).\n\n\nPrimer lema de Borel‚ÄìCantelli:\n\\[\n\\sum\\limits_{n=1}^\\infty P(A_n) &lt; \\infty \\quad\\implies\\quad P(A_n \\text{ i.o.}) = 0\n\\]\nSegundo lema de Borel‚ÄìCantelli:\n\\[\n\\left.\\begin{array} AA_n \\text{ son independientes} \\\\ \\sum\\limits_{n=1}^\\infty P(A_n) = \\infty \\end{array}\\right\\}\\quad\\implies\\quad P(A_n \\text{ i.o.}) = 1\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 3: Teor√≠a General de la Probabilidad"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "¬øQui√©n Sos?",
    "section": "",
    "text": "Hola soy Diego!\n¬øCu√°nto es 1+1?\n\n1 + 1\n\n[1] 2\n\n\nPod√©s visualizar mi curr√≠culum directamente en esta p√°gina:\n\n\n\nTambi√©n pod√©s descargarlo directamente desde este enlace:\nüëâ Descargar CV en PDF"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Diego Alberto Vega V√≠quez",
    "section": "",
    "text": "Bienvenido a mi sitio web personal. Este espacio ha sido creado como una plataforma para compartir mis apuntes, recursos y materiales de estudio a lo largo de mi formaci√≥n acad√©mica.\n\n\nEl prop√≥sito principal de esta p√°gina es organizar de forma clara y accesible mis apuntes de distintos cursos, permiti√©ndome consultarlos f√°cilmente desde cualquier lugar, as√≠ como compartirlos con otras personas interesadas en los temas que estudio.\nAqu√≠ encontrar√°s:\n\nüìö Apuntes por curso, organizados por tema.\nüßë‚Äçüíº Una breve secci√≥n sobre m√≠, con enlaces a mis redes profesionales.\nüîç Una estructura clara y navegable, pensada para facilitar el aprendizaje y la revisi√≥n.\n\n\n\n\nEn la barra superior de navegaci√≥n pod√©s acceder a:\n\nInicio (esta p√°gina)\nSobre m√≠ ‚Äì Una presentaci√≥n personal y formas de contacto\nCursos ‚Äì Acceso a los apuntes clasificados por materia\n\nGracias por visitar este espacio. ¬°Espero que el contenido te sea √∫til!"
  },
  {
    "objectID": "index.html#objetivo-del-sitio",
    "href": "index.html#objetivo-del-sitio",
    "title": "Diego Alberto Vega V√≠quez",
    "section": "",
    "text": "El prop√≥sito principal de esta p√°gina es organizar de forma clara y accesible mis apuntes de distintos cursos, permiti√©ndome consultarlos f√°cilmente desde cualquier lugar, as√≠ como compartirlos con otras personas interesadas en los temas que estudio.\nAqu√≠ encontrar√°s:\n\nüìö Apuntes por curso, organizados por tema.\nüßë‚Äçüíº Una breve secci√≥n sobre m√≠, con enlaces a mis redes profesionales.\nüîç Una estructura clara y navegable, pensada para facilitar el aprendizaje y la revisi√≥n."
  },
  {
    "objectID": "index.html#qu√©-pod√©s-explorar",
    "href": "index.html#qu√©-pod√©s-explorar",
    "title": "Diego Alberto Vega V√≠quez",
    "section": "",
    "text": "En la barra superior de navegaci√≥n pod√©s acceder a:\n\nInicio (esta p√°gina)\nSobre m√≠ ‚Äì Una presentaci√≥n personal y formas de contacto\nCursos ‚Äì Acceso a los apuntes clasificados por materia\n\nGracias por visitar este espacio. ¬°Espero que el contenido te sea √∫til!"
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#variables-aleatorias-continuas",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#variables-aleatorias-continuas",
    "title": "Variables Aleatorias",
    "section": "Variables aleatorias continuas",
    "text": "Variables aleatorias continuas\nSon aquellas para las cuales \\(X[\\Omega]\\) es un intervalo.\n\nFunci√≥n de distribuci√≥n\nLas variables aleatorias absolutamente continuas son aquellas en las cuales existe una funci√≥n \\(f_X(x)\\) no negativa tal que:\n\\[\nF_X(t) = Pr(X \\leq t) = \\int_{-\\infty}^t f_X(u)\\,du\n\\]\nDonde:\n\n\\(F_X(t)\\) es la funci√≥n de distribuci√≥n de \\(X\\).\n\\(f_X(x)\\) es la funci√≥n de densidad de probabilidad de \\(X\\) (p.d.f de \\(X\\)).\nSe cumple que \\(Pr(X = a) = 0\\)‚ÄÉpara todo \\(a \\in \\mathbb{R}\\).\nCuando \\(f_X(x)\\) es continua, entonces \\(\\dfrac{d}{dx}F_X(x) = f_X(x)\\).\nDonde \\(F_X(x)\\) es derivable,‚ÄÉ\\(\\dfrac{d}{dx}F_X(x) = f_X(x)\\).\n\n\n\nTransformaciones\nSea \\(X\\) una v.a. absolutamente continua en un e.p. \\((\\Omega, \\mathcal{F}, P)\\).\nSea \\(f_X(x)\\) su funci√≥n de densidad.\nSea \\(Y = g(X)\\) donde \\(g\\) es una funci√≥n estrictamente mon√≥tona.\nDefina:\n\n\\(\\mathcal{X} = \\{x : f_X(x) &gt; 0\\}\\)\n\\(\\mathcal{Y} = \\{y : y = g(x) \\text{ para alg√∫n } x \\in \\mathcal{X}\\}\\)\n\nSi se cumple que:\n\n\\(f_X(x)\\) es continua en \\(\\mathcal{X}\\)\n\\(g^{-1}(y)\\) tiene derivada continua en \\(\\mathcal{Y}\\)\n\nentonces \\(Y\\) es una v.a. absolutamente continua y\n\\[\nf_Y(y) =\n\\begin{cases}\nf_X\\left(g^{-1}(y)\\right) \\cdot \\left| \\dfrac{d}{dy}g^{-1}(y) \\right| & \\text{si } y \\in \\mathcal{Y} \\\\\n0 & \\text{si no}\n\\end{cases}\n\\]\n\n\n\nEsperanza\n\nSea \\(X\\) una v.a continua con f.d.p. \\(f_X(x)\\), se define la esperanza como:\n\n\\[\n\\mathbb{E}[X] = \\int_{-\\infty}^{+\\infty} x \\cdot f_X(x)\\, dx\n\\]\nSiempre y cuando esta integral sea absolutamente convergente.\n\n\nLey del estad√≠stico inconsciente\nSi \\(g: \\mathbb{R} \\to \\mathbb{R}\\) es continua, entonces:\n\\[\n\\mathbb{E}[g(X)] = \\int_{-\\infty}^{+\\infty} g(x) \\cdot f_X(x)\\, dx\n\\]\nSiempre y cuando esta integral converja absolutamente.\n\n\nMomentos y Varianza\nSea \\(X\\) una v.a. discreta en un e.p \\((\\Omega, \\mathcal{F}, P)\\) y sea \\(n &gt; 0\\):\n\nEl \\(n\\)‚Äì√©simo momento de \\(X\\) se define como \\(\\mathbb{E}[X^n]\\)\nSi \\(\\mu = \\mathbb{E}[X]\\), el \\(n\\)‚Äì√©simo momento centrado se define como:\n\n\\[\n\\mathbb{E}\\left[(X - \\mu)^n\\right]\n\\]\n\nEl segundo momento centrado es particularmente importante:\n\n\\[\n\\sigma^2 = \\text{Var}[X] = \\mathbb{E} \\left[ (X - \\mathbb{E}[X])^2 \\right] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n\\]\nSiempre y cuando\n\\[\n\\int_{-\\infty}^{+\\infty} x^2 f_X(x)\\, dx\n\\]\nconverja.\n\nPropiedades de la varianza\nSean \\(X\\) e \\(Y\\) dos variables aleatorias y sea \\(c\\) una constante, entonces:\n\n\\(\\operatorname{Var}(c) = 0\\)\n\\(\\operatorname{Var}(X + c) = \\operatorname{Var}(X)\\)\n\\(\\operatorname{Var}(cX) = c^2 \\cdot \\operatorname{Var}(X)\\)\nSi \\(X\\) e \\(Y\\) son variables aleatorias independientes, entonces:\n\n\\[\n\\operatorname{Var}(X + Y) = \\operatorname{Var}(X) + \\operatorname{Var}(Y)\n\\]\n\n\n\nDesviaci√≥n est√°ndar\n\\[\n\\sigma_X = \\sqrt{\\text{Var}[X]}\n\\]\n\n\nF√≥rmula de convoluci√≥n continua\nSean \\(X\\), \\(Y\\) v.a. absolutamente continuas e independientes en un e.p. \\((\\Omega, \\mathcal{F}, P)\\).\nEntonces \\(Z = X + Y\\) es una v.a. absolutamente continua y\n\\[\nf_{X+Y}(z) = \\int_{-\\infty}^{\\infty} f_X(r) f_Y(z - r)\\, dr\n\\]\nEsta f√≥rmula permite demostrar la relaci√≥n:\n\\[\n\\varphi_{X+Y}(t) = \\varphi_X(t) \\cdot \\varphi_Y(t) \\quad \\forall\\, t \\in \\mathbb{R}\n\\]\ndonde \\(X\\) y \\(Y\\) son v.a. absolutamente continuas e independientes.\n\n^4La prueba del siguiente resultado involucra un poco de vectores aleatorios. No obstante, la f√≥rmula puede ser f√°cilmente recordada por su similitud con la f√≥rmula para el caso discreto.\n\n\n\nFunciones importantes\nSea \\(X\\) una v.a. absolutamente continua con funci√≥n de densidad \\(f_X(x)\\):\n\n\n\n\n\n\nFunci√≥n Caracter√≠stica\n\n\n\n\\[\n\\varphi_X(t) = \\mathbb{E}[e^{itX}] = \\int_{-\\infty}^{+\\infty} e^{itx} \\cdot f_X(x) \\, dx\n\\]\nEsta est√° definida para todo \\(t \\in \\mathbb{R}\\).\n\n\n\n\n\n\n\n\nFunci√≥n Generadora de Momentos\n\n\n\n\\[\nM_X(t) = \\mathbb{E}[e^{tX}] = \\int_{-\\infty}^{+\\infty} e^{tx} \\cdot f_X(x) \\, dx\n\\]\nPara todos aquellos valores de \\(t\\) donde dicho valor esperado exista.\n\n\n\n\n\n\n\n\nFunci√≥n Generadora de Probabilidades\n\n\n\n\\[\nG_X(t) = \\mathbb{E}[t^X] = \\int_{-\\infty}^{+\\infty} t^x \\cdot f_X(x) \\, dx\n\\]\nPara todos aquellos valores de \\(t\\) donde dicho valor esperado exista.\n\n\n\n\nDistribuciones continuas comunes\n\n\n\n\n\n\nDistribuci√≥n uniforme\n\n\n\n\\[X \\sim {U}[a, b]\\]\nSu funci√≥n de densidad viene dada por:\n\\[\nf(x) =\n\\begin{cases}\n\\frac{1}{b - a} & \\text{si } x \\in [a, b] \\\\\\\\\n0 & \\text{si } x \\notin [a, b]\n\\end{cases}\n\\]\nPara este tipo de variable se cumple que:\n\n\\(\\mathbb{E}[X] = \\dfrac{a + b}{2}\\)\n\\(\\operatorname{Var}(X) = \\dfrac{(b - a)^2}{12}\\)\n\\(M_X(t) =\n\\begin{cases}\n\\dfrac{e^{tb} - e^{ta}}{t(b - a)} & t \\neq 0 \\\\\\\\\n1 & t = 0\n\\end{cases}\\)\n\n\n\n\nFunci√≥n Gamma\nLa funci√≥n Gamma es una extensi√≥n del factorial para n√∫meros reales (y complejos) positivos. Est√° definida por la integral impropia:\n\\[\n\\Gamma(\\alpha) = \\int_0^{+\\infty} x^{\\alpha - 1} e^{-x} \\, dx \\qquad \\forall \\ \\alpha &gt; 0\n\\]\n\nPropiedades fundamentales\n\nRecurrencia: \\[\n\\Gamma(a + 1) = a \\cdot \\Gamma(a) \\qquad \\text{para } a &gt; 0\n\\]\nEnteros positivos: \\[\n\\Gamma(n) = (n - 1)! \\qquad \\text{para } n \\in \\mathbb{N}^*\n\\]\nRelaci√≥n generalizada: \\[\n\\Gamma(a + n) = \\Gamma(a) \\cdot \\prod_{j = 1}^n (a + j - 1) \\qquad \\text{para } a &gt; 0, \\ n \\in \\mathbb{N}\n\\]\nEvaluaci√≥n especial: \\[\n\\Gamma\\left(\\frac{1}{2}\\right) = 2 \\int_0^{+\\infty} e^{-x^2} \\, dx = \\sqrt{\\pi}\n\\]\n\n\n\nF√≥rmula de reflexi√≥n de Euler\nAunque su demostraci√≥n escapa al curso, existe la identidad conocida como f√≥rmula de reflexi√≥n de Euler:\n\\[\n\\Gamma(z)\\Gamma(1 - z) = \\frac{\\pi}{\\sin(\\pi z)} \\qquad \\text{para } z \\in (0,1)\n\\]\n\n\n\n\n\n\nDistribuci√≥n Gamma\n\n\n\n\\[X \\sim \\Gamma(\\alpha, \\beta)\\]\nCon par√°metro de forma \\(\\alpha\\) y par√°metro de escala \\(\\beta\\) (aqu√≠ \\(\\alpha &gt; 0\\) y \\(\\beta &gt; 0\\)).\n\\[\nf(x) =\n\\begin{cases}\n\\dfrac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x} & x &gt; 0 \\\\\\\\\n0 & \\text{si no}\n\\end{cases}\n\\]\ndonde \\(\\Gamma(\\alpha) = \\displaystyle\\int_0^{+\\infty} x^{\\alpha - 1} e^{-x} dx\\)\n\n\\(\\mathbb{E}[X] = \\dfrac{\\alpha}{\\beta}\\)\n\\(\\operatorname{Var}(X) = \\dfrac{\\alpha}{\\beta^2}\\)\n\\(M_X(t) = \\dfrac{\\beta^\\alpha}{(\\beta - t)^\\alpha}\\) para \\(t &lt; \\beta\\)\n\n\n\n\nLa distribuci√≥n exponencial de par√°metro \\(\\beta\\) es una \\(\\Gamma(1, \\beta)\\). Su funci√≥n de densidad viene dada por\n\\[\n\\beta e^{-\\beta x} \\quad \\text{para} \\quad x \\geq 0\n\\]\nLa distribuci√≥n de Erlang corresponde a una \\(\\Gamma(n, \\beta)\\) donde \\(n \\in \\mathbb{N}\\). Su funci√≥n de densidad viene dada por\n\\[\n\\dfrac{(\\beta x)^{n-1}}{(n - 1)!} \\, \\beta \\, e^{-\\beta x} \\quad \\text{para} \\quad x &gt; 0\n\\]\nLa distribuci√≥n Chi-cuadrado con \\(n\\) grados de libertad ,, (\\(\\chi^2_n\\)) corresponde a una\n\\(\\Gamma\\left(\\dfrac{n}{2}, \\dfrac{1}{2}\\right)\\) donde \\(n \\in \\mathbb{N}\\). Su funci√≥n de densidad viene dada por\n\\[\n\\left(\\dfrac{1}{2}\\right)^{n/2} \\dfrac{x^{n/2 - 1}}{\\Gamma(n/2)} e^{-x/2} \\quad \\text{para} \\quad x &gt; 0\n\\]\n\n\n\n\nFunci√≥n Beta\nSea la variable aleatoria \\(X\\) con par√°metros \\(a, b\\) (donde \\(a &gt; 0\\) y \\(b &gt; 0\\)), se dice que \\(X\\) sigue una distribuci√≥n Beta si su funci√≥n de densidad viene dada por\n\\[\nf(x) =\n\\begin{cases}\n\\dfrac{1}{\\beta(a, b)} x^{a - 1} (1 - x)^{b - 1} & \\text{si } 0 &lt; x &lt; 1 \\\\\n0 & \\text{si no}\n\\end{cases}\n\\]\ndonde \\[\n\\beta(a, b) = \\int_0^1 x^{a - 1}(1 - x)^{b - 1} dx.\n\\]\nEn este caso se escribe \\(X \\sim \\beta(a, b)\\).\nLa funci√≥n beta \\(\\beta(a, b)\\) satisface:\n\\[\n\\beta(a, b) = \\dfrac{\\Gamma(a) \\Gamma(b)}{\\Gamma(a + b)}\n\\]\n\nNota: No es dif√≠cil ver que la distribuci√≥n \\(\\beta(1,1)\\) coincide con la distribuci√≥n uniforme \\(U([0,1])\\).\n\n\nOtras representaciones de la funci√≥n Beta\nAunque no es especialmente relevante para nuestros prop√≥sitos, en ocasiones es √∫til tener presente que para \\(a &gt; 0\\) y \\(b &gt; 0\\) se cumple que:\n\nHaciendo el cambio de variable \\(x = \\operatorname{sen}^2(\\theta)\\) se obtiene:\n\n\\[\n\\dfrac{1}{2} \\beta(a, b) = \\int_0^{\\pi/2} \\operatorname{sen}^{2a-1}(\\theta) \\cos^{2b - 1}(\\theta) \\, d\\theta\n\\]\n\nHaciendo el cambio de variable \\(x = \\dfrac{z}{1 + z}\\) se obtiene:\n\n\\[\n\\beta(a, b) = \\int_0^{+\\infty} \\dfrac{z^{a - 1}}{(1 + z)^{a + b}} \\, dz\n\\]\n\n\n\n\n\n\nDistribuci√≥n Beta\n\n\n\n\\[X \\sim \\text{Beta}(a, b)\\]\nCon par√°metros \\(a, b\\) (aqu√≠ \\(a &gt; 0\\) y \\(b &gt; 0\\)).\n\\[\nf(x) =\n\\begin{cases}\n\\dfrac{1}{\\beta(a, b)} x^{a - 1} (1 - x)^{b - 1} & 0 &lt; x &lt; 1 \\\\\\\\\n0 & \\text{si no}\n\\end{cases}\n\\]\ndonde \\(\\beta(a, b) = \\displaystyle\\int_0^1 x^{a - 1}(1 - x)^{b - 1} dx\\)\n\n\\(\\mathbb{E}[X] = \\dfrac{a}{a + b}\\)\n\\(\\operatorname{Var}(X) = \\dfrac{ab}{(a + b)^2 (a + b + 1)}\\)\n\\(M_X(t) = 1 + \\displaystyle\\sum_{n=1}^{\\infty} \\left( \\prod_{r=0}^{n-1} \\dfrac{a + r}{a + b + r} \\right) \\dfrac{t^n}{n!}\\)\n\n\n\n\n\n\n\n\n\nDistribuci√≥n Weibull\n\n\n\n\\[X \\sim \\text{Weibull}(\\alpha, \\lambda)\\]\nSu funci√≥n de densidad es:\n\\[\nf(x) = \\lambda \\alpha (\\lambda x)^{\\alpha - 1} e^{-(\\lambda x)^\\alpha} \\quad x &gt; 0\n\\]\nCon \\(\\alpha, \\lambda &gt; 0\\), donde \\(\\alpha\\) es el par√°metro de forma y \\(\\lambda\\) es el par√°metro de escala de la distribuci√≥n.\n\n\n\n\n\n\n\n\nDistribuci√≥n Normal\n\n\n\n\\[X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\]\nCon par√°metros \\(\\mu\\), \\(\\sigma^2\\) (aqu√≠ \\(\\mu &gt; 0\\) y \\(\\sigma^2 &gt; 0\\)).\nSu funci√≥n de densidad viene dada por:\n\\[\nf(x) = \\dfrac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n\\]\nSe cumple que:\n\n\\(\\mathbb{E}[X] = \\mu\\)\n\\(\\operatorname{Var}(X) = \\sigma^2\\)\n\\(M_X(t) = e^{t\\mu + \\frac{t^2 \\sigma^2}{2}}\\)\n\nLa funci√≥n de distribuci√≥n normal est√°ndar es un caso especial de la funci√≥n donde \\(\\mu = 0\\) y \\(\\sigma = 1\\).\n\n\n\n\n\n\n\n\nDistribuci√≥n de Cauchy\n\n\n\n\\[X \\sim \\text{Cauchy}(x_0, \\gamma)\\]\nCentrada en \\(x_0\\) y con par√°metro \\(\\gamma\\).\nSu funci√≥n de densidad viene dada por:\n\\[\nf(x) = \\dfrac{\\gamma}{\\pi \\left((x - x_0)^2 + \\gamma^2 \\right)}\n\\]\nSe cumple que:\n\n\\(\\mathbb{E}[X]\\) no existe\nLa funci√≥n generadora de momentos solo existe para \\(t = 0\\)\nSu funci√≥n caracter√≠stica es:\n\n\\[\n\\varphi_X(t) = e^{itx_0 - \\gamma \\lvert t \\rvert}\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 4: Variables Aleatorias"
    ]
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#cuantiles",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#cuantiles",
    "title": "Variables Aleatorias",
    "section": "Cuantiles",
    "text": "Cuantiles\nSea \\(p \\in (0, 1]\\).\nEl cuantil \\(p\\) de una variable aleatoria \\(X\\) es el valor \\(c_p\\) m√°s peque√±o tal que:\n\\[\nF_X(c_p) \\geq p\n\\]\nes decir, \\(c_p\\) es el valor m√°s peque√±o donde la funci√≥n de distribuci√≥n acumula al menos una probabilidad \\(p\\).\nEl cuantil para \\(p = 0.5\\) se llama mediana.",
    "crumbs": [
      "Inicio",
      "Tema 4: Variables Aleatorias"
    ]
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#moda",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#moda",
    "title": "Variables Aleatorias",
    "section": "Moda",
    "text": "Moda\nLa moda de \\(X\\) es el valor \\(x^*\\) donde la funci√≥n de densidad o probabilidad alcanza su m√°ximo.\n\nNota: En distribuciones absolutamente continuas, la moda puede no existir; en distribuciones discretas, la moda siempre existe.",
    "crumbs": [
      "Inicio",
      "Tema 4: Variables Aleatorias"
    ]
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#funciones-importantes-2",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#funciones-importantes-2",
    "title": "Variables Aleatorias",
    "section": "Funciones importantes",
    "text": "Funciones importantes\nSean \\(X, Y\\) dos variables aleatorias en un e.p \\((\\Omega, \\mathcal{F}, P)\\) que toman valores en \\(\\mathbb{N} \\cup \\{0\\}\\).\n\nCaso discreto\n\n\n\n\n\n\n\n\nFunci√≥n\nExpresi√≥n\nCondici√≥n de validez\n\n\n\n\nCaracter√≠stica\n\\[\\begin{align*} \\varphi_X(t) &= \\mathbb{E}[e^{itX}] \\\\ &= \\sum_{n \\in \\text{Im}(X)} e^{itn} \\cdot P[X = n] \\end{align*}\\]\nDefinida para todo \\(t \\in \\mathbb{R}\\)\n\n\nGeneradora de Momentos (MGF)\n\\[\\begin{align*} M_X(t) &= \\mathbb{E}[e^{tX}] \\\\ &= \\sum_{n \\in \\text{Im}(X)} e^{tn} \\cdot P[X = n] \\end{align*}\\]\nV√°lida para todo \\(t\\) donde el valor esperado exista\n\n\nGeneradora de Probabilidades (PGF)\n\\[\\begin{align*} G_X(t) &= \\mathbb{E}[t^X] \\\\ &= \\sum_{n \\in \\text{Im}(X)} t^n \\cdot P[X = n] \\end{align*}\\]\nV√°lida para todo \\(t\\) donde el valor esperado exista\n\n\n\n\n\nCaso continuo\n\n\n\n\n\n\n\n\nFunci√≥n\nExpresi√≥n\nCondici√≥n de validez\n\n\n\n\nCaracter√≠stica\n\\[\\begin{align*} \\varphi_X(t) &= \\mathbb{E}[e^{itX}] \\\\ &= \\int_{-\\infty}^{+\\infty} e^{itx} \\cdot f_X(x) \\, dx \\end{align*}\\]\nDefinida para todo \\(t \\in \\mathbb{R}\\)\n\n\nGeneradora de Momentos (MGF)\n\\[\\begin{align*} M_X(t) &= \\mathbb{E}[e^{tX}] \\\\ &= \\int_{-\\infty}^{+\\infty} e^{tx} \\cdot f_X(x) \\, dx \\end{align*}\\]\nV√°lida para todo \\(t\\) donde el valor esperado exista\n\n\nGeneradora de Probabilidades (PGF)\n\\[\\begin{align*} G_X(t) &= \\mathbb{E}[t^X] \\\\ &= \\int_{-\\infty}^{+\\infty} t^x \\cdot f_X(x) \\, dx \\end{align*}\\]\nV√°lida para todo \\(t\\) donde el valor esperado exista\n\n\n\n\n\nPropiedades de la funci√≥n caracter√≠stica\n\nLa funci√≥n caracter√≠stica de \\(X\\) determina su distribuci√≥n, y viceversa.\nSi \\(n \\in \\mathbb{N}\\) y \\(\\mathbb{E}[|X|^n] &lt; \\infty\\), entonces existe \\(\\varphi_X^{(n)}(t)\\) y se cumple: \\[\n\\mathbb{E}[X^n] = i^{-n} \\cdot \\varphi_X^{(n)}(0)\n\\]\nTambi√©n: \\[\n\\varphi_X(t) = \\sum_{k = 0}^{n} \\dfrac{(it)^k}{k!} \\mathbb{E}[X^k] + o(|t|^k)\n\\]\n\n\n\nPropiedades de la funci√≥n generadora de momentos\n\nSi existe \\(M_X(t)\\) en un intervalo \\(I = ] -s, s[\\) para alg√∫n \\(s &gt; 0\\), entonces:\n\n\\(\\mathbb{E}[X^n] &lt; \\infty \\quad \\forall t \\in I\\)\n\\(M_X(t) = \\sum\\limits_{n = 0}^{+\\infty} \\dfrac{\\mathbb{E}[X^n]}{n!} t^n\\)\nEn particular, \\(\\mathbb{E}[X^n] = M_X^{(n)}(0)\\)\n\nSi \\(X, Y\\) son independientes \\(\\forall t\\), entonces: \\[\nM_{X+Y}(t) = M_X(t) M_Y(t)\n\\]\nSi \\(M_X(t) = M_Y(t)\\) en un abierto que contiene a 0, entonces: \\[\nF_X(t) = F_Y(t)\n\\]\n\n\n\nPropiedades de la funci√≥n generadora de probabilidades\n\nSe cumple que \\(\\forall n \\in \\mathbb{N}\\): \\[\nP[X = n] = \\dfrac{G_X^{(n)}(0)}{n!}\n\\]\nSi \\(X, Y\\) son independientes \\(\\forall t\\), entonces: \\[\nG_{X+Y}(t) = G_X(t) G_Y(t)\n\\]\nSi \\(G_X(t) = G_Y(t)\\) en un abierto que contiene a 0, entonces: \\[\nF_X(t) = F_Y(t)\n\\]\nSi \\(X\\) es tal que \\(\\exists \\mathbb{E}[|X|^n]\\), entonces: \\[\nG_X^{(n)}(X) = \\mathbb{E}[X(X-1)(X-2)\\cdots(X - n + 1)]\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 4: Variables Aleatorias"
    ]
  },
  {
    "objectID": "cursos/CA0721/variables_aleatorias_CA0721.html#funciones-importantes-3",
    "href": "cursos/CA0721/variables_aleatorias_CA0721.html#funciones-importantes-3",
    "title": "Variables Aleatorias",
    "section": "Funciones importantes",
    "text": "Funciones importantes\nSean \\(X, Y\\) dos variables aleatorias en un e.p \\((\\Omega, \\mathcal{F}, P)\\) que toman valores en \\(\\mathbb{N} \\cup \\{0\\}\\).\n\nCaso discreto\n\n\n\n\n\n\n\n\nFunci√≥n\nExpresi√≥n\nCondici√≥n de validez\n\n\n\n\nCaracter√≠stica\n\\[\\begin{align*} \\varphi_X(t) &= \\mathbb{E}[e^{itX}] \\\\ &= \\sum_{n \\in \\text{Im}(X)} e^{itn} \\cdot P[X = n] \\end{align*}\\]\nDefinida para todo \\(t \\in \\mathbb{R}\\)\n\n\nGeneradora de Momentos (MGF)\n\\[\\begin{align*} M_X(t) &= \\mathbb{E}[e^{tX}] \\\\ &= \\sum_{n \\in \\text{Im}(X)} e^{tn} \\cdot P[X = n] \\end{align*}\\]\nV√°lida para todo \\(t\\) donde el valor esperado exista\n\n\nGeneradora de Probabilidades (PGF)\n\\[\\begin{align*} G_X(t) &= \\mathbb{E}[t^X] \\\\ &= \\sum_{n \\in \\text{Im}(X)} t^n \\cdot P[X = n] \\end{align*}\\]\nV√°lida para todo \\(t\\) donde el valor esperado exista\n\n\n\n\n\n\nCaso continuo\n\n\n\nCaracter√≠stica\n\\[\\begin{align*}\n\\varphi_X(t) &= \\mathbb{E}[e^{itX}] \\\\\n             &= \\int_{-\\infty}^{+\\infty} e^{itx} \\cdot f_X(x) \\, dx\n\\end{align*}\\] Est√° definida \\(\\forall t \\in \\mathbb{R}\\)\n\n\n\nGeneradora de Momentos\n\\[\\begin{align*}\nM_X(t) &= \\mathbb{E}[e^{tX}] \\\\\n       &= \\int_{-\\infty}^{+\\infty} e^{tx} \\cdot f_X(x) \\, dx\n\\end{align*}\\] V√°lida para todo \\(t\\) donde dicho valor esperado exista.\n\n\n\nGeneradora de Probabilidades\n\\[\\begin{align*}\nG_X(t) &= \\mathbb{E}[t^X] \\\\\n       &= \\int_{-\\infty}^{+\\infty} t^x \\cdot f_X(x) \\, dx\n\\end{align*}\\] V√°lida para todo \\(t\\) donde dicho valor esperado exista.\n\n\n\n\n\n\nPropiedades de la funci√≥n caracter√≠stica\n\nLa funci√≥n caracter√≠stica de \\(X\\) determina su distribuci√≥n, y viceversa.\nSi \\(n \\in \\mathbb{N}\\) y \\(\\mathbb{E}[|X|^n] &lt; \\infty\\), entonces existe \\(\\varphi_X^{(n)}(t)\\) y se cumple: \\[\n\\mathbb{E}[X^n] = i^{-n} \\cdot \\varphi_X^{(n)}(0)\n\\]\nTambi√©n: \\[\n\\varphi_X(t) = \\sum_{k = 0}^{n} \\dfrac{(it)^k}{k!} \\mathbb{E}[X^k] + o(|t|^k)\n\\]\n\n\n\n\nPropiedades de la funci√≥n generadora de momentos\n\nSi existe \\(M_X(t)\\) en un intervalo \\(I = ] -s, s[\\) para alg√∫n \\(s &gt; 0\\), entonces:\n\n\\(\\mathbb{E}[X^n] &lt; \\infty \\quad \\forall t \\in I\\)\n\\(M_X(t) = \\sum\\limits_{n = 0}^{+\\infty} \\dfrac{\\mathbb{E}[X^n]}{n!} t^n\\)\nEn particular, \\(\\mathbb{E}[X^n] = M_X^{(n)}(0)\\)\n\nSi \\(X, Y\\) son independientes \\(\\forall t\\), entonces: \\[\nM_{X+Y}(t) = M_X(t) M_Y(t)\n\\]\nSi \\(M_X(t) = M_Y(t)\\) en un abierto que contiene a 0, entonces: \\[\nF_X(t) = F_Y(t)\n\\]\n\n\n\n\nPropiedades de la funci√≥n generadora de probabilidades\n\nSe cumple que \\(\\forall n \\in \\mathbb{N}\\): \\[\nP[X = n] = \\dfrac{G_X^{(n)}(0)}{n!}\n\\]\nSi \\(X, Y\\) son independientes \\(\\forall t\\), entonces: \\[\nG_{X+Y}(t) = G_X(t) G_Y(t)\n\\]\nSi \\(G_X(t) = G_Y(t)\\) en un abierto que contiene a 0, entonces: \\[\nF_X(t) = F_Y(t)\n\\]\nSi \\(X\\) es tal que \\(\\exists \\mathbb{E}[|X|^n]\\), entonces: \\[\nG_X^{(n)}(X) = \\mathbb{E}[X(X-1)(X-2)\\cdots(X - n + 1)]\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 4: Variables Aleatorias"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html",
    "title": "Vectores Aleatorios",
    "section": "",
    "text": "Un vector aleatorio (v.e) sobre un e.p \\((\\Omega, \\mathcal{F}, P)\\) es una funci√≥n\n\\[\nX : \\Omega \\to \\mathbb{R}^n \\quad | \\quad X^{-1}(B) \\in \\mathcal{F} \\quad \\forall B \\in \\mathcal{B}(\\mathbb{R}^n)\n\\]\ndonde \\(\\mathcal{B}(\\mathbb{R}^n)\\) denota la \\(\\sigma\\)-√°lgebra de Borel en \\(\\mathbb{R}^n\\), es decir \\(\\mathcal{B}(\\mathbb{R}^n)\\) es la \\(\\sigma\\)-√°lgebra generada por todos los conjuntos abiertos de \\(\\mathbb{R}^n\\).\nPara mantener la presentaci√≥n sencilla se expondr√° la teor√≠a usando vectores \\((X, Y)\\) aunque la teor√≠a es f√°cilmente extendible a vectores en m√°s dimensiones.",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#definici√≥n",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#definici√≥n",
    "title": "Vectores Aleatorios",
    "section": "",
    "text": "Un vector aleatorio (v.e) sobre un e.p \\((\\Omega, \\mathcal{F}, P)\\) es una funci√≥n\n\\[\nX : \\Omega \\to \\mathbb{R}^n \\quad | \\quad X^{-1}(B) \\in \\mathcal{F} \\quad \\forall B \\in \\mathcal{B}(\\mathbb{R}^n)\n\\]\ndonde \\(\\mathcal{B}(\\mathbb{R}^n)\\) denota la \\(\\sigma\\)-√°lgebra de Borel en \\(\\mathbb{R}^n\\), es decir \\(\\mathcal{B}(\\mathbb{R}^n)\\) es la \\(\\sigma\\)-√°lgebra generada por todos los conjuntos abiertos de \\(\\mathbb{R}^n\\).\nPara mantener la presentaci√≥n sencilla se expondr√° la teor√≠a usando vectores \\((X, Y)\\) aunque la teor√≠a es f√°cilmente extendible a vectores en m√°s dimensiones.",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#funci√≥n-de-distribuci√≥n",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#funci√≥n-de-distribuci√≥n",
    "title": "Vectores Aleatorios",
    "section": "Funci√≥n de distribuci√≥n",
    "text": "Funci√≥n de distribuci√≥n\nLa funci√≥n de distribuci√≥n conjunta de un vector aleatorio continuo \\((X, Y)\\) corresponde a la funci√≥n\n\\[\nF_{X,Y}(x, y) = P[X \\leq x, Y \\leq y]\n\\]\nSe pueden recuperar las funciones de distribuci√≥n mediante\n\\[\nF_X(x) = \\lim_{y \\to +\\infty} F_{X,Y}(x, y), \\quad\nF_Y(y) = \\lim_{x \\to +\\infty} F_{X,Y}(x, y)\n\\]\nEn el caso de vectores aleatorios absolutamente continuos existe una funci√≥n no negativa \\(f_{X,Y}(x, y)\\) tal que\n\\[\nF_{X,Y}(x, y) = \\int_{-\\infty}^x \\int_{-\\infty}^y f_{X,Y}(u, v) \\, dv \\, du\n\\]\nA \\(f_{X,Y}(x, y)\\) se le dice la funci√≥n de densidad conjunta (joint pdf) de \\((X, Y)\\).\nEn particular, cuando \\(f_{X,Y}(x, y)\\) es continua, se cumple que\n\\[\n\\frac{\\partial^2}{\\partial x \\, \\partial y} F_{X,Y}(x, y) = f_{X,Y}(x, y)\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#densidades-marginales",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#densidades-marginales",
    "title": "Vectores Aleatorios",
    "section": "Densidades marginales",
    "text": "Densidades marginales\n\\(f_{X,Y}(x, y)\\) continua es la joint pdf de \\((X, Y)\\). Se pueden encontrar las pdf \\(f_X, f_Y\\) de la siguiente manera:\n\\[\n\\begin{aligned}\nf_X(x) &= \\frac{d}{dx} P(X \\leq x) \\\\\n       &= \\frac{d}{dx} \\int_{-\\infty}^x \\int_{-\\infty}^{+\\infty} f_{X,Y}(u, v) \\, dv \\, du \\\\\n       &= \\int_{-\\infty}^{+\\infty} f_{X,Y}(x, v) \\, dv\n\\end{aligned}\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#c√°lculo-de-probabilidades",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#c√°lculo-de-probabilidades",
    "title": "Vectores Aleatorios",
    "section": "C√°lculo de probabilidades",
    "text": "C√°lculo de probabilidades\nSea \\(D \\subset \\mathbb{R}^2\\) una regi√≥n en el plano que cumple con las condiciones para ser Riemann integrable.\n\\(f_{X,Y}(x, y)\\) es la joint pdf de \\((X, Y)\\) y tiene la siguiente propiedad:\n\\[\nP[(X, Y) \\in D] = \\iint_D f_{X,Y}(x, y) \\, dA\n\\]\nAdem√°s, bajo las condiciones del Teorema de Fubini se cumple que la anterior integral doble puede calcularse tanto como una integral iterada en el orden \\(dx \\, dy\\) como una en el orden \\(dy \\, dx\\), aunque para esto los l√≠mites de integraci√≥n deben acomodarse adecuadamente.",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#independencia",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#independencia",
    "title": "Vectores Aleatorios",
    "section": "Independencia",
    "text": "Independencia\nSi \\(r, s\\) son funciones continuas y \\(X, Y\\) son independientes, entonces \\(r(X)\\) y \\(s(Y)\\) tambi√©n son independientes.\nA partir de dicha definici√≥n puede probarse que \\(X, Y\\) son independientes:\n\\[\n\\Longleftrightarrow F_{X,Y}(x, y) = F_X(x) F_Y(y) \\quad \\forall x, y \\in \\mathbb{R}\n\\]\nAsumiendo que \\(F_X, F_Y\\) son derivables \\(\\forall \\mathbb{R}\\), entonces la anterior igualdad ocurre:\n\\[\n\\Longleftrightarrow f_{X,Y}(x, y) = f_X(x) f_Y(y) \\quad \\forall x, y \\in \\mathbb{R}\n\\]\nTeorema de Factorizaci√≥n:\nSi el vector \\((X, Y)\\) es absolutamente continuo, entonces\n\\[\nf_{X,Y}(x, y) = g(x) h(y) \\quad \\forall x, y \\in \\mathbb{R}\n\\]\npara ciertas funciones \\(g, h\\).",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#densidad-de-una-suma",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#densidad-de-una-suma",
    "title": "Vectores Aleatorios",
    "section": "Densidad de una suma",
    "text": "Densidad de una suma\n\n\n\n\n\n\nNota\n\n\n\nTeorema:\nSi \\((X, Y)\\) es un vector absolutamente continuo y \\(f_{X,Y}\\) es su funci√≥n de densidad conjunta, entonces la funci√≥n de densidad de \\(X + Y\\) viene dada por:\n\\[\nf_{X+Y}(z) = \\int_{-\\infty}^{+\\infty} f_{X,Y}(u, z - u) \\, du \\quad \\text{para } z \\in \\mathbb{R}\n\\]\nNota:\nComo corolario del teorema anterior se obtiene que si \\(X, Y\\) son v.a. absolutamente continuas e independientes, entonces \\(f_{X,Y}(u, z - u) = f_X(u) f_Y(z - u)\\) y:\n\\[\nf_{X+Y}(z) = \\int_{-\\infty}^{+\\infty} f_X(u) f_Y(z - u) \\, du \\quad \\text{para } z \\in \\mathbb{R}\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#transformaciones-en-vectores-aleatorios",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#transformaciones-en-vectores-aleatorios",
    "title": "Vectores Aleatorios",
    "section": "Transformaciones en vectores aleatorios",
    "text": "Transformaciones en vectores aleatorios\nSea \\((X, Y)\\) un v.e. abs. continuo con joint pdf \\(f_{X,Y}(x, y)\\) y sean \\(g_1(x, y), g_2(x, y)\\) dos funciones.\nDef√≠nase:\n\n\\(A = \\{(x, y) \\in \\mathbb{R}^2 : f_{X,Y}(x, y) &gt; 0\\}\\)\n\n\\(B = \\{(u, v) \\in \\mathbb{R}^2 : u = g_1(x, y), v = g_2(x, y) \\ \\text{para alg√∫n } (x, y) \\in A\\}\\)\n\nSuponga que \\(g_1, g_2\\) son inyectivas en \\(A\\) de modo que la transformaci√≥n \\((U, V) = T(x, y) = (g_1(x, y), g_2(x, y))\\) es biyectiva como funci√≥n de \\(A\\) a \\(B\\) y en particular \\(T^{-1}(u, v) = (x, y) = (h_1(u, v), h_2(u, v))\\) existe.\nSuponga que \\(h_1, h_2\\) son \\(C^1\\) en \\(B\\) y que adem√°s para todo \\((u, v) \\in B\\) se tiene que\n\\[\nJ := \\left| \\begin{array}{cc}\n\\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} \\\\\n\\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v}\n\\end{array} \\right| \\neq 0\n\\]\nEntonces el vector aleatorio \\((U, V)\\) es absolutamente continuo y su densidad conjunta \\(f_{U,V}(u, v)\\) viene dada por:\n\\[\nf_{U,V}(u, v) = \\begin{cases}\n0 & \\text{si } (u, v) \\notin B \\\\\nf_{X,Y}(x(u, v), y(u, v)) \\cdot |J| & \\text{si } (u, v) \\in B\n\\end{cases}\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#acerca-de-independencia",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#acerca-de-independencia",
    "title": "Vectores Aleatorios",
    "section": "Acerca de independencia",
    "text": "Acerca de independencia\nLos conceptos de independencia, el teorema de factorizaci√≥n, funciones generadoras de momentos y cambios de variable para variables aleatorias se extienden de manera natural a dimensiones mayores a 2.",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#funci√≥n-generadora-de-momentos",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#funci√≥n-generadora-de-momentos",
    "title": "Vectores Aleatorios",
    "section": "Funci√≥n generadora de momentos",
    "text": "Funci√≥n generadora de momentos\nLa funci√≥n generadora de momentos de un vector \\(X = (X_1, X_2, \\dots, X_n)\\) corresponde a la funci√≥n:\n\\[\nM_X(t_1, t_2, \\dots, t_n) = \\mathbb{E} \\left[ e^{\\sum\\limits_{j=1}^n t_j X_j} \\right]\n\\]\ndefinida en aquella regi√≥n de \\(\\mathbb{R}^n\\) donde dicha esperanza exista.\n\n\n\n\n\n\nNota\n\n\n\nNota 1:\nEn el caso de que \\((X_1, X_2, \\dots, X_n)\\) sean independientes, se cumple que\n\\[\nM_X(t_1, t_2, \\dots, t_n) = \\prod_{j=1}^n M_{X_j}(t_j)\n\\]\nNota 2:\nSimilar al caso de dimensi√≥n 1, si la anterior \\(M_X(t_1, t_2, \\dots, t_n)\\) existe en un intervalo abierto del origen \\(\\vec{0}\\), entonces dicha funci√≥n puede utilizarse para calcular momentos. Por ejemplo:\n\\[\n\\mathbb{E}[X_1^3] = \\left. \\frac{\\partial^3}{\\partial t_1^3} M_X(t_1, t_2, \\dots, t_n) \\right|_{t = \\vec{0}}\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#distribuci√≥n-normal-multivariada",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#distribuci√≥n-normal-multivariada",
    "title": "Vectores Aleatorios",
    "section": "Distribuci√≥n normal multivariada",
    "text": "Distribuci√≥n normal multivariada\nSea \\(\\mu \\in \\mathbb{R}^n\\), \\(\\Sigma \\in M(n, \\mathbb{R})\\) donde \\(\\Sigma^T = \\Sigma\\) y \\(\\Sigma\\) es una matriz definida positiva. Se dice que el v.e. \\(X = (X_1, X_2, \\dots, X_n)\\) tiene una distribuci√≥n normal multivariada con media \\(\\mu\\) y matriz de covarianza \\(\\Sigma\\), si su funci√≥n de densidad viene dada por:\n\\[\nf(X) = \\frac{1}{(2\\pi)^{n/2} |\\Sigma|^{1/2}} \\cdot e^{-\\frac{1}{2} (X - \\mu)^T \\Sigma^{-1} (X - \\mu)}\n\\]\nAl igual que en el caso de la normal bivariada, si el vector \\(X\\) es normal multivariado entonces cada componente del vector es normal. De hecho, usando el resultado de la diapositiva anterior puede probarse que toda combinaci√≥n lineal de las variables \\(X_1, X_2, \\dots, X_n\\) es normal tambi√©n.\n\n\n\n\n\n\nAdvertencia\n\n\n\nCuidado:\nComo vimos anteriormente puede ocurrir que \\(X, Y\\) sean dos variables normales (no independientes), pero que el vector \\((X, Y)\\) no sea normal bivariado. Esta situaci√≥n se generaliza para dimensiones superiores.",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#esperanzas",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#esperanzas",
    "title": "Vectores Aleatorios",
    "section": "Esperanzas",
    "text": "Esperanzas\nSea \\((X, Y)\\) un v.e con joint pdf \\(f_{X,Y}(x,y)\\) y sea \\(g : \\mathbb{R}^2 \\to \\mathbb{R}\\) una funci√≥n continua. Es importante se√±alar que incluso sin conocer dicha densidad el teorema del estad√≠stico inconsciente sigue siendo v√°lido en este contexto y nos dice que:\n\\[\n\\mathbb{E}[g(X,Y)] = \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} g(x,y) f_{X,Y}(x,y) \\, dy dx\n\\]\nsiempre que la integral sea absolutamente convergente.\n\n\nPropiedades\n\nSi \\(\\mathbb{E}[X]\\) y \\(\\mathbb{E}[Y]\\) existen, entonces:\n\n\\[\n\\mathbb{E}[\\alpha X + \\beta Y] = \\alpha \\mathbb{E}[X] + \\beta \\mathbb{E}[Y] \\quad \\text{para todo } \\alpha, \\beta \\in \\mathbb{R}\n\\]\n\nSi \\(X, Y\\) son variables independientes, entonces:\n\n\\[\n\\mathbb{E}[XY] = \\mathbb{E}[X] \\, \\mathbb{E}[Y]\n\\]\n\nSi \\(X \\geq 0\\) c.s., entonces \\(\\mathbb{E}[X] \\geq 0\\).\nEl anterior resultado puede usarse para deducir algunas desigualdades tales como1:\n\nMonotonicidad de la esperanza:\nSi \\(X \\leq Y\\) c.s., entonces\n\\[\\mathbb{E}[X] \\leq \\mathbb{E}[Y]\\qquad\\text{(cuando ambas esperanzas existan)}\\]\nDesigualdad triangular:\n\\[|\\mathbb{E}[X]| \\leq \\mathbb{E}[|X|] \\quad \\text{ cuando }\\quad\\mathbb{E}(|X|) &lt; \\infty\\]\nCauchy-Schwarz:\n\\[|\\mathbb{E}[XY]| \\leq \\sqrt{\\mathbb{E}(X^2)} \\sqrt{\\mathbb{E}(Y^2)}\\quad \\text{ cuando }\\quad \\mathbb{E}[X^2] &lt; \\infty \\; \\text{ y }\\; \\mathbb{E}[Y^2] &lt; \\infty\\]",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#covarianza-correlaci√≥n-y-matriz-de-covarianza",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#covarianza-correlaci√≥n-y-matriz-de-covarianza",
    "title": "Vectores Aleatorios",
    "section": "Covarianza, correlaci√≥n y matriz de covarianza",
    "text": "Covarianza, correlaci√≥n y matriz de covarianza\nDen√≥tese:\n\\[\\mu_X = \\mathbb{E}(X) \\qquad \\mu_Y = \\mathbb{E}(Y)\\]\n\nEl valor esperado del vector \\((X, Y)\\) es el vector \\((\\mu_X, \\mu_Y)\\).\nLa covarianza de las variables \\(X, Y\\) se define como:\n\n\\[\n\\text{Cov}[X, Y] = \\mathbb{E} \\left[ (X - \\mu_X)(Y - \\mu_Y) \\right]\n\\]\n(De donde se deduce):\n\\[\n\\text{Var}[X] = \\text{Cov}[X, X], \\quad \\text{Cov}[X, Y] = \\text{Cov}[Y, X]\n\\]\n\nSi \\(\\text{Var}[X]\\) y \\(\\text{Var}[Y]\\) existen, entonces:\n\n\\[\n\\text{Var}[\\alpha X + \\beta Y] = \\alpha^2 \\text{Var}[X] + \\beta^2 \\text{Var}[Y] + 2\\alpha \\beta \\text{Cov}[X, Y]\n\\]\n\nEn particular, si \\(X\\) y \\(Y\\) son independientes, entonces:\n\n\\[\n\\text{Var}[\\alpha X + \\beta Y] = \\alpha^2 \\text{Var}[X] + \\beta^2 \\text{Var}[Y]\n\\]\n\nLa matriz de covarianza del vector \\((X, Y)\\) es la matriz:\n\n\\[\n\\Sigma(X,Y) =\n\\begin{pmatrix}\n\\text{Var}[X] & \\text{Cov}[X,Y] \\\\\n\\text{Cov}[Y,X] & \\text{Var}[Y]\n\\end{pmatrix}\n\\]\n\nEl coeficiente de correlaci√≥n entre \\(X\\) y \\(Y\\) se define como:\n\n\\[\n\\rho_{XY} = \\frac{\\text{Cov}[X,Y]}{\\sigma_X \\sigma_Y}\n\\]\n\nLa matriz de correlaci√≥n del vector \\((X, Y)\\) es la matriz2:\n\n\\[\n\\begin{pmatrix}\n1 & \\rho_{XY} \\\\\n\\rho_{YX} & 1\n\\end{pmatrix}\n\\]\n\n\nOtras propiedades\nSean \\(X, Y\\) dos variables aleatorias:\n\nSea \\(X\\) una v.a. no negativa c.s. Entonces \\(\\mathbb{E}[X] = 0\\) si y solo si \\(X = 0\\) c.s.\n\\(\\text{Cov}[X, Y] = \\mathbb{E}[XY] - \\mu_X \\mu_Y\\)\nSi \\(X, Y\\) son independientes, entonces \\(\\text{Cov}[X, Y] = 0\\)\n\\(|\\text{Cov}[X,Y]| \\leq \\sqrt{\\text{Var}[X]} \\sqrt{\\text{Var}[Y]}\\).\nEn particular, se tiene que \\(-1 \\leq \\rho_{XY} \\leq 1\\)",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#footnotes",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#footnotes",
    "title": "Vectores Aleatorios",
    "section": "Notas",
    "text": "Notas\n\n\nEstas propiedades son v√°lidas para todos los tipos de variables aleatorias (discretas, absolutamente continuas, mixtas, etc).‚Ü©Ô∏é\nTanto la matriz de covarianza como la de correlaci√≥n son matrices sim√©tricas.‚Ü©Ô∏é",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#vectores-aleatorios-discretos",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#vectores-aleatorios-discretos",
    "title": "Vectores Aleatorios",
    "section": "Vectores Aleatorios Discretos",
    "text": "Vectores Aleatorios Discretos\nLo de vectores aleatorios absolutamente continuos puede ser adaptado para ser utilizado en el caso de vectores discretos.\n\nFunci√≥n de masa condicional\nSea \\((X, Y)\\) un v.e. discreto con funci√≥n de probabilidad \\(p_{X,Y}(x,y)\\) y marginales \\(p_X(x)\\), \\(p_Y(y)\\). \\(\\forall x : p_X(x) &gt; 0\\).\nSe define la pmf condicional de \\(Y\\) dado que \\(X = x\\) como:\n\\[\np_{Y|X}(y \\mid x) = \\frac{P(X = x, Y = y)}{P(X = x)} = \\frac{p(x,y)}{p_X(x)}\n\\]\nSimilarmente, para cada \\(y\\) tal que \\(p_Y(y) &gt; 0\\) se define la pmf de \\(X\\) dado que \\(Y = y\\) como:\n\\[\np_{X|Y}(x \\mid y) = \\frac{p_{X,Y}(x,y)}{p_Y(y)}\n\\]\n\n\n\nEsperanza condicional\nSea \\(Y\\) una v.a. tal que \\(\\mathbb{E}|Y| &lt; \\infty\\) y sea \\(g\\) una funci√≥n.\nLa esperanza condicional de \\(g(Y)\\) dado \\(X = x\\) se define como:\n\\[\n\\phi(x) := \\mathbb{E}(g(Y) \\mid X = x) = \\sum_{y \\in \\text{Im}(Y)} g(y) \\, p_{Y|X}(y \\mid x)\n\\]\nsiempre que la anterior suma (en caso de ser una serie) converja absolutamente.",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#densidad-condicional",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#densidad-condicional",
    "title": "Vectores Aleatorios",
    "section": "Densidad condicional",
    "text": "Densidad condicional\nSea \\((X,Y)\\) un v.e. absolutamente continuo con joint pdf \\(f_{X,Y}(x,y)\\)\ny con marginal pdf \\(f_X(x)\\), \\(f_Y(y)\\).\nPara cada \\(x\\) tal que \\(f_X(x) &gt; 0\\) se define la pdf condicional de \\(Y\\) dado que \\(X = x\\) como:\n\\[\nf_{Y|X}(y \\mid x) = \\frac{f_{X,Y}(x,y)}{f_X(x)}\n\\]\nSimilarmente \\(\\forall y : f_Y(y) &gt; 0\\) se define la densidad condicional de \\(X\\) dado que \\(Y = y\\) como:\n\\[\n\\phi(x) := \\mathbb{E}[g(Y) \\mid X = x] = \\int_{-\\infty}^{+\\infty} g(y) \\cdot f_{Y|X}(y|x) \\, dy\n\\]\nsiempre que la anterior integral converja absolutamente.\nDe manera similar al caso discreto, se define \\(\\mathbb{E}[g(X) \\mid X]\\).",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#varianza-condicional",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#varianza-condicional",
    "title": "Vectores Aleatorios",
    "section": "Varianza condicional",
    "text": "Varianza condicional\nTambi√©n, la varianza condicional de \\(Y\\) dada \\(X = x\\) se define como:\n\\[\nr(x) = \\text{Var}[Y \\mid X = x] = \\mathbb{E}\\left[Y^2 \\mid X = x\\right] - \\left( \\mathbb{E}[Y \\mid X = x] \\right)^2\n\\]\nEsta definici√≥n aplica tanto para el caso discreto como para el caso continuo.\n\nPropiedades\nTanto para el caso discreto como absolutamente continuo (y otros m√°s generales), se cumplen las siguientes propiedades (asumiendo que las esperanzas y varianzas involucradas existen):\n\nLey de esperanza total:\nLa esperanza condicional \\(\\mathbb{E}[X \\mid Y]\\) es una v.a. la cual es una funci√≥n de \\(Y\\) y satisface que:\n\\[\n\\mathbb{E}[\\mathbb{E}[X \\mid Y]] = \\mathbb{E}[X]\n\\]\nM√°s generalmente:\n\\[\n\\mathbb{E}[X] = \\sum_{i=1}^n P(A_i) \\mathbb{E}[X \\mid A_i]\n\\]\nLinealidad:\nLa esperanza condicional es lineal, i.e.:\n\\[\n\\mathbb{E}[\\alpha X + \\beta Y \\mid Z] = \\alpha \\cdot \\mathbb{E}[X \\mid Z] + \\beta \\cdot \\mathbb{E}[Y \\mid Z]\n\\]\nIndependencia:\nSi \\(X, Y\\) son independientes entonces:\n\\[\n\\mathbb{E}[X \\mid Y] = \\mathbb{E}[X]\n\\]\nSacar informaci√≥n conocida:\n\\[\n\\mathbb{E}[X \\mid X] = X\n\\]\n\\[\n\\mathbb{E}[g(X) \\mid X] = g(X)\n\\]\nY m√°s generalmente:\n\\[\n\\mathbb{E}[X \\cdot g(Y) \\mid Y] = g(Y) \\cdot \\mathbb{E}[X \\mid Y]\n\\]\nLey de varianza total:\n\\[\n\\text{Var}[X] = \\mathbb{E}[\\text{Var}[X \\mid Y]] + \\text{Var}(\\mathbb{E}[X \\mid Y])\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#propiedades-1",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#propiedades-1",
    "title": "Vectores Aleatorios",
    "section": "Propiedades",
    "text": "Propiedades\nTanto para el caso discreto como absolutamente continuo (y otros m√°s generales), se cumplen las siguientes propiedades (asumiendo que las esperanzas y varianzas involucradas existen):\n\nLey de esperanza total:\nLa esperanza condicional \\(\\mathbb{E}[X \\mid Y]\\) es una v.a. la cual es una funci√≥n de \\(Y\\) y satisface que:\n\\[\n\\mathbb{E}[\\mathbb{E}[X \\mid Y]] = \\mathbb{E}[X]\n\\]\nM√°s generalmente:\n\\[\n\\mathbb{E}[X] = \\sum_{i=1}^n P(A_i) \\mathbb{E}[X \\mid A_i]\n\\]\nLinealidad:\nLa esperanza condicional es lineal, i.e.:\n\\[\n\\mathbb{E}[\\alpha X + \\beta Y \\mid Z] = \\alpha \\cdot \\mathbb{E}[X \\mid Z] + \\beta \\cdot \\mathbb{E}[Y \\mid Z]\n\\]\nIndependencia:\nSi \\(X, Y\\) son independientes entonces:\n\\[\n\\mathbb{E}[X \\mid Y] = \\mathbb{E}[X]\n\\]\nSacar informaci√≥n conocida:\n\\[\n\\mathbb{E}[X \\mid X] = X\n\\]\n\\[\n\\mathbb{E}[g(X) \\mid X] = g(X)\n\\]\nY m√°s generalmente:\n\\[\n\\mathbb{E}[X \\cdot g(Y) \\mid Y] = g(Y) \\cdot \\mathbb{E}[X \\mid Y]\n\\]\nLey de varianza total:\n\\[\n\\text{Var}[X] = \\mathbb{E}[\\text{Var}[X \\mid Y]] + \\text{Var}(\\mathbb{E}[X \\mid Y])\n\\]"
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#definici√≥n-formal-de-mathbbex-mid-mathcalh",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#definici√≥n-formal-de-mathbbex-mid-mathcalh",
    "title": "Vectores Aleatorios",
    "section": "Definici√≥n formal de \\(\\mathbb{E}[X \\mid \\mathcal{H}]\\)",
    "text": "Definici√≥n formal de \\(\\mathbb{E}[X \\mid \\mathcal{H}]\\)\nSea \\((\\Omega, \\mathcal{F}, P)\\) e.p y sea \\(X : \\Omega \\to \\mathbb{R}\\) una v.a. tal que \\(\\mathbb{E}|X| &lt; \\infty\\) y sea \\(\\mathcal{H} \\subset \\mathcal{F}\\) otra \\(\\sigma\\)‚Äì√°lgebra.\nUna esperanza condicional de \\(X\\) dado \\(\\mathcal{H}\\) es cualquier v.a. \\(Z : \\Omega \\to \\mathbb{R}\\) tal que:\n\n\\(Z^{-1}(B) \\in \\mathcal{H}\\) para todo \\(B \\in \\mathcal{B}(\\mathbb{R})\\)\n\n\\(\\mathbb{E}[Z \\cdot 1_H] = \\mathbb{E}[X \\cdot 1_H]\\) para todo \\(H \\in \\mathcal{H}\\)\n\n\nObservaciones:\n\nLa esperanza condicional no es la √∫nica que dicha unicidad sea entendida en un sentido casi siempre.\nLa ‚Äú√∫nica‚Äù esperanza condicional de \\(X\\) dado \\(\\mathcal{H}\\) se denota por \\(\\mathbb{E}[Y \\mid \\mathcal{H}]\\).\nCuando \\(Y\\) es una v.a. se define \\(\\mathbb{E}[X \\mid Y]\\) como \\(\\mathbb{E}[X \\mid \\sigma(Y)]\\) donde \\(\\sigma(Y)\\) es la \\(\\sigma\\)‚Äì√°lgebra generada por la v.a. \\(Y\\).\nLa esperanza condicional \\(\\mathbb{E}[X \\mid \\mathcal{H}]\\) se interpreta como la mejor estimaci√≥n que puede hacerse de \\(X\\) en t√©rminos de la informaci√≥n contenida en \\(\\mathcal{H}\\).",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#esperanza-condicional-respecto-a-un-evento",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#esperanza-condicional-respecto-a-un-evento",
    "title": "Vectores Aleatorios",
    "section": "Esperanza condicional respecto a un evento",
    "text": "Esperanza condicional respecto a un evento\nSea \\(X\\) en \\((\\Omega, \\mathcal{F}, P)\\) y sea \\(B \\in \\mathcal{F}\\) con \\(P(B) &gt; 0\\).\nSuponga que \\(\\mathbb{E}|X| &lt; \\infty\\).\n\\[\n\\mathbb{E}[X \\mid B] = \\frac{\\mathbb{E}[X \\cdot \\mathbf{1}_B]}{P(B)}\n\\]\nSean \\((B_i)_{i=1}^n\\) eventos en \\((\\Omega, \\mathcal{F}, P)\\) partici√≥n de \\(\\Omega\\):\n\\[\n\\mathbb{E}[X] = \\sum_{i=1}^n \\mathbb{E}[X \\mid B_i] \\cdot P(B_i)\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#propiedad-minimizadora-de-la-esperanza",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#propiedad-minimizadora-de-la-esperanza",
    "title": "Vectores Aleatorios",
    "section": "Propiedad minimizadora de la esperanza",
    "text": "Propiedad minimizadora de la esperanza\nLa esperanza condicional \\(\\mathbb{E}[Y \\mid X]\\) suele ser interpretada como la mejor predicci√≥n que puede hacerse de la variable \\(Y\\) a partir de la variable \\(X\\).\nSuponga que se observa el valor de una v.a. \\(X\\) y luego, con base en el valor observado, se intenta predecir el valor de una segunda v.a. \\(Y\\).\nDen√≥tese por \\(g(X)\\) el predictor; i.e., si se observa que \\(X = x\\), entonces \\(g(x)\\) es nuestra predicci√≥n para el valor de \\(Y\\).\nLa intenci√≥n es escoger \\(g(X)\\) de manera que en cierta forma est√© cerca de la variable \\(Y\\).\nPor supuesto, en general, hay distintas maneras en que se puede medir la cercan√≠a de \\(g(X)\\) con \\(Y\\), pero pensemos que se desea utilizar como criterio la expresi√≥n:\n\\[\n\\mathbb{E}[(Y - g(X))^2]\n\\]\nPara esto se requiere asumir que \\(Y\\) y \\(g(X)\\) satisfacen ciertas condiciones en relaci√≥n con sus segundos momentos.\nAsumiendo que tales condiciones se cumplen, no es dif√≠cil mostrar que:\n\\[\n\\mathbb{E}[(Y - g(X))^2] \\geq \\mathbb{E}[(Y - \\mathbb{E}[Y \\mid X])^2]\n\\]\nDe manera que, bajo esta noci√≥n de cercan√≠a, se puede ver que \\(\\mathbb{E}[Y \\mid X]\\) es en efecto el mejor predictor de \\(Y\\) que puede hacerse a partir de \\(X\\).",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#revisando-la-normal-bivariada",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#revisando-la-normal-bivariada",
    "title": "Vectores Aleatorios",
    "section": "Revisando la normal bivariada",
    "text": "Revisando la normal bivariada\nSean \\(Z_1, Z_2\\) dos v.a. indep. con distribuci√≥n \\(\\mathcal{N}(0,1)\\) y sean \\(\\mu_X, \\mu_Y \\in \\mathbb{R}, \\sigma_X, \\sigma_Y \\in \\mathbb{R}^+, \\rho \\in [-1,1]\\).\nUsando la f√≥rmula de cambio de variable se puede mostrar que si\n\\(X = \\sigma_X Z_1 + \\mu_X\\),\n\\(Y = \\mu_Y + \\sigma_Y(\\rho Z_1 + \\sqrt{1 - \\rho^2} Z_2)\\),\nentonces el vector \\((X,Y)\\) sigue una distribuci√≥n normal bivariada donde:\n\n\\(\\mathbb{E}(X) = \\mu_X\\)\n\n\\(\\mathbb{E}(Y) = \\mu_Y\\)\n\n\\(\\text{Var}(X) = \\sigma_X^2\\)\n\n\\(\\text{Var}(Y) = \\sigma_Y^2\\)\n\n\\(\\text{Cov}(X,Y) = \\sigma_X \\sigma_Y \\rho\\)\n\nDe hecho, la anterior implicaci√≥n es reversible en el sentido de que si el vector \\((X,Y)\\) sigue una distribuci√≥n normal bivariada con \\(\\mathbb{E}(X) = \\mu_X\\), \\(\\mathbb{E}(Y) = \\mu_Y\\), \\(\\text{Var}(X) = \\sigma_X^2\\), \\(\\text{Var}(Y) = \\sigma_Y^2\\), \\(\\text{Cov}(X,Y) = \\sigma_X \\sigma_Y \\rho\\), entonces existen variables aleatorias \\(Z_1, Z_2\\) independientes con distribuci√≥n \\(\\mathcal{N}(0,1)\\), tal que:\n\\[\nX = \\sigma_X Z_1 + \\mu_X,\\quad Y = \\mu_Y + \\sigma_Y (\\rho Z_1 + \\sqrt{1 - \\rho^2} Z_2)\n\\]\nAlgo muy conveniente de los ejemplos es que permite usar propiedades de esperanzas, varianzas y covarianzas para verificar que:\n\n\\(\\mathbb{E}(X) = \\mu_X\\)\n\\(\\mathbb{E}(Y) = \\mu_Y\\)\n\\(\\text{Var}(X) = \\sigma_X^2\\)\n\\(\\text{Var}(Y) = \\sigma_Y^2\\)\n\\(\\text{Cov}(X,Y) = \\sigma_X \\sigma_Y \\rho\\)\n\nSimilarmente, usando propiedades de las variables con distribuci√≥n normal y de la esperanza condicional, puede verse que si \\((X,Y)\\) es un v.e. con distribuci√≥n normal bivariada con par√°metros \\(\\mu_X, \\mu_Y, \\sigma_X, \\sigma_Y, \\rho\\), entonces:\n\\[\n\\mathbb{E}[Y \\mid X = x] = \\mu_Y + \\rho \\sigma_Y \\frac{x - \\mu_X}{\\sigma_X}\n\\]\n\\[\n\\text{Var}[Y \\mid X = x] = (1 - \\rho^2) \\sigma_Y^2\n\\]\nNota: Un resultado similar aplica para \\(X \\mid Y = y\\).",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#funciones-importantes",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#funciones-importantes",
    "title": "Vectores Aleatorios",
    "section": "Funciones importantes",
    "text": "Funciones importantes\nSea \\(\\mathbf{X} = (X_1, \\dots, X_n)\\) un vector aleatorio \\(n\\)‚Äìdimensional. Se utiliza \\(\\mathbf{t} \\cdot \\mathbf{X} = \\mathbf{t}^\\mathsf{T} \\mathbf{X}\\) en lugar de \\(tX\\):\n\n\n\n\n\n\nFunci√≥n Caracter√≠stica\n\n\n\n\\[\n\\varphi_{\\mathbf{X}}(\\mathbf{t}) = \\mathbb{E} \\left[ e^{i \\mathbf{t}^\\mathsf{T} \\mathbf{X}} \\right]\n= \\int_{\\mathbb{R}^n} e^{i \\mathbf{t}^\\mathsf{T} \\mathbf{x}} \\cdot f_{\\mathbf{X}}(\\mathbf{x}) \\, d\\mathbf{x}\n\\]\nEst√° definida para todo \\(\\mathbf{t} \\in \\mathbb{R}^n\\).\n\n\n\n\n\n\n\n\nFunci√≥n Generadora de Momentos\n\n\n\n\\[\nM_{\\mathbf{X}}(\\mathbf{t}) = \\mathbb{E} \\left[ e^{\\mathbf{t}^\\mathsf{T} \\mathbf{X}} \\right]\n= \\int_{\\mathbb{R}^n} e^{\\mathbf{t}^\\mathsf{T} \\mathbf{x}} \\cdot f_{\\mathbf{X}}(\\mathbf{x}) \\, d\\mathbf{x}\n\\]\nV√°lida para todo \\(\\mathbf{t}\\) donde dicho valor esperado exista.\n\n\n\n\n\n\n\n\nFunci√≥n Generadora de Probabilidades\n\n\n\n\\[\nG_{\\mathbf{X}}(\\mathbf{t}) = \\mathbb{E} \\left[ \\mathbf{t}^{\\mathbf{X}} \\right]\n= \\int_{\\mathbb{R}^n} \\mathbf{t}^{\\mathbf{x}} \\cdot f_{\\mathbf{X}}(\\mathbf{x}) \\, d\\mathbf{x}\n\\]\nV√°lida para todo \\(\\mathbf{t}\\) donde dicho valor esperado exista.",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  },
  {
    "objectID": "cursos/CA0721/vectores_aleatorios_CA0721.html#estad√≠sticos-de-orden",
    "href": "cursos/CA0721/vectores_aleatorios_CA0721.html#estad√≠sticos-de-orden",
    "title": "Vectores Aleatorios",
    "section": "Estad√≠sticos de orden",
    "text": "Estad√≠sticos de orden\nSean \\(X_1, X_2, \\dots, X_n\\) variables independientes absolutamente continuas e id√©nticamente distribuidas.\nEs claro que por definici√≥n:\n\\[\nX_{(1)} \\leq X_{(2)} \\leq X_{(3)} \\leq \\cdots \\leq X_{(n)}\n\\]\nDefinamos:\n\n\\(X_{(1)}\\) = el m√°s peque√±o de \\(X_1, X_2, \\dots, X_n\\)\n\\(X_{(2)}\\) = el segundo m√°s peque√±o\n\\(X_{(3)}\\) = el tercero m√°s peque√±o\n\\(\\;\\;\\vdots\\)\n\\(X_{(n)}\\) = el mayor\n\nSean \\(f\\) y \\(F\\) la funci√≥n de densidad y distribuci√≥n (com√∫n) de las variables \\(X_1, X_2, \\dots, X_n\\), y \\(X_{(1)}, X_{(2)}, \\dots, X_{(n)}\\) los estad√≠sticos de orden. Sean \\(i, j \\in \\{1, 2, \\dots, n\\}\\):\n\nFunci√≥n de densidad conjunta\n\\[\nf_{X_{(1)}, \\dots, X_{(n)}}(x_1, \\dots, x_n) =\n\\begin{cases}\nn! \\prod\\limits_{j=1}^{n} f(x_j) & \\text{si } x_1 &lt; x_2 &lt; \\cdots &lt; x_n \\\\\n0 & \\text{en otro caso}\n\\end{cases}\n\\]\n\n\nFunci√≥n de densidad del \\(j\\)-√©simo orden\n\\[\nf_{X_{(j)}}(x) = \\binom{n-1}{j-1} F^{j-1}(x) \\cdot (1 - F(x))^{n-j} \\cdot f(x)\n\\]\n\n\nFunci√≥n de distribuci√≥n de \\(X_{(j)}\\)\n\\[\nF_{X_{(j)}}(x) = \\sum_{k=j}^{n} \\binom{n}{k} F^k(x)(1 - F(x))^{n-k}\n\\]\n\nIntuici√≥n: \\(X_{(j)} &lt; x \\Leftrightarrow\\) al menos \\(j\\) de las variables son menores que \\(x\\)\n\n\n\nFunci√≥n de distribuci√≥n conjunta de \\(X_{(i)}, X_{(j)}\\) con \\(i &lt; j\\)\n\\[\nf_{X_{(i)}, X_{(j)}}(x_i, x_j) =\n\\tbinom{n}{i-1, j-i-1, 1, n-j} F^{i-1}(x_i) (F(x_j) - F(x_i))^{j-i-1} (1 - F(x_j))^{n-j} f(x_i) f(x_j)\n\\]\n\nIntuici√≥n: Una variable igual a \\(x_i\\), otra a \\(x_j\\), \\(i-1\\) menores a \\(x_i\\), \\(n-j\\) mayores que \\(x_j\\), y \\(j-i-1\\) entre \\(x_i\\) y \\(x_j\\).\n\n\n\n\nRango de la muestra aleatoria\nSean \\(X_1, X_2, \\dots, X_n\\) v.a. independientes absolutamente continuas e id√©nticamente distribuidas con distribuci√≥n uniforme \\(U(0,1)\\).\nSe define la variable del rango como:\n\\[\nV = X_{(n)} - X_{(1)} \\sim \\text{Beta}(n - 1, 2)\n\\]",
    "crumbs": [
      "Inicio",
      "Tema 5: Vectores Aleatorios"
    ]
  }
]